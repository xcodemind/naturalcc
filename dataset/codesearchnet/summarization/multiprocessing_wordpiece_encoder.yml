# Train (Joint vocabulary)
preprocess:
  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
  format: piece # piece, id, type=str, help='path to vocab.bpe'
  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_joined #", type=str, help='path to vocab.bpe'
  inputs:
    - '~/.ncc/CodeSearchNet/flatten/ruby/train.code' # type=str, help='path to vocab.bpe'
    - '~/.ncc/CodeSearchNet/flatten/ruby/train.docstring'
  outputs:
    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/train.code.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/train.docstring.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
  keep_empty: 1 #", action="store_true", help="keep empty lines"
  insert: 1 # ", action="store_true", help="keep empty lines"
  workers: 40
  train_model: 1


## Train (code)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_code #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/train.code' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/train.code.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 1


## Train (docstring)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_docstring #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/train.docstring' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/train.docstring.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 1


## Valid (code)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_joined #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/valid.code' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/valid.code.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 0


## Valid (docstring)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_joined #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/valid.docstring' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/valid.docstring.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 0


## Test (code)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_joined #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/test.code' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/test.code.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 0



## Test (docstring)
#preprocess:
#  vocab_size: 50000  #type=int, default=50000, help='path to vocab.bpe'
#  format: piece # piece, id, type=str, help='path to vocab.bpe'
#  model_prefix: ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/wordpiece_bpe/codesearchnet_joined #", type=str, help='path to vocab.bpe'
#  inputs:
#    - '~/.ncc/CodeSearchNet/flatten/ruby/test.docstring' # type=str, help='path to vocab.bpe'
#  outputs:
#    - ~/.ncc/CodeSearchNet/summarization/hicodebert-data-bin/test.docstring.bpe # ", nargs="+", default=['-'], help="path to save encoded outputs"
#  keep_empty: 1 #", action="store_true", help="keep empty lines"
#  insert: 1 # ", action="store_true", help="keep empty lines"
#  workers: 40
#  train_model: 0