# Steps to reproduce

## Step 1
Download dataset **Version 1.0 [526.6MB]** from (https://www.sri.inf.ethz.ch/py150)

```
wget http://files.srl.inf.ethz.ch/data/py150.tar.gz
```

Move the py150.tar.gz to ~/.ncc folder

```
mv py150.tar.gz ~/.ncc/
``` 

Then, unzip it

```
tar zxvf py150.tar.gz
```

We organise the ~/.ncc/py150 as follows:

|-- parse_python.py (some tools provided by py150)

|-- raw (the unzip py150.tar.gz files) 

|---- python100k_train.json  

|---- python1k_train.json  (```head -100 python100k_train.json > python1k_train.json``` for debug)

|---- python50k_eval.json

|-- trav_trans (all dataset for trav_trans baseline)

|---- checkpoints  (used to save the trained models.) 

|---- data-mmap   (used to save the preprocessed data via mmap binary mode.)

|---- data-raw  (used to save the preprocessed data via raw mode.)

|---- raw

|------ train.ast_trav_df (generated by Step 2)

|-- trav_trans_plus (all dataset for trav_trans_plus baseline)


## Step 2
Convert the ASTs in py150 dataset (https://www.sri.inf.ethz.ch/phog) to modified ASTs, as explained in Appendix A.1.
This step is only for py150, since there is some problems for the generated ASTs, please refer to Appendix A.1, to check whether there is some problems for our generated ASTs on CodeSearchNet dataset.

```
python -m dataset.py150.generate_new_trees -i ~/.ncc/py150/raw/python100_train.json -o ~/.ncc/py150/data/train.ast_trav_df
```


## Step 3
Run the preprocess script

```
python -m dataset.py150.trav_trans.preprocess
```
This script will generate the files in data-mmap/data-raw.