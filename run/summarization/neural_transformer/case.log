nohup: ignoring input
[2020-11-20 23:26:55]    INFO >> [code_tokens] dictionary: 50000 types (be_summarization.py:130, setup_task())
[2020-11-20 23:26:55]    INFO >> [docstring_tokens] dictionary: 30000 types (be_summarization.py:131, setup_task())
[2020-11-20 23:27:01]    INFO >> ["def getRadialPath(begin, center, end, path):\n\tbeginComplex = begin.dropAxis()\n\tendComplex = end.dropAxis()\n\tcenterComplex = center.dropAxis()\n\tbeginMinusCenterComplex = (beginComplex - centerComplex)\n\tendMinusCenterComplex = (endComplex - centerComplex)\n\tbeginMinusCenterComplexRadius = abs(beginMinusCenterComplex)\n\tendMinusCenterComplexRadius = abs(endMinusCenterComplex)\n\tif ((beginMinusCenterComplexRadius == 0.0) or (endMinusCenterComplexRadius == 0.0)):\n\t\treturn [begin]\n\tbeginMinusCenterComplex \/= beginMinusCenterComplexRadius\n\tendMinusCenterComplex \/= endMinusCenterComplexRadius\n\tangleDifference = euclidean.getAngleDifferenceByComplex(endMinusCenterComplex, beginMinusCenterComplex)\n\tradialPath = []\n\tfor point in path:\n\t\tweightEnd = point.x\n\t\tweightBegin = (1.0 - weightEnd)\n\t\tweightedRadius = ((beginMinusCenterComplexRadius * weightBegin) + ((endMinusCenterComplexRadius * weightEnd) * (1.0 + point.y)))\n\t\tradialComplex = ((weightedRadius * euclidean.getWiddershinsUnitPolar((angleDifference * point.x))) * beginMinusCenterComplex)\n\t\tpolygonPoint = (center + Vector3(radialComplex.real, radialComplex.imag, point.z))\n\t\tradialPath.append(polygonPoint)\n\treturn radialPath\n","get radial path ."] (predictor.py:56, main())
[2020-11-20 23:27:01]    INFO >> ["def getArcDistance(relativeLocation, splitLine):\n\thalfPlaneLineDistance = (0.5 * abs(relativeLocation.dropAxis(2)))\n\tradius = getDoubleFromCharacterSplitLine('R', splitLine)\n\tif (radius == None):\n\t\tiFloat = getDoubleFromCharacterSplitLine('I', splitLine)\n\t\tjFloat = getDoubleFromCharacterSplitLine('J', splitLine)\n\t\tradius = abs(complex(iFloat, jFloat))\n\tangle = 0.0\n\tif (radius > 0.0):\n\t\thalfPlaneLineDistanceOverRadius = (halfPlaneLineDistance \/ radius)\n\t\tif (halfPlaneLineDistance < radius):\n\t\t\tangle = (2.0 * math.asin(halfPlaneLineDistanceOverRadius))\n\t\telse:\n\t\t\tangle = (math.pi * halfPlaneLineDistanceOverRadius)\n\treturn abs(complex((angle * radius), relativeLocation.z))\n","get arc distance ."] (predictor.py:56, main())
[2020-11-20 23:27:01]    INFO >> ["def win32_utf8_argv():\n\ttry:\n\t\tfrom ctypes import POINTER, byref, cdll, c_int, windll\n\t\tfrom ctypes.wintypes import LPCWSTR, LPWSTR\n\t\tGetCommandLineW = cdll.kernel32.GetCommandLineW\n\t\tGetCommandLineW.argtypes = []\n\t\tGetCommandLineW.restype = LPCWSTR\n\t\tCommandLineToArgvW = windll.shell32.CommandLineToArgvW\n\t\tCommandLineToArgvW.argtypes = [LPCWSTR, POINTER(c_int)]\n\t\tCommandLineToArgvW.restype = POINTER(LPWSTR)\n\t\tcmd = GetCommandLineW()\n\t\targc = c_int(0)\n\t\targv = CommandLineToArgvW(cmd, byref(argc))\n\t\tif (argc.value > 0):\n\t\t\treturn [argv[i] for i in xrange(0, argc.value)]\n\texcept Exception:\n\t\tpass\n","uses shell32 ."] (predictor.py:56, main())
[2020-11-20 23:27:02]    INFO >> ["def localOutp(images, hidSums, targets, numModulesX, paddingStart, filterSizeX, moduleStride, numImgColors):\n\tnumGroups = 1\n\tpartialSum = 0\n\tnumImages = images.shape[0]\n\tnumFilters = (hidSums.shape[1] \/ (numModulesX ** 2))\n\tassert (targets.shape == (numFilters, (((numModulesX ** 2) * numImgColors) * (filterSizeX ** 2)))), ('%s\t%d\t%d-%d-%d' % (targets.shape.__str__(), numFilters, numImgColors, filterSizeX, filterSizeX))\n\t_ConvNet.localOutp(images.p_mat, hidSums.p_mat, targets.p_mat, numModulesX, filterSizeX, (- paddingStart), moduleStride, numImgColors, numGroups, partialSum)\n","images - hidsums - targets - ."] (predictor.py:56, main())
[2020-11-20 23:27:02]    INFO >> ["def positional(max_positional_args):\n\tdef positional_decorator(wrapped):\n\t\t@functools.wraps(wrapped)\n\t\tdef positional_wrapper(*args, **kwargs):\n\t\t\tif (len(args) > max_positional_args):\n\t\t\t\tplural_s = ''\n\t\t\t\tif (max_positional_args != 1):\n\t\t\t\t\tplural_s = 's'\n\t\t\t\tmessage = ('%s()\ttakes\tat\tmost\t%d\tpositional\targument%s\t(%d\tgiven)' % (wrapped.__name__, max_positional_args, plural_s, len(args)))\n\t\t\t\tif (positional_parameters_enforcement == POSITIONAL_EXCEPTION):\n\t\t\t\t\traise TypeError(message)\n\t\t\t\telif (positional_parameters_enforcement == POSITIONAL_WARNING):\n\t\t\t\t\tlogger.warning(message)\n\t\t\t\telse:\n\t\t\t\t\tpass\n\t\t\treturn wrapped(*args, **kwargs)\n\t\treturn positional_wrapper\n\tif isinstance(max_positional_args, six.integer_types):\n\t\treturn positional_decorator\n\telse:\n\t\t(args, _, _, defaults) = inspect.getargspec(max_positional_args)\n\t\treturn positional((len(args) - len(defaults)))(max_positional_args)\n","a decorator to declare that only the first n arguments my be positional ."] (predictor.py:56, main())
[2020-11-20 23:27:02]    INFO >> ["def load_grammar(gt='Grammar.txt', gp=None, save=True, force=False, logger=None):\n\tif (logger is None):\n\t\tlogger = logging.getLogger()\n\tif (gp is None):\n\t\t(head, tail) = os.path.splitext(gt)\n\t\tif (tail == '.txt'):\n\t\t\ttail = ''\n\t\tgp = (((head + tail) + '.'.join(map(str, sys.version_info))) + '.pickle')\n\tif (force or (not _newer(gp, gt))):\n\t\tlogger.info('Generating\tgrammar\ttables\tfrom\t%s', gt)\n\t\tg = pgen.generate_grammar(gt)\n\t\tif save:\n\t\t\tlogger.info('Writing\tgrammar\ttables\tto\t%s', gp)\n\t\t\ttry:\n\t\t\t\tg.dump(gp)\n\t\t\texcept IOError as e:\n\t\t\t\tlogger.info(('Writing\tfailed:' + str(e)))\n\telse:\n\t\tg = grammar.Grammar()\n\t\tg.load(gp)\n\treturn g\n","load the grammar ."] (predictor.py:56, main())
[2020-11-20 23:27:03]    INFO >> ["def make_thumbnail(in_fname, out_fname, width, height):\n\timg = Image.open(in_fname)\n\t(width_in, height_in) = img.size\n\tscale_w = (width \/ float(width_in))\n\tscale_h = (height \/ float(height_in))\n\tif ((height_in * scale_w) <= height):\n\t\tscale = scale_w\n\telse:\n\t\tscale = scale_h\n\twidth_sc = int(round((scale * width_in)))\n\theight_sc = int(round((scale * height_in)))\n\timg.thumbnail((width_sc, height_sc), Image.ANTIALIAS)\n\tthumb = Image.new('RGB', (width, height), (255, 255, 255))\n\tpos_insert = (((width - width_sc) \/ 2), ((height - height_sc) \/ 2))\n\tthumb.paste(img, pos_insert)\n\tthumb.save(out_fname)\n","make a thumbnail with the same aspect ratio centered in an image with a given width and height ."] (predictor.py:56, main())
[2020-11-20 23:27:03]    INFO >> ["def test_rgb_to_hsl_part_15():\n\tassert (rgb_to_hsl(0, 51, 0) == (120, 100, 10))\n\tassert (rgb_to_hsl(0, 102, 0) == (120, 100, 20))\n\tassert (rgb_to_hsl(0, 153, 0) == (120, 100, 30))\n\tassert (rgb_to_hsl(0, 204, 0) == (120, 100, 40))\n\tassert (rgb_to_hsl(0, 255, 0) == (120, 100, 50))\n\tassert (rgb_to_hsl(51, 255, 51) == (120, 100, 60))\n\tassert (rgb_to_hsl(102, 255, 102) == (120, 100, 70))\n\tassert (rgb_to_hsl(153, 255, 153) == (120, 100, 80))\n\tassert (rgb_to_hsl(204, 255, 204) == (120, 100, 90))\n","test rgb to hsl color function ."] (predictor.py:56, main())
[2020-11-20 23:27:05]    INFO >> ["def get_image_dimensions(file_or_path, close=False):\n\tfrom PIL import ImageFile as PillowImageFile\n\tp = PillowImageFile.Parser()\n\tif hasattr(file_or_path, 'read'):\n\t\tfile = file_or_path\n\t\tfile_pos = file.tell()\n\t\tfile.seek(0)\n\telse:\n\t\tfile = open(file_or_path, 'rb')\n\t\tclose = True\n\ttry:\n\t\tchunk_size = 1024\n\t\twhile 1:\n\t\t\tdata = file.read(chunk_size)\n\t\t\tif (not data):\n\t\t\t\tbreak\n\t\t\ttry:\n\t\t\t\tp.feed(data)\n\t\t\texcept zlib.error as e:\n\t\t\t\tif e.args[0].startswith('Error\t-5'):\n\t\t\t\t\tpass\n\t\t\t\telse:\n\t\t\t\t\traise\n\t\t\texcept struct.error:\n\t\t\t\tpass\n\t\t\tif p.image:\n\t\t\t\treturn p.image.size\n\t\t\tchunk_size *= 2\n\t\treturn (None, None)\n\tfinally:\n\t\tif close:\n\t\t\tfile.close()\n\t\telse:\n\t\t\tfile.seek(file_pos)\n","returns the of an image ."] (predictor.py:56, main())
[2020-11-20 23:27:05]    INFO >> ["def _mkstemp_inner(dir, pre, suf, flags):\n\tnames = _get_candidate_names()\n\tfor seq in xrange(TMP_MAX):\n\t\tname = names.next()\n\t\tfile = _os.path.join(dir, ((pre + name) + suf))\n\t\ttry:\n\t\t\tfd = _os.open(file, flags, 384)\n\t\t\t_set_cloexec(fd)\n\t\t\treturn (fd, _os.path.abspath(file))\n\t\texcept OSError as e:\n\t\t\tif (e.errno == _errno.EEXIST):\n\t\t\t\tcontinue\n\t\t\tif ((_os.name == 'nt') and (e.errno == _errno.EACCES)):\n\t\t\t\tcontinue\n\t\t\traise\n\traise IOError, (_errno.EEXIST, 'No\tusable\ttemporary\tfile\tname\tfound')\n","code common to mkstemp ."] (predictor.py:56, main())
[2020-11-20 23:27:06]    INFO >> ["def MessageEncoder(field_number, is_repeated, is_packed):\n\ttag = TagBytes(field_number, wire_format.WIRETYPE_LENGTH_DELIMITED)\n\tlocal_EncodeVarint = _EncodeVarint\n\tassert (not is_packed)\n\tif is_repeated:\n\t\tdef EncodeRepeatedField(write, value):\n\t\t\tfor element in value:\n\t\t\t\twrite(tag)\n\t\t\t\tlocal_EncodeVarint(write, element.ByteSize())\n\t\t\t\telement._InternalSerialize(write)\n\t\treturn EncodeRepeatedField\n\telse:\n\t\tdef EncodeField(write, value):\n\t\t\twrite(tag)\n\t\t\tlocal_EncodeVarint(write, value.ByteSize())\n\t\t\treturn value._InternalSerialize(write)\n\t\treturn EncodeField\n","returns an encoder for a message field ."] (predictor.py:56, main())
[2020-11-20 23:27:07]    INFO >> ["def _get_head_types(pat):\n\tif isinstance(pat, (pytree.NodePattern, pytree.LeafPattern)):\n\t\tif (pat.type is None):\n\t\t\traise _EveryNode\n\t\treturn {pat.type}\n\tif isinstance(pat, pytree.NegatedPattern):\n\t\tif pat.content:\n\t\t\treturn _get_head_types(pat.content)\n\t\traise _EveryNode\n\tif isinstance(pat, pytree.WildcardPattern):\n\t\tr = set()\n\t\tfor p in pat.content:\n\t\t\tfor x in p:\n\t\t\t\tr.update(_get_head_types(x))\n\t\treturn r\n\traise Exception((\"Oh\tno!\tI\tdon't\tunderstand\tpattern\t%s\" % pat))\n","accepts a pytree pattern node and returns a set of the pattern types which will match first ."] (predictor.py:56, main())
[2020-11-20 23:27:07]    INFO >> ["def user_cache_dir(appname):\n\tif WINDOWS:\n\t\tpath = os.path.normpath(_get_win_folder('CSIDL_LOCAL_APPDATA'))\n\t\tpath = os.path.join(path, appname, 'Cache')\n\telif (sys.platform == 'darwin'):\n\t\tpath = expanduser('~\/Library\/Caches')\n\t\tpath = os.path.join(path, appname)\n\telse:\n\t\tpath = os.getenv('XDG_CACHE_HOME', expanduser('~\/.cache'))\n\t\tpath = os.path.join(path, appname)\n\treturn path\n","return full path to the user-specific cache dir for this application ."] (predictor.py:56, main())
[2020-11-20 23:27:08]    INFO >> ["def getCarveIntersectionFromEdge(edge, vertexes, z):\n\tfirstVertex = vertexes[edge.vertexIndexes[0]]\n\tfirstVertexComplex = firstVertex.dropAxis(2)\n\tsecondVertex = vertexes[edge.vertexIndexes[1]]\n\tsecondVertexComplex = secondVertex.dropAxis(2)\n\tzMinusFirst = (z - firstVertex.z)\n\tup = (secondVertex.z - firstVertex.z)\n\treturn (((zMinusFirst * (secondVertexComplex - firstVertexComplex)) \/ up) + firstVertexComplex)\n","get the complex where the carve intersects the edge ."] (predictor.py:56, main())
[2020-11-20 23:27:09]    INFO >> ["def split_code_at_show(text):\n\tparts = []\n\tis_doctest = contains_doctest(text)\n\tpart = []\n\tfor line in text.split(u'\\n'):\n\t\tif (((not is_doctest) and (line.strip() == u'plt.show()')) or (is_doctest and (line.strip() == u'>>>\tplt.show()'))):\n\t\t\tpart.append(line)\n\t\t\tparts.append(u'\\n'.join(part))\n\t\t\tpart = []\n\t\telse:\n\t\t\tpart.append(line)\n\tif u'\\n'.join(part).strip():\n\t\tparts.append(u'\\n'.join(part))\n\treturn parts\n","split code at plt ."] (predictor.py:56, main())
[2020-11-20 23:27:10]    INFO >> ["@pytest.mark.django_db\ndef test_verify_user_after_update_email(trans_member):\n\twith pytest.raises(EmailAddress.DoesNotExist):\n\t\tEmailAddress.objects.get(user=trans_member)\n\tassert (trans_member.email == '')\n\taccounts.utils.update_user_email(trans_member, 'trans_member@this.test')\n\taccounts.utils.verify_user(trans_member)\n\tEmailAddress.objects.get(user=trans_member, primary=True, verified=True)\n","test verifying user using verify_user function ."] (predictor.py:56, main())
[2020-11-20 23:27:10]    INFO >> ["def get_short_module_name(module_name, obj_name):\n\tparts = module_name.split('.')\n\tshort_name = module_name\n\tfor i in range((len(parts) - 1), 0, (-1)):\n\t\tshort_name = '.'.join(parts[:i])\n\t\ttry:\n\t\t\texec ('from\t%s\timport\t%s' % (short_name, obj_name))\n\t\texcept Exception:\n\t\t\tshort_name = '.'.join(parts[:(i + 1)])\n\t\t\tbreak\n\treturn short_name\n","get the shortest possible module name ."] (predictor.py:56, main())
[2020-11-20 23:27:11]    INFO >> ["def getIntegerFromCharacterLengthLineOffset(character, offset, splitLine, stepLength):\n\tlineFromCharacter = gcodec.getStringFromCharacterSplitLine(character, splitLine)\n\tif (lineFromCharacter == None):\n\t\treturn 0\n\tfloatValue = ((float(lineFromCharacter) + offset) \/ stepLength)\n\treturn int(round(floatValue))\n","get the integer after the first occurence of the character in the split line ."] (predictor.py:56, main())
[2020-11-20 23:27:12]    INFO >> ["def constant_time_compare(val1, val2):\n\tif (len(val1) != len(val2)):\n\t\treturn False\n\tresult = 0\n\tif (six.PY3 and isinstance(val1, bytes) and isinstance(val2, bytes)):\n\t\tfor (x, y) in zip(val1, val2):\n\t\t\tresult |= (x ^ y)\n\telse:\n\t\tfor (x, y) in zip(val1, val2):\n\t\t\tresult |= (ord(x) ^ ord(y))\n\treturn (result == 0)\n","returns true if the two strings are equal ."] (predictor.py:56, main())
[2020-11-20 23:27:13]    INFO >> ["def detectLinuxBrokenPipeBehavior():\n\t(r, w) = os.pipe()\n\tos.write(w, 'a')\n\t(reads, writes, exes) = select.select([w], [], [], 0)\n\tif reads:\n\t\tbrokenPipeBehavior = True\n\telse:\n\t\tbrokenPipeBehavior = False\n\tos.close(r)\n\tos.close(w)\n\treturn brokenPipeBehavior\n","on some linux version ."] (predictor.py:56, main())
[2020-11-20 23:27:14]    INFO >> ["def decode_params_utf8(params):\n\tdecoded = []\n\tfor (k, v) in params:\n\t\tdecoded.append(((k.decode('utf-8') if isinstance(k, str) else k), (v.decode('utf-8') if isinstance(v, str) else v)))\n\treturn decoded\n","ensures that all parameters in a list of 2-element tuples are decoded to unicode using utf-8 ."] (predictor.py:56, main())
[2020-11-20 23:27:16]    INFO >> ["def run_proxy(port=8080, start_ioloop=True):\n\tapp = tornado.web.Application([('.*', ProxyHandler)])\n\tapp.listen(port, address='127.0.0.1')\n\tioloop = tornado.ioloop.IOLoop.instance()\n\tif start_ioloop:\n\t\tioloop.start()\n","run proxy on the specified port ."] (predictor.py:56, main())
[2020-11-20 23:27:16]    INFO >> ["def test_rgb_to_hsl_part_8():\n\tassert (rgb_to_hsl(153, 153, 102) == (60, 20, 50))\n\tassert (rgb_to_hsl(204, 204, 51) == (60, 60, 50))\n\tassert (rgb_to_hsl(255, 255, 0) == (60, 100, 50))\n","test rgb to hsl color function ."] (predictor.py:56, main())
[2020-11-20 23:27:16]    INFO >> ["def mean(x, axis=None, keepdims=False):\n\taxis = _normalize_axis(axis, ndim(x))\n\tif (x.dtype.base_dtype == tf.bool):\n\t\tx = tf.cast(x, floatx())\n\treturn tf.reduce_mean(x, reduction_indices=axis, keep_dims=keepdims)\n","mean of a tensor ."] (predictor.py:56, main())
[2020-11-20 23:27:17]    INFO >> ["def getopenfilename(parent=None, caption='', basedir='', filters='', selectedfilter='', options=None):\n\treturn _qfiledialog_wrapper('getOpenFileName', parent=parent, caption=caption, basedir=basedir, filters=filters, selectedfilter=selectedfilter, options=options)\n","wrapper around qtgui ."] (predictor.py:56, main())
[2020-11-20 23:27:18]    INFO >> ["def tempfilepager(text, cmd):\n\timport tempfile\n\tfilename = tempfile.mktemp()\n\tfile = open(filename, 'w')\n\tfile.write(_encode(text))\n\tfile.close()\n\ttry:\n\t\tos.system((((cmd + '\t\"') + filename) + '\"'))\n\tfinally:\n\t\tos.unlink(filename)\n","page through text by invoking a program on a temporary file ."] (predictor.py:56, main())
[2020-11-20 23:27:19]    INFO >> ["def modify_acl_group(id, **data):\n\tgroup = models.AclGroup.smart_get(id)\n\tgroup.check_for_acl_violation_acl_group()\n\tgroup.update_object(data)\n\tgroup.add_current_user_if_empty()\n","modify acl group ."] (predictor.py:56, main())
[2020-11-20 23:27:20]    INFO >> ["def python_2_unicode_compatible(klass):\n\tif (not six.PY3):\n\t\tklass.__unicode__ = klass.__str__\n\t\tklass.__str__ = (lambda self: self.__unicode__().encode(u'utf-8'))\n\treturn klass\n","a decorator that defines __unicode__ and __str__ methods under python 2 ."] (predictor.py:56, main())
[2020-11-20 23:27:21]    INFO >> ["def _has_required_boto():\n\tif (not HAS_BOTO):\n\t\treturn False\n\telif (LooseVersion(boto.__version__) < LooseVersion(required_boto_version)):\n\t\treturn False\n\telse:\n\t\treturn True\n","returns true\/false boolean depending on if boto is installed and correct version ."] (predictor.py:56, main())
[2020-11-20 23:27:21]    INFO >> ["def _count_righthand_zero_bits(number, bits):\n\tif (number == 0):\n\t\treturn bits\n\tfor i in range(bits):\n\t\tif ((number >> i) & 1):\n\t\t\treturn i\n\treturn bits\n","count the number of zero bits on the right hand side ."] (predictor.py:56, main())
[2020-11-20 23:27:22]    INFO >> ["def getOverhangSpan(elementNode):\n\treturn getCascadeFloatWithoutSelf((2.0 * getLayerHeight(elementNode)), elementNode, 'overhangSpan')\n","get the overhang span ."] (predictor.py:56, main())
[2020-11-20 23:27:22]    INFO >> ["def setlocale(category, locale=None):\n\tif (locale and (not isinstance(locale, _builtin_str))):\n\t\tlocale = normalize(_build_localename(locale))\n\treturn _setlocale(category, locale)\n","set the locale for the given category ."] (predictor.py:56, main())
[2020-11-20 23:27:22]    INFO >> ["def test_rus_sample_wt_fit():\n\trus = RandomUnderSampler(random_state=RND_SEED)\n\tassert_raises(RuntimeError, rus.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:27:23]    INFO >> ["def _ip_bridge_cmd(action, params, device):\n\tcmd = ['ip', 'addr', action]\n\tcmd.extend(params)\n\tcmd.extend(['dev', device])\n\treturn cmd\n","build commands to add\/del ips to bridges\/devices ."] (predictor.py:56, main())
[2020-11-20 23:27:23]    INFO >> ["def instance_floating_address_get_all(context, instance_uuid):\n\treturn IMPL.instance_floating_address_get_all(context, instance_uuid)\n","get all floating ip addresses of an instance ."] (predictor.py:56, main())
[2020-11-20 23:27:24]    INFO >> ["def update_last_login(sender, user, **kwargs):\n\tuser.last_login = timezone.now()\n\tuser.save()\n","a signal receiver which updates the last_login date for the user logging in ."] (predictor.py:56, main())
[2020-11-20 23:27:24]    INFO >> ["def _copy_array_if_base_present(a):\n\tif (a.base is not None):\n\t\treturn a.copy()\n\treturn a\n","copies the array if its base points to a parent array ."] (predictor.py:56, main())
[2020-11-20 23:27:25]    INFO >> ["def DEFINE_bool(name, default, help):\n\tCONFIG.AddOption(type_info.Bool(name=name, default=default, description=help))\n","a helper for defining boolean options ."] (predictor.py:56, main())
[2020-11-20 23:27:25]    INFO >> ["def _read_int32(f):\n\treturn np.int32(struct.unpack('>i', f.read(4))[0])\n","read a signed 32-bit integer ."] (predictor.py:56, main())
[2020-11-20 23:27:26]    INFO >> ["def render_comment_form(parser, token):\n\treturn RenderCommentFormNode.handle_token(parser, token)\n","render the comment form through the comments\/form ."] (predictor.py:56, main())
[2020-11-20 23:27:26]    INFO >> ["def strip_entities(value):\n\treturn re.sub('&(?:\\\\w+|#\\\\d);', '', value)\n","returns the given html with all entities stripped ."] (predictor.py:56, main())
[2020-11-20 23:27:26]    INFO >> ["def isXQuartz():\n\tassert (_tk_type is not None)\n\treturn (_tk_type == 'xquartz')\n","returns true if idle is using an os x x11 tk ."] (predictor.py:56, main())
[2020-11-20 23:27:27]    INFO >> ["def snapshot_destroy(context, snapshot_id):\n\treturn IMPL.snapshot_destroy(context, snapshot_id)\n","destroy the snapshot or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:27:27]    INFO >> ["def provide_worker_fake_entries(group):\n\treturn _WORKER_FAKE_ENTRIES.get(group, [])\n","give a set of fake entries for known groups ."] (predictor.py:56, main())
[2020-11-20 23:27:27]    INFO >> ["def get_disk_size(path, format=None):\n\tsize = images.qemu_img_info(path, format).virtual_size\n\treturn int(size)\n","get the size of a disk image ."] (predictor.py:56, main())
[2020-11-20 23:27:27]    INFO >> ["def processElementNode(elementNode):\n\tpath.convertElementNode(elementNode, getGeometryOutput(None, elementNode))\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:27:28]    INFO >> ["def _isDefaultHandler():\n\treturn (signal.getsignal(signal.SIGCHLD) == signal.SIG_DFL)\n","determine whether the i{sigchld} handler is the default or not ."] (predictor.py:56, main())
[2020-11-20 23:27:29]    INFO >> ["def answer():\n\toutput = s3_rest_controller()\n\treturn output\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:27:29]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:27:30]    INFO >> ["def getGeometryOutput(elementNode):\n\tderivation = HeightmapDerivation(elementNode)\n\theightGrid = derivation.heightGrid\n\tif (derivation.fileName != ''):\n\t\theightGrid = getHeightGrid(archive.getAbsoluteFolderPath(elementNode.getOwnerDocument().fileName, derivation.fileName))\n\treturn getGeometryOutputByHeightGrid(derivation, elementNode, heightGrid)\n","get vector3 vertexes from attribute dictionary ."] (predictor.py:56, main())
[2020-11-20 23:27:31]    INFO >> ["def _goBooleanProxy(expression):\n\tinitTechnique(kb.technique)\n\tif conf.dnsName:\n\t\tquery = agent.prefixQuery(kb.injection.data[kb.technique].vector)\n\t\tquery = agent.suffixQuery(query)\n\t\tpayload = agent.payload(newValue=query)\n\t\toutput = _goDns(payload, expression)\n\t\tif (output is not None):\n\t\t\treturn output\n\tvector = kb.injection.data[kb.technique].vector\n\tvector = vector.replace('[INFERENCE]', expression)\n\tquery = agent.prefixQuery(vector)\n\tquery = agent.suffixQuery(query)\n\tpayload = agent.payload(newValue=query)\n\ttimeBasedCompare = (kb.technique in (PAYLOAD.TECHNIQUE.TIME, PAYLOAD.TECHNIQUE.STACKED))\n\toutput = hashDBRetrieve(expression, checkConf=True)\n\tif (output is None):\n\t\toutput = Request.queryPage(payload, timeBasedCompare=timeBasedCompare, raise404=False)\n\t\tif (output is not None):\n\t\t\thashDBWrite(expression, output)\n\treturn output\n","retrieve the output of a boolean based sql query ."] (predictor.py:56, main())
[2020-11-20 23:27:32]    INFO >> ["def geo_apps(namespace=True, runtests=False):\n\tfrom django.db import connection\n\tfrom django.contrib.gis.geos import GEOS_PREPARE\n\tfrom django.contrib.gis.gdal import HAS_GDAL\n\tapps = ['geoapp', 'relatedapp']\n\tif (not connection.ops.mysql):\n\t\tapps.append('distapp')\n\tif (connection.ops.postgis and connection.ops.geography):\n\t\tapps.append('geogapp')\n\tif HAS_GDAL:\n\t\tif (connection.ops.postgis and GEOS_PREPARE):\n\t\t\tapps.append('geo3d')\n\t\tapps.append('layermap')\n\tif runtests:\n\t\treturn [('django.contrib.gis.tests', app) for app in apps]\n\telif namespace:\n\t\treturn [('django.contrib.gis.tests.%s' % app) for app in apps]\n\telse:\n\t\treturn apps\n","returns a list of geodjango test applications that reside in django ."] (predictor.py:56, main())
[2020-11-20 23:27:33]    INFO >> ["def declarative_base(bind=None, metadata=None, mapper=None, cls=object, name='Base', constructor=_declarative_constructor, class_registry=None, metaclass=DeclarativeMeta):\n\tlcl_metadata = (metadata or MetaData())\n\tif bind:\n\t\tlcl_metadata.bind = bind\n\tif (class_registry is None):\n\t\tclass_registry = weakref.WeakValueDictionary()\n\tbases = (((not isinstance(cls, tuple)) and (cls,)) or cls)\n\tclass_dict = dict(_decl_class_registry=class_registry, metadata=lcl_metadata)\n\tif isinstance(cls, type):\n\t\tclass_dict['__doc__'] = cls.__doc__\n\tif constructor:\n\t\tclass_dict['__init__'] = constructor\n\tif mapper:\n\t\tclass_dict['__mapper_cls__'] = mapper\n\treturn metaclass(name, bases, class_dict)\n","construct a base class for declarative class definitions ."] (predictor.py:56, main())
[2020-11-20 23:27:34]    INFO >> ["def get_test_hooks(test_files, cfg, cov=None):\n\tresults = []\n\tdirs = set(map(os.path.dirname, test_files))\n\tfor dir in list(dirs):\n\t\tif (os.path.basename(dir) == 'ftests'):\n\t\t\tdirs.add(os.path.join(os.path.dirname(dir), 'tests'))\n\tdirs = list(dirs)\n\tdirs.sort()\n\tfor dir in dirs:\n\t\tfilename = os.path.join(dir, 'checks.py')\n\t\tif os.path.exists(filename):\n\t\t\tmodule = import_module(filename, cfg, tracer=tracer)\n\t\t\tif (cov is not None):\n\t\t\t\tcov.start()\n\t\t\thooks = module.test_hooks()\n\t\t\tif (cov is not None):\n\t\t\t\tcov.stop()\n\t\t\tresults.extend(hooks)\n\treturn results\n","returns a list of test hooks from a given list of test modules ."] (predictor.py:56, main())
[2020-11-20 23:27:35]    INFO >> ["def PBKDF1(password, salt, dkLen, count=1000, hashAlgo=None):\n\tif (not hashAlgo):\n\t\thashAlgo = SHA1\n\tpassword = tobytes(password)\n\tpHash = hashAlgo.new((password + salt))\n\tdigest = pHash.digest_size\n\tif (dkLen > digest):\n\t\traise TypeError(('Selected\thash\talgorithm\thas\ta\ttoo\tshort\tdigest\t(%d\tbytes).' % digest))\n\tif (len(salt) != 8):\n\t\traise ValueError(('Salt\tis\tnot\t8\tbytes\tlong\t(%d\tbytes\tinstead).' % len(salt)))\n\tfor i in xrange((count - 1)):\n\t\tpHash = pHash.new(pHash.digest())\n\treturn pHash.digest()[:dkLen]\n","derive one key from a password ."] (predictor.py:56, main())
[2020-11-20 23:27:35]    INFO >> ["def makeUnicode(text):\n\tif isinstance(text, str):\n\t\ttext = unicode(text, 'ISO-8859-1')\n\telif (not isinstance(text, unicode)):\n\t\ttry:\n\t\t\ttext = unicode(text)\n\t\texcept UnicodeError:\n\t\t\ttry:\n\t\t\t\ttext = str(text)\n\t\t\texcept Exception:\n\t\t\t\ttext = repr(text)\n\t\t\treturn makeUnicode(text)\n\ttext = regex_control_code.sub((lambda regs: controlchars[ord(regs.group(1))]), text)\n\ttext = re.sub('\\\\\\\\x0([0-7])(?=[^0-7]|$)', '\\\\\\\\\\\\1', text)\n\treturn text\n","convert text to printable unicode string ."] (predictor.py:56, main())
[2020-11-20 23:27:35]    INFO >> ["def dnn_gradinput3d(kerns, topgrad, img_shp, border_mode='valid', subsample=(1, 1, 1), conv_mode='conv'):\n\tctx_name = infer_context_name(kerns, topgrad)\n\tkerns = as_gpuarray_variable(kerns, ctx_name)\n\ttopgrad = as_gpuarray_variable(topgrad, ctx_name)\n\tkerns = gpu_contiguous(kerns)\n\ttopgrad = gpu_contiguous(topgrad)\n\timg_shp = as_tensor_variable(img_shp)\n\tdesc = gpu_dnn_conv_desc(border_mode=border_mode, subsample=subsample, conv_mode=conv_mode)(kerns.shape)\n\tout = gpu_alloc_empty(ctx_name, kerns.dtype)(*img_shp)\n\treturn gpu_dnn_conv_gradI()(kerns, topgrad, out, desc)\n","gpu convolution gradient with respect to input using cudnn from nvidia ."] (predictor.py:56, main())
[2020-11-20 23:27:36]    INFO >> ["def get_msvcr():\n\tmsc_pos = sys.version.find('MSC\tv.')\n\tif (msc_pos != (-1)):\n\t\tmsc_ver = sys.version[(msc_pos + 6):(msc_pos + 10)]\n\t\tif (msc_ver == '1300'):\n\t\t\treturn ['msvcr70']\n\t\telif (msc_ver == '1310'):\n\t\t\treturn ['msvcr71']\n\t\telif (msc_ver == '1400'):\n\t\t\treturn ['msvcr80']\n\t\telif (msc_ver == '1500'):\n\t\t\treturn ['msvcr90']\n\t\telif (msc_ver == '1600'):\n\t\t\treturn ['msvcr100']\n\t\telse:\n\t\t\traise ValueError(('Unknown\tMS\tCompiler\tversion\t%s\t' % msc_ver))\n","include the appropriate msvc runtime library if python was built with msvc 7 ."] (predictor.py:56, main())
[2020-11-20 23:27:37]    INFO >> ["def arithmeticEval(s):\n\tnode = ast.parse(s, mode=u'eval')\n\tdef _eval(node):\n\t\tif isinstance(node, ast.Expression):\n\t\t\treturn _eval(node.body)\n\t\telif isinstance(node, ast.Str):\n\t\t\treturn node.s\n\t\telif isinstance(node, ast.Num):\n\t\t\treturn node.n\n\t\telif isinstance(node, ast.BinOp):\n\t\t\treturn _binOps[type(node.op)](_eval(node.left), _eval(node.right))\n\t\telse:\n\t\t\traise Exception(u'Unsupported\ttype\t{}'.format(node))\n\treturn _eval(node.body)\n","a safe eval supporting basic arithmetic operations ."] (predictor.py:56, main())
[2020-11-20 23:27:38]    INFO >> ["def _NewDocumentFromPb(doc_pb):\n\tlang = None\n\tif doc_pb.has_language():\n\t\tlang = _DecodeUTF8(doc_pb.language())\n\treturn Document(doc_id=_DecodeUTF8(doc_pb.id()), fields=_NewFieldsFromPb(doc_pb.field_list()), language=lang, rank=doc_pb.order_id())\n","constructs a document from a document_pb ."] (predictor.py:56, main())
[2020-11-20 23:27:39]    INFO >> ["def test_call_accepts_func_kw_params_kw_types():\n\t@accepts(kw_1=int, kw_2=int, kw_3=int)\n\tdef foo(kw_1=5, kw_2=6, kw_3=7):\n\t\tpass\n\tt = time.time()\n\tfor i in range(0, 10000):\n\t\tfoo(5, 6, 7)\n\treturn (time.time() - t)\n","calling an accepts-checked function: kw params ."] (predictor.py:56, main())
[2020-11-20 23:27:40]    INFO >> ["def MGF1(mgfSeed, maskLen, hash):\n\tT = b('')\n\tfor counter in xrange(ceil_div(maskLen, hash.digest_size)):\n\t\tc = long_to_bytes(counter, 4)\n\t\ttry:\n\t\t\tT = (T + hash.new((mgfSeed + c)).digest())\n\t\texcept AttributeError:\n\t\t\tT = (T + Hash_new(hash, (mgfSeed + c)).digest())\n\tassert (len(T) >= maskLen)\n\treturn T[:maskLen]\n","mask generation function ."] (predictor.py:56, main())
[2020-11-20 23:27:40]    INFO >> ["@pytest.mark.network\ndef test_download_if_requested(script):\n\tresult = script.pip('install', 'INITools==0.1', '-d', '.', expect_error=True)\n\tassert ((Path('scratch') \/ 'INITools-0.1.tar.gz') in result.files_created)\n\tassert ((script.site_packages \/ 'initools') not in result.files_created)\n","it should download and not install if requested ."] (predictor.py:56, main())
[2020-11-20 23:27:41]    INFO >> ["def chop_traceback(tb, exclude_prefix=_UNITTEST_RE, exclude_suffix=_SQLA_RE):\n\tstart = 0\n\tend = (len(tb) - 1)\n\twhile ((start <= end) and exclude_prefix.search(tb[start])):\n\t\tstart += 1\n\twhile ((start <= end) and exclude_suffix.search(tb[end])):\n\t\tend -= 1\n\treturn tb[start:(end + 1)]\n","chop extraneous lines off beginning and end of a traceback ."] (predictor.py:56, main())
[2020-11-20 23:27:41]    INFO >> ["def dottedQuadToNum(ip):\n\timport socket, struct\n\ttry:\n\t\treturn struct.unpack('!L', socket.inet_aton(ip.strip()))[0]\n\texcept socket.error:\n\t\tif (ip.strip() == '255.255.255.255'):\n\t\t\treturn 4294967295L\n\t\telse:\n\t\t\traise ValueError(('Not\ta\tgood\tdotted-quad\tIP:\t%s' % ip))\n\treturn\n","convert decimal dotted quad string to long integer ."] (predictor.py:56, main())
[2020-11-20 23:27:42]    INFO >> ["def topic_list(request, slug, template_name='groups\/topics\/topic_list.html'):\n\tgroup = get_object_or_404(Group, slug=slug, is_active=True)\n\ttopic_list = GroupTopic.objects.filter(group=group, is_active=True)\n\treturn render(request, template_name, {'group': group, 'topic_list': topic_list})\n","returns a group topic list page ."] (predictor.py:56, main())
[2020-11-20 23:27:42]    INFO >> ["def is_unavailable_exception(e):\n\ttry:\n\t\tif ((e.errcode == (-1)) or (e.headers is None)):\n\t\t\treturn True\n\t\texc_mess = e.headers.get('X-exception')\n\texcept AttributeError:\n\t\texc_mess = str(e)\n\tif (exc_mess and ('temporarily\tunavailable' in exc_mess.lower())):\n\t\treturn True\n","returns true if the given protocolerror is the product of a server-side exception caused by the temporarily unavailable response sometimes given by operations on non-blocking sockets ."] (predictor.py:56, main())
[2020-11-20 23:27:43]    INFO >> ["def LoadYamlConfig(config_file_name):\n\t(loaders, exporters) = bulkloader_config.load_config(config_file_name, increment_id=IncrementId)\n\tfor cls in loaders:\n\t\tLoader.RegisterLoader(cls())\n\tfor cls in exporters:\n\t\tExporter.RegisterExporter(cls())\n","loads a config file and registers any loader classes present ."] (predictor.py:56, main())
[2020-11-20 23:27:43]    INFO >> ["def clean_url(url):\n\turl = url.encode('utf8')\n\turl = ''.join([(urllib.parse.quote(c) if (ord(c) >= 127) else c) for c in url.decode('utf-8')])\n\treturn url\n","url quotes unicode data out of urls ."] (predictor.py:56, main())
[2020-11-20 23:27:44]    INFO >> ["def compare_package(version1, version2):\n\tdef normalize(v):\n\t\treturn [int(x) for x in re.sub('(\\\\.0+)*$', '', v).split('.')]\n\treturn cmp(normalize(version1), normalize(version2))\n","compare version packages ."] (predictor.py:56, main())
[2020-11-20 23:27:44]    INFO >> ["def manhattan(rating1, rating2):\n\tdistance = 0\n\ttotal = 0\n\tfor key in rating1:\n\t\tif (key in rating2):\n\t\t\tdistance += abs((rating1[key] - rating2[key]))\n\t\t\ttotal += 1\n\tif (total > 0):\n\t\treturn (distance \/ total)\n\telse:\n\t\treturn (-1)\n","computes the manhattan distance ."] (predictor.py:56, main())
[2020-11-20 23:27:44]    INFO >> ["def overload_attribute(typ, attr):\n\tfrom .typing.templates import make_overload_attribute_template\n\tdef decorate(overload_func):\n\t\ttemplate = make_overload_attribute_template(typ, attr, overload_func)\n\t\tinfer_getattr(template)\n\t\treturn overload_func\n\treturn decorate\n","a decorator marking the decorated function as typing and implementing attribute *attr* for the given numba type in nopython mode ."] (predictor.py:56, main())
[2020-11-20 23:27:45]    INFO >> ["def onLoginAppReady():\n\tINFO_MSG(('onLoginAppReady:\tbootstrapGroupIndex=%s,\tbootstrapGlobalIndex=%s' % (os.getenv('KBE_BOOTIDX_GROUP'), os.getenv('KBE_BOOTIDX_GLOBAL'))))\n","kbengine method ."] (predictor.py:56, main())
[2020-11-20 23:27:45]    INFO >> ["def vary_on_cookie(func):\n\tdef inner_func(*args, **kwargs):\n\t\tresponse = func(*args, **kwargs)\n\t\tpatch_vary_headers(response, ('Cookie',))\n\t\treturn response\n\treturn inner_func\n","a view decorator that adds \"cookie\" to the vary header of a response ."] (predictor.py:56, main())
[2020-11-20 23:27:46]    INFO >> ["def _module_to_dict(module, omittable=(lambda k: k.startswith('_'))):\n\treturn dict([(k, repr(v)) for (k, v) in module.__dict__.items() if (not omittable(k))])\n","converts a module namespace to a python dictionary ."] (predictor.py:56, main())
[2020-11-20 23:27:46]    INFO >> ["def _get_zone(gcdns, zone_name, zone_id):\n\tif (zone_id is not None):\n\t\ttry:\n\t\t\treturn gcdns.get_zone(zone_id)\n\t\texcept ZoneDoesNotExistError:\n\t\t\treturn None\n\tavailable_zones = gcdns.iterate_zones()\n\tfound_zone = None\n\tfor zone in available_zones:\n\t\tif (zone.domain == zone_name):\n\t\t\tfound_zone = zone\n\t\t\tbreak\n\treturn found_zone\n","gets the zone object for a given domain name ."] (predictor.py:56, main())
[2020-11-20 23:27:47]    INFO >> ["def sql_indexes(app, style, connection):\n\toutput = []\n\tfor model in models.get_models(app, include_auto_created=True):\n\t\toutput.extend(connection.creation.sql_indexes_for_model(model, style))\n\treturn output\n","returns a list of the create index sql statements for all models in the given app ."] (predictor.py:56, main())
[2020-11-20 23:27:47]    INFO >> ["def rfc822_escape(header):\n\tlines = header.split('\\n')\n\tsep = ('\\n' + (8 * '\t'))\n\treturn sep.join(lines)\n","return a version of the string escaped for inclusion in an rfc-822 header ."] (predictor.py:56, main())
[2020-11-20 23:27:47]    INFO >> ["def _translate_attachment_summary_view(_context, vol):\n\td = {}\n\tconductor_id = vol['id']\n\td['id'] = conductor_id\n\td['conductor_id'] = conductor_id\n\treturn d\n","maps keys for attachment summary view ."] (predictor.py:56, main())
[2020-11-20 23:27:48]    INFO >> ["@require_context\ndef virtual_interface_get_by_uuid(context, vif_uuid):\n\tvif_ref = _virtual_interface_query(context).filter_by(uuid=vif_uuid).first()\n\treturn vif_ref\n","gets a virtual interface from the table ."] (predictor.py:56, main())
[2020-11-20 23:27:48]    INFO >> ["def encode_for_xml(ustr, encoding='ascii'):\n\tif isinstance(ustr, unicode):\n\t\tpass\n\telif isinstance(ustr, str):\n\t\tustr = ustr.decode(codepage, 'replace')\n\telse:\n\t\tustr = unicode(str(ustr))\n\treturn ustr.encode(encoding, 'xmlcharrefreplace')\n","encode unicode_data for use as xml or html ."] (predictor.py:56, main())
[2020-11-20 23:27:49]    INFO >> ["def network_get_associated_fixed_ips(context, network_id, host=None):\n\treturn IMPL.network_get_associated_fixed_ips(context, network_id, host)\n","get all networks ips that have been associated ."] (predictor.py:56, main())
[2020-11-20 23:27:49]    INFO >> ["def col(loc, strg):\n\treturn ((((loc < len(strg)) and (strg[loc] == '\\n')) and 1) or (loc - strg.rfind('\\n', 0, loc)))\n","returns current column within a string ."] (predictor.py:56, main())
[2020-11-20 23:27:49]    INFO >> ["def write_file(filename, contents):\n\tf = open(filename, 'w')\n\ttry:\n\t\tfor line in contents:\n\t\t\tf.write((line + '\\n'))\n\tfinally:\n\t\tf.close()\n","create a file with the specified name and write contents to it ."] (predictor.py:56, main())
[2020-11-20 23:27:50]    INFO >> ["def __hash_new(name, string=''):\n\ttry:\n\t\treturn _hashlib.new(name, string)\n\texcept ValueError:\n\t\treturn __get_builtin_constructor(name)(string)\n","new - return a new hashing object using the named algorithm; optionally initialized with a string ."] (predictor.py:56, main())
[2020-11-20 23:27:50]    INFO >> ["def quota_create(context, project_id, resource, limit, user_id=None):\n\treturn IMPL.quota_create(context, project_id, resource, limit, user_id=user_id)\n","create a quota for the given project and resource ."] (predictor.py:56, main())
[2020-11-20 23:27:51]    INFO >> ["def smart_split(text):\n\ttext = force_unicode(text)\n\tfor bit in smart_split_re.finditer(text):\n\t\t(yield bit.group(0))\n","generator that splits a string by spaces ."] (predictor.py:56, main())
[2020-11-20 23:27:51]    INFO >> ["def apply_optimizer(optimizer, func, a, b):\n\treturn (optimizer(func, a, b, full_output=True)[1].function_calls,)\n","return the number of function calls given an root-finding optimizer ."] (predictor.py:56, main())
[2020-11-20 23:27:51]    INFO >> ["def get_level(request):\n\tstorage = getattr(request, '_messages', default_storage(request))\n\treturn storage.level\n","returns the minimum level of messages to be recorded ."] (predictor.py:56, main())
[2020-11-20 23:27:52]    INFO >> ["def set_vif_host_backend_ethernet_config(conf, tapname):\n\tconf.net_type = 'ethernet'\n\tconf.target_dev = tapname\n\tconf.script = ''\n","populate a libvirtconfigguestinterface instance with host backend details for an externally configured host device ."] (predictor.py:56, main())
[2020-11-20 23:27:52]    INFO >> ["def do_forceescape(value):\n\tif hasattr(value, '__html__'):\n\t\tvalue = value.__html__()\n\treturn escape(text_type(value))\n","enforce html escaping ."] (predictor.py:56, main())
[2020-11-20 23:27:52]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:27:53]    INFO >> ["def out_of_date(original, derived):\n\treturn ((not os.path.exists(derived)) or (os.path.exists(original) and (os.stat(derived).st_mtime < os.stat(original).st_mtime)))\n","returns true if derivative is out-of-date wrt original ."] (predictor.py:56, main())
[2020-11-20 23:27:53]    INFO >> ["def index_alt():\n\ts3_redirect_default(URL(f='person'))\n","module homepage for non-admin users when no cms content found ."] (predictor.py:56, main())
[2020-11-20 23:27:53]    INFO >> ["def window_hanning(x):\n\treturn (np.hanning(len(x)) * x)\n","return x times the hanning window of len(x) ."] (predictor.py:56, main())
[2020-11-20 23:27:54]    INFO >> ["def _get_hub():\n\tglobal _threadlocal\n\ttry:\n\t\treturn _threadlocal.hub\n\texcept AttributeError:\n\t\tpass\n","return the hub for the current thread ."] (predictor.py:56, main())
[2020-11-20 23:27:54]    INFO >> ["def normcase(s):\n\treturn s\n","normalize case of pathname ."] (predictor.py:56, main())
[2020-11-20 23:27:55]    INFO >> ["def _sample_rois(roidb, fg_rois_per_image, rois_per_image, num_classes):\n\tlabels = roidb['max_classes']\n\toverlaps = roidb['max_overlaps']\n\trois = roidb['boxes']\n\tfg_inds = np.where((overlaps >= cfg.TRAIN.FG_THRESH))[0]\n\tfg_rois_per_this_image = np.minimum(fg_rois_per_image, fg_inds.size)\n\tif (fg_inds.size > 0):\n\t\tfg_inds = npr.choice(fg_inds, size=fg_rois_per_this_image, replace=False)\n\tbg_inds = np.where(((overlaps < cfg.TRAIN.BG_THRESH_HI) & (overlaps >= cfg.TRAIN.BG_THRESH_LO)))[0]\n\tbg_rois_per_this_image = (rois_per_image - fg_rois_per_this_image)\n\tbg_rois_per_this_image = np.minimum(bg_rois_per_this_image, bg_inds.size)\n\tif (bg_inds.size > 0):\n\t\tbg_inds = npr.choice(bg_inds, size=bg_rois_per_this_image, replace=False)\n\tkeep_inds = np.append(fg_inds, bg_inds)\n\tlabels = labels[keep_inds]\n\tlabels[fg_rois_per_this_image:] = 0\n\toverlaps = overlaps[keep_inds]\n\trois = rois[keep_inds]\n\t(bbox_targets, bbox_inside_weights) = _get_bbox_regression_labels(roidb['bbox_targets'][keep_inds, :], num_classes)\n\treturn (labels, overlaps, rois, bbox_targets, bbox_inside_weights)\n","generate a random sample of rois comprising foreground and background examples ."] (predictor.py:56, main())
[2020-11-20 23:27:56]    INFO >> ["def build_ffi_for_binding(module_name, module_prefix, modules, libraries=[], extra_compile_args=[], extra_link_args=[]):\n\ttypes = []\n\tincludes = []\n\tfunctions = []\n\tmacros = []\n\tcustomizations = []\n\tfor name in modules:\n\t\t__import__((module_prefix + name))\n\t\tmodule = sys.modules[(module_prefix + name)]\n\t\ttypes.append(module.TYPES)\n\t\tmacros.append(module.MACROS)\n\t\tfunctions.append(module.FUNCTIONS)\n\t\tincludes.append(module.INCLUDES)\n\t\tcustomizations.append(module.CUSTOMIZATIONS)\n\tverify_source = '\\n'.join(((includes + functions) + customizations))\n\tffi = build_ffi(module_name, cdef_source='\\n'.join(((types + functions) + macros)), verify_source=verify_source, libraries=libraries, extra_compile_args=extra_compile_args, extra_link_args=extra_link_args)\n\treturn ffi\n","modules listed in modules should have the following attributes: * includes: a string containing c includes ."] (predictor.py:56, main())
[2020-11-20 23:27:57]    INFO >> ["def plot_img_and_hist(img, axes, bins=256):\n\t(ax_img, ax_hist) = axes\n\tax_cdf = ax_hist.twinx()\n\tax_img.imshow(img, cmap=plt.cm.gray)\n\tax_img.set_axis_off()\n\tax_hist.hist(img.ravel(), bins=bins)\n\tax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n\tax_hist.set_xlabel('Pixel\tintensity')\n\t(xmin, xmax) = dtype_range[img.dtype.type]\n\tax_hist.set_xlim(xmin, xmax)\n\t(img_cdf, bins) = exposure.cumulative_distribution(img, bins)\n\tax_cdf.plot(bins, img_cdf, 'r')\n\treturn (ax_img, ax_hist, ax_cdf)\n","plot an image along with its histogram and cumulative histogram ."] (predictor.py:56, main())
[2020-11-20 23:27:57]    INFO >> ["@docstring.dedent_interpd\ndef cohere(x, y, NFFT=256, Fs=2, detrend=detrend_none, window=window_hanning, noverlap=0, pad_to=None, sides=u'default', scale_by_freq=None):\n\tif (len(x) < (2 * NFFT)):\n\t\traise ValueError(_coh_error)\n\t(Pxx, f) = psd(x, NFFT, Fs, detrend, window, noverlap, pad_to, sides, scale_by_freq)\n\t(Pyy, f) = psd(y, NFFT, Fs, detrend, window, noverlap, pad_to, sides, scale_by_freq)\n\t(Pxy, f) = csd(x, y, NFFT, Fs, detrend, window, noverlap, pad_to, sides, scale_by_freq)\n\tCxy = ((np.abs(Pxy) ** 2) \/ (Pxx * Pxy))\n\treturn (Cxy, f)\n","the coherence between *x* and *y* ."] (predictor.py:56, main())
[2020-11-20 23:27:58]    INFO >> ["def test_rgb_to_hsl_part_17():\n\tassert (rgb_to_hsl(0, 0, 51) == (240, 100, 10))\n\tassert (rgb_to_hsl(0, 0, 102) == (240, 100, 20))\n\tassert (rgb_to_hsl(0, 0, 153) == (240, 100, 30))\n\tassert (rgb_to_hsl(0, 0, 204) == (240, 100, 40))\n\tassert (rgb_to_hsl(0, 0, 255) == (240, 100, 50))\n\tassert (rgb_to_hsl(51, 51, 255) == (240, 100, 60))\n\tassert (rgb_to_hsl(102, 102, 255) == (240, 100, 70))\n\tassert (rgb_to_hsl(153, 153, 255) == (240, 100, 80))\n\tassert (rgb_to_hsl(204, 204, 255) == (240, 100, 90))\n","test rgb to hsl color function ."] (predictor.py:56, main())
[2020-11-20 23:27:58]    INFO >> ["def addAlreadyFilledArounds(alreadyFilledArounds, loop, radius):\n\tradius = abs(radius)\n\talreadyFilledLoop = []\n\tslightlyGreaterThanRadius = (1.01 * radius)\n\tmuchGreaterThanRadius = (2.5 * radius)\n\tcenters = intercircle.getCentersFromLoop(loop, slightlyGreaterThanRadius)\n\tfor center in centers:\n\t\talreadyFilledInset = intercircle.getSimplifiedInsetFromClockwiseLoop(center, radius)\n\t\tif intercircle.isLargeSameDirection(alreadyFilledInset, center, radius):\n\t\t\talreadyFilledLoop.append(alreadyFilledInset)\n\tif (len(alreadyFilledLoop) > 0):\n\t\talreadyFilledArounds.append(alreadyFilledLoop)\n","add already filled loops around loop to alreadyfilledarounds ."] (predictor.py:56, main())
[2020-11-20 23:28:00]    INFO >> ["def select(rlist, wlist, xlist, timeout=None):\n\tallevents = []\n\ttimeout = Timeout.start_new(timeout)\n\tresult = SelectResult()\n\ttry:\n\t\ttry:\n\t\t\tfor readfd in rlist:\n\t\t\t\tallevents.append(core.read_event(get_fileno(readfd), result.update, arg=readfd))\n\t\t\tfor writefd in wlist:\n\t\t\t\tallevents.append(core.write_event(get_fileno(writefd), result.update, arg=writefd))\n\t\texcept IOError as ex:\n\t\t\traise error(*ex.args)\n\t\tresult.event.wait(timeout=timeout)\n\t\treturn (result.read, result.write, [])\n\tfinally:\n\t\tfor evt in allevents:\n\t\t\tevt.cancel()\n\t\ttimeout.cancel()\n","an implementation of :meth:select ."] (predictor.py:56, main())
[2020-11-20 23:28:00]    INFO >> ["def load_handler(path, *args, **kwargs):\n\ti = path.rfind(u'.')\n\t(module, attr) = (path[:i], path[(i + 1):])\n\ttry:\n\t\tmod = importlib.import_module(module)\n\texcept ImportError as e:\n\t\traise ImproperlyConfigured((u'Error\timporting\tupload\thandler\tmodule\t%s:\t\"%s\"' % (module, e)))\n\texcept ValueError:\n\t\traise ImproperlyConfigured(u'Error\timporting\tupload\thandler\tmodule.Is\tFILE_UPLOAD_HANDLERS\ta\tcorrectly\tdefined\tlist\tor\ttuple?')\n\ttry:\n\t\tcls = getattr(mod, attr)\n\texcept AttributeError:\n\t\traise ImproperlyConfigured((u'Module\t\"%s\"\tdoes\tnot\tdefine\ta\t\"%s\"\tupload\thandler\tbackend' % (module, attr)))\n\treturn cls(*args, **kwargs)\n","given a path to a handler ."] (predictor.py:56, main())
[2020-11-20 23:28:01]    INFO >> ["def get_resource_manager_extra_kwargs(f, args, allow_conflicts=False):\n\thooks = getattr(f, 'resource_manager_kwargs_hooks', [])\n\textra_kwargs = {}\n\tfor hook in hooks:\n\t\thook_name = hook.__name__\n\t\thook_kwargs = hook(args)\n\t\tconflicting_keys = (set(hook_kwargs.keys()) & set(extra_kwargs.keys()))\n\t\tif (conflicting_keys and (not allow_conflicts)):\n\t\t\traise Exception((\"Hook\t'%(hook_name)s'\tis\tattempting\tto\tredefine\tattributes\t'%(conflicting_keys)s'\" % locals()))\n\t\textra_kwargs.update(hook_kwargs)\n\treturn extra_kwargs\n","return extra_kwargs by calling resource manager kwargs hooks ."] (predictor.py:56, main())
[2020-11-20 23:28:01]    INFO >> ["def _dynamic_max_trials(n_inliers, n_samples, min_samples, probability):\n\tinlier_ratio = (n_inliers \/ float(n_samples))\n\tnom = max(_EPSILON, (1 - probability))\n\tdenom = max(_EPSILON, (1 - (inlier_ratio ** min_samples)))\n\tif (nom == 1):\n\t\treturn 0\n\tif (denom == 1):\n\t\treturn float('inf')\n\treturn abs(float(np.ceil((np.log(nom) \/ np.log(denom)))))\n","determine number trials such that at least one outlier-free subset is sampled for the given inlier\/outlier ratio ."] (predictor.py:56, main())
[2020-11-20 23:28:02]    INFO >> ["def url_params_from_lookup_dict(lookups):\n\tparams = {}\n\tif (lookups and hasattr(lookups, u'items')):\n\t\titems = []\n\t\tfor (k, v) in lookups.items():\n\t\t\tif callable(v):\n\t\t\t\tv = v()\n\t\t\tif isinstance(v, (tuple, list)):\n\t\t\t\tv = u','.join([str(x) for x in v])\n\t\t\telif isinstance(v, bool):\n\t\t\t\tv = (u'0', u'1')[v]\n\t\t\telse:\n\t\t\t\tv = six.text_type(v)\n\t\t\titems.append((k, v))\n\t\tparams.update(dict(items))\n\treturn params\n","converts the type of lookups specified in a foreignkey limit_choices_to attribute to a dictionary of query parameters ."] (predictor.py:56, main())
[2020-11-20 23:28:02]    INFO >> ["def html_body(input_string, source_path=None, destination_path=None, input_encoding='unicode', output_encoding='unicode', doctitle=True, initial_header_level=1):\n\tparts = html_parts(input_string=input_string, source_path=source_path, destination_path=destination_path, input_encoding=input_encoding, doctitle=doctitle, initial_header_level=initial_header_level)\n\tfragment = parts['html_body']\n\tif (output_encoding != 'unicode'):\n\t\tfragment = fragment.encode(output_encoding)\n\treturn fragment\n","given an input string ."] (predictor.py:56, main())
[2020-11-20 23:28:03]    INFO >> ["def _syscmd_file(target, default=''):\n\tif (sys.platform in ('dos', 'win32', 'win16', 'os2')):\n\t\treturn default\n\ttarget = _follow_symlinks(target)\n\ttry:\n\t\tf = os.popen(('file\t\"%s\"\t2>\t\/dev\/null' % target))\n\texcept (AttributeError, os.error):\n\t\treturn default\n\toutput = string.strip(f.read())\n\trc = f.close()\n\tif ((not output) or rc):\n\t\treturn default\n\telse:\n\t\treturn output\n","interface to the systems file command ."] (predictor.py:56, main())
[2020-11-20 23:28:03]    INFO >> ["def headers_to_account_info(headers, status_int=HTTP_OK):\n\t(headers, meta, sysmeta) = _prep_headers_to_info(headers, 'account')\n\taccount_info = {'status': status_int, 'container_count': headers.get('x-account-container-count'), 'total_object_count': headers.get('x-account-object-count'), 'bytes': headers.get('x-account-bytes-used'), 'meta': meta, 'sysmeta': sysmeta}\n\tif is_success(status_int):\n\t\taccount_info['account_really_exists'] = (not config_true_value(headers.get('x-backend-fake-account-listing')))\n\treturn account_info\n","construct a cacheable dict of account info based on response headers ."] (predictor.py:56, main())
[2020-11-20 23:28:04]    INFO >> ["def format_histograms(raw_hist, pre_hist, post_hist, bin_edges):\n\tlines = []\n\tlines.append('#\tbins\traw\tsequence\tlengths,\tlength\tof\tsequences\tthat\tpass\tquality\tfilters\tbefore\tprocessing,\tand\tlengths\tof\tsequences\tthat\tpass\tquality\tfilters\tpost\tprocessing.')\n\tlines.append('Length DCTB Raw DCTB Before DCTB After')\n\tfor (edge, raw, pre, post) in zip(bin_edges, raw_hist, pre_hist, post_hist):\n\t\tlines.append(' DCTB '.join(map(str, [edge, raw, pre, post])))\n\treturn '\\n'.join(lines)\n","returns text-formatted histogram ."] (predictor.py:56, main())
[2020-11-20 23:28:04]    INFO >> ["def text_repr(value):\n\ttry:\n\t\treturn pydoc.text.repr(value)\n\texcept KeyboardInterrupt:\n\t\traise\n\texcept:\n\t\ttry:\n\t\t\treturn repr(value)\n\t\texcept KeyboardInterrupt:\n\t\t\traise\n\t\texcept:\n\t\t\ttry:\n\t\t\t\tname = getattr(value, '__name__', None)\n\t\t\t\tif name:\n\t\t\t\t\treturn text_repr(name)\n\t\t\t\tklass = getattr(value, '__class__', None)\n\t\t\t\tif klass:\n\t\t\t\t\treturn ('%s\tinstance' % text_repr(klass))\n\t\t\texcept KeyboardInterrupt:\n\t\t\t\traise\n\t\t\texcept:\n\t\t\t\treturn 'UNRECOVERABLE\tREPR\tFAILURE'\n","hopefully pretty robust repr equivalent ."] (predictor.py:56, main())
[2020-11-20 23:28:04]    INFO >> ["def manhattan_distances(X, Y):\n\tif (X is Y):\n\t\tX = Y = np.asanyarray(X)\n\telse:\n\t\tX = np.asanyarray(X)\n\t\tY = np.asanyarray(Y)\n\tif (X.shape[1] != Y.shape[1]):\n\t\traise ValueError('Incompatible\tdimension\tfor\tX\tand\tY\tmatrices')\n\tXY = ssd.cdist(X, Y, 'cityblock')\n\treturn (1.0 - (XY \/ float(X.shape[1])))\n","considering the rows of x as vectors ."] (predictor.py:56, main())
[2020-11-20 23:28:05]    INFO >> ["def create_bootstrap_script(extra_text, python_version=''):\n\tfilename = __file__\n\tif filename.endswith('.pyc'):\n\t\tfilename = filename[:(-1)]\n\twith codecs.open(filename, 'r', encoding='utf-8') as f:\n\t\tcontent = f.read()\n\tpy_exe = ('python%s' % python_version)\n\tcontent = ((('#!\/usr\/bin\/env\t%s\\n' % py_exe) + '##\tWARNING:\tThis\tfile\tis\tgenerated\\n') + content)\n\treturn content.replace('##EXTEND##', extra_text)\n","creates a bootstrap script ."] (predictor.py:56, main())
[2020-11-20 23:28:05]    INFO >> ["def make_image_dict(image):\n\tdef _fetch_attrs(d, attrs):\n\t\treturn dict([(a, d[a]) for a in attrs if (a in d.keys())])\n\tproperties = dict(((p['name'], p['value']) for p in image['properties'] if (not p['deleted'])))\n\timage_dict = _fetch_attrs(image, glance.db.IMAGE_ATTRS)\n\timage_dict['properties'] = properties\n\t_limit_locations(image_dict)\n\treturn image_dict\n","create a dict representation of an image which we can use to serialize the image ."] (predictor.py:56, main())
[2020-11-20 23:28:06]    INFO >> ["def render_value_in_context(value, context):\n\tvalue = template_localtime(value, use_tz=context.use_tz)\n\tvalue = localize(value, use_l10n=context.use_l10n)\n\tvalue = force_text(value)\n\tif ((context.autoescape and (not isinstance(value, SafeData))) or isinstance(value, EscapeData)):\n\t\treturn escape(value)\n\telse:\n\t\treturn value\n","converts any value to a string to become part of a rendered template ."] (predictor.py:56, main())
[2020-11-20 23:28:07]    INFO >> ["def widthratio(parser, token):\n\tbits = token.contents.split()\n\tif (len(bits) != 4):\n\t\traise TemplateSyntaxError('widthratio\ttakes\tthree\targuments')\n\t(tag, this_value_expr, max_value_expr, max_width) = bits\n\treturn WidthRatioNode(parser.compile_filter(this_value_expr), parser.compile_filter(max_value_expr), parser.compile_filter(max_width))\n","for creating bar charts and such ."] (predictor.py:56, main())
[2020-11-20 23:28:07]    INFO >> ["def _AddClearFieldMethod(message_descriptor, cls):\n\tdef ClearField(self, field_name):\n\t\ttry:\n\t\t\tfield = message_descriptor.fields_by_name[field_name]\n\t\texcept KeyError:\n\t\t\traise ValueError(('Protocol\tmessage\thas\tno\t\"%s\"\tfield.' % field_name))\n\t\tif (field in self._fields):\n\t\t\tdel self._fields[field]\n\t\tself._Modified()\n\tcls.ClearField = ClearField\n","helper for _addmessagemethods() ."] (predictor.py:56, main())
[2020-11-20 23:28:08]    INFO >> ["def UnregisterNamedPath(name):\n\tkeyStr = ((BuildDefaultPythonKey() + '\\\\PythonPath\\\\') + name)\n\ttry:\n\t\twin32api.RegDeleteKey(GetRootKey(), keyStr)\n\texcept win32api.error as (code, fn, details):\n\t\timport winerror\n\t\tif (code != winerror.ERROR_FILE_NOT_FOUND):\n\t\t\traise win32api.error, (code, fn, desc)\n\t\treturn\n","unregister a named path - ie ."] (predictor.py:56, main())
[2020-11-20 23:28:08]    INFO >> ["def test_nm2_sample_wrong_X():\n\tnm2 = NearMiss(random_state=RND_SEED, version=VERSION_NEARMISS)\n\tnm2.fit(X, Y)\n\tassert_raises(RuntimeError, nm2.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:28:08]    INFO >> ["def get_random_string(length=12, allowed_chars=u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'):\n\tif (not using_sysrandom):\n\t\trandom.seed(hashlib.sha256((u'%s%s%s' % (random.getstate(), time.time(), settings.SECRET_KEY)).encode(u'utf-8')).digest())\n\treturn u''.join([random.choice(allowed_chars) for i in range(length)])\n","returns a securely generated random string ."] (predictor.py:56, main())
[2020-11-20 23:28:09]    INFO >> ["def action_peek_json(body):\n\ttry:\n\t\tdecoded = jsonutils.loads(body)\n\texcept ValueError:\n\t\tmsg = _('cannot\tunderstand\tJSON')\n\t\traise exception.MalformedRequestBody(reason=msg)\n\tif (len(decoded) != 1):\n\t\tmsg = _('too\tmany\tbody\tkeys')\n\t\traise exception.MalformedRequestBody(reason=msg)\n\treturn list(decoded.keys())[0]\n","determine action to invoke ."] (predictor.py:56, main())
[2020-11-20 23:28:10]    INFO >> ["def instance_update(context, instance_uuid, values, update_cells=True):\n\trv = IMPL.instance_update(context, instance_uuid, values)\n\tif update_cells:\n\t\ttry:\n\t\t\tcells_rpcapi.CellsAPI().instance_update_at_top(context, rv)\n\t\texcept Exception:\n\t\t\tLOG.exception(_('Failed\tto\tnotify\tcells\tof\tinstance\tupdate'))\n\treturn rv\n","set the given properties on an instance and update it ."] (predictor.py:56, main())
[2020-11-20 23:28:10]    INFO >> ["def register_filter(f):\n\tif (not issubclass(f, Filter)):\n\t\traise ValueError(\"Must\tbe\ta\tsubclass\tof\t'Filter'\")\n\tif (not f.name):\n\t\traise ValueError('Must\thave\ta\tname')\n\tif (f.name in _FILTERS):\n\t\traise KeyError(('Filter\twith\tname\t%s\talready\tregistered' % f.name))\n\t_FILTERS[f.name] = f\n","add the given filter to the list of know filters ."] (predictor.py:56, main())
[2020-11-20 23:28:11]    INFO >> ["def split_into(n, type, value):\n\tparts = map((lambda x: x.strip()), value.split(';', (n - 1)))\n\tif (sum((1 for part in parts if part)) < n):\n\t\traise ValueError(('invalid\t%s\tindex\tentry\t%r' % (type, value)))\n\treturn parts\n","split an index entry into a given number of parts at semicolons ."] (predictor.py:56, main())
[2020-11-20 23:28:11]    INFO >> ["def libvlc_new(argc, argv):\n\tf = (_Cfunctions.get('libvlc_new', None) or _Cfunction('libvlc_new', ((1,), (1,)), class_result(Instance), ctypes.c_void_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p)))\n\treturn f(argc, argv)\n","create and initialize a libvlc instance ."] (predictor.py:56, main())
[2020-11-20 23:28:13]    INFO >> ["def padTo(n, seq, default=None):\n\tif (len(seq) > n):\n\t\traise ValueError(('%d\telements\tis\tmore\tthan\t%d.' % (len(seq), n)))\n\tblank = ([default] * n)\n\tblank[:len(seq)] = list(seq)\n\treturn blank\n","pads a sequence out to n elements ."] (predictor.py:56, main())
[2020-11-20 23:28:13]    INFO >> ["def _a_encode_unicode(value, mapping):\n\tassert isinstance(value, unicode), ('VALUE\thas\tinvalid\ttype:\t%s' % type(value))\n\tvalue = value.encode('UTF-8')\n\treturn (str(len(value)).encode('UTF-8'), 's', value)\n","foo-bar --> ."] (predictor.py:56, main())
[2020-11-20 23:28:14]    INFO >> ["def addToMenu(master, menu, repository, window):\n\tmetaFilePath = archive.getSkeinforgePluginsPath('meta.py')\n\tsettings.addPluginsParentToMenu(skeinforge_meta.getPluginsDirectoryPath(), menu, metaFilePath, skeinforge_meta.getPluginFileNames())\n","add a tool plugin menu ."] (predictor.py:56, main())
[2020-11-20 23:28:14]    INFO >> ["def randomRange(start=0, stop=1000, seed=None):\n\tif (seed is not None):\n\t\t_ = getCurrentThreadData().random\n\t\t_.seed(seed)\n\t\trandint = _.randint\n\telse:\n\t\trandint = random.randint\n\treturn int(randint(start, stop))\n","returns random integer value in given range ."] (predictor.py:56, main())
[2020-11-20 23:28:15]    INFO >> ["def metadef_resource_type_get(context, resource_type_name, session=None):\n\tsession = (session or get_session())\n\treturn metadef_resource_type_api.get(context, resource_type_name, session)\n","get a resource_type ."] (predictor.py:56, main())
[2020-11-20 23:28:15]    INFO >> ["def unregister_models(engine):\n\tmodels = (ArtifactDependency, ArtifactBlobLocation, ArtifactBlob, ArtifactProperty, ArtifactTag, Artifact)\n\tfor model in models:\n\t\tmodel.metadata.drop_all(engine)\n","drop database tables for all models with the given engine ."] (predictor.py:56, main())
[2020-11-20 23:28:16]    INFO >> ["@profiler.trace\ndef flavor_extra_set(request, flavor_id, metadata):\n\tflavor = novaclient(request).flavors.get(flavor_id)\n\tif (not metadata):\n\t\treturn None\n\treturn flavor.set_keys(metadata)\n","set the flavor extra spec keys ."] (predictor.py:56, main())
[2020-11-20 23:28:16]    INFO >> ["def _output_to_list(cmdoutput):\n\treturn [item for line in cmdoutput.splitlines() if _safe_output(line) for item in line.split()]\n","convert rabbitmqctl output to a list of strings ."] (predictor.py:56, main())
[2020-11-20 23:28:17]    INFO >> ["def convert_image(source, dest, out_format, run_as_root=False):\n\tcmd = ('qemu-img', 'convert', '-O', out_format, source, dest)\n\tutils.execute(run_as_root=run_as_root, *cmd)\n","convert image to other format ."] (predictor.py:56, main())
[2020-11-20 23:28:17]    INFO >> ["def run_migrations_offline():\n\tset_mysql_engine()\n\tkwargs = dict()\n\tif neutron_config.database.connection:\n\t\tkwargs['url'] = neutron_config.database.connection\n\telse:\n\t\tkwargs['dialect_name'] = neutron_config.database.engine\n\tkwargs['include_object'] = include_object\n\tcontext.configure(**kwargs)\n\twith context.begin_transaction():\n\t\tcontext.run_migrations()\n","run migrations in offline mode ."] (predictor.py:56, main())
[2020-11-20 23:28:17]    INFO >> ["def writeOutput(fileName=''):\n\tfileName = fabmetheus_interpret.getFirstTranslatorFileNameUnmodified(fileName)\n\tif (fileName != ''):\n\t\tskeinforge_craft.writeChainTextWithNounMessage(fileName, 'unpause')\n","fillet a gcode linear move file ."] (predictor.py:56, main())
[2020-11-20 23:28:18]    INFO >> ["def token_view(request):\n\tcontext = RequestContext(request, processors=[csrf])\n\ttemplate = Template(u'{%\tcsrf_token\t%}')\n\treturn HttpResponse(template.render(context))\n","a view that uses {% csrf_token %} ."] (predictor.py:56, main())
[2020-11-20 23:28:18]    INFO >> ["def spawn(coro):\n\tif (not isinstance(coro, types.GeneratorType)):\n\t\traise ValueError((u'%s\tis\tnot\ta\tcoroutine' % coro))\n\treturn SpawnEvent(coro)\n","event: add another coroutine to the scheduler ."] (predictor.py:56, main())
[2020-11-20 23:28:19]    INFO >> ["def memory(since=0.0):\n\tans = get_memory()\n\tans \/= float((1024 ** 2))\n\treturn (ans - since)\n","return memory usage in bytes ."] (predictor.py:56, main())
[2020-11-20 23:28:19]    INFO >> ["def runtime_rewriter_middleware(application):\n\treturn functools.partial(_rewriter_middleware, _REQUEST_REWRITER_CHAIN, _RUNTIME_RESPONSE_REWRITER_CHAIN, application)\n","wsgi middleware application that applies a chain of response rewriters ."] (predictor.py:56, main())
[2020-11-20 23:28:19]    INFO >> ["def foobar_explosion(radius):\n\tdef get_55():\n\t\t'A\tfunction\tthat\treturns\t55.'\n\t\treturn 55\n\treturn (get_55() * radius)\n","a nice and neat way of documenting code ."] (predictor.py:56, main())
[2020-11-20 23:28:20]    INFO >> ["def block_device_mapping_destroy(context, bdm_id):\n\treturn IMPL.block_device_mapping_destroy(context, bdm_id)\n","destroy the block device mapping ."] (predictor.py:56, main())
[2020-11-20 23:28:20]    INFO >> ["def floating_ip_deallocate(context, address):\n\treturn IMPL.floating_ip_deallocate(context, address)\n","deallocate a floating ip by address ."] (predictor.py:56, main())
[2020-11-20 23:28:22]    INFO >> ["def station():\n\toutput = s3_rest_controller(rheader=police_rheader)\n\treturn output\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:28:22]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:28:22]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:28:23]    INFO >> ["def set_nodes(nodes):\n\tglobal _FAKE_NODES\n\t_FAKE_NODES = nodes\n","sets fakedrivers node ."] (predictor.py:56, main())
[2020-11-20 23:28:23]    INFO >> ["def hours(h):\n\treturn (h \/ 24.0)\n","return hours as days ."] (predictor.py:56, main())
[2020-11-20 23:28:23]    INFO >> ["def getNewRepository():\n\treturn ExportRepository()\n","get new repository ."] (predictor.py:56, main())
[2020-11-20 23:28:25]    INFO >> ["def _update_all_uuids_to_ids(t_images, t_image_members, t_image_properties):\n\timages = list(t_images.select().execute())\n\tnew_id = 1\n\tfor image in images:\n\t\told_id = image['id']\n\t\tt_images.update().where((t_images.c.id == old_id)).values(id=str(new_id)).execute()\n\t\tt_image_members.update().where((t_image_members.c.image_id == old_id)).values(image_id=str(new_id)).execute()\n\t\tt_image_properties.update().where((t_image_properties.c.image_id == old_id)).values(image_id=str(new_id)).execute()\n\t\tt_image_properties.update().where(and_(or_((t_image_properties.c.name == 'kernel_id'), (t_image_properties.c.name == 'ramdisk_id')), (t_image_properties.c.value == old_id))).values(value=str(new_id)).execute()\n\t\tnew_id += 1\n","transition from varchar id to integer id ."] (predictor.py:56, main())
[2020-11-20 23:28:25]    INFO >> ["def get_models(app_labels):\n\tfrom django.db.models import get_app, get_apps, get_model\n\tfrom django.db.models import get_models as get_all_models\n\tfrom django.contrib.contenttypes.models import ContentType\n\tEXCLUDED_MODELS = (ContentType,)\n\tmodels = []\n\tif (not app_labels):\n\t\tfor app in get_apps():\n\t\t\tmodels += [m for m in get_all_models(app) if (m not in EXCLUDED_MODELS)]\n\tfor app_label in app_labels:\n\t\tif ('.' in app_label):\n\t\t\t(app_label, model_name) = app_label.split('.', 1)\n\t\t\tmodels.append(get_model(app_label, model_name))\n\t\telse:\n\t\t\tmodels += [m for m in get_all_models(get_app(app_label)) if (m not in EXCLUDED_MODELS)]\n\treturn models\n","gets a list of models for the given app labels ."] (predictor.py:56, main())
[2020-11-20 23:28:26]    INFO >> ["def _MergeBuiltinsIncludes(appinfo_path, appyaml, open_fn=open):\n\tif (not appyaml.builtins):\n\t\tappyaml.builtins = [appinfo.BuiltinHandler(default='on')]\n\telif (not appinfo.BuiltinHandler.IsDefined(appyaml.builtins, 'default')):\n\t\tappyaml.builtins.append(appinfo.BuiltinHandler(default='on'))\n\t(aggregate_appinclude, include_paths) = _ResolveIncludes(appinfo_path, appinfo.AppInclude(builtins=appyaml.builtins, includes=appyaml.includes), os.path.dirname(appinfo_path), appyaml.runtime, open_fn=open_fn)\n\treturn (appinfo.AppInclude.MergeAppYamlAppInclude(appyaml, aggregate_appinclude), include_paths)\n","merges app ."] (predictor.py:56, main())
[2020-11-20 23:28:27]    INFO >> ["def migrate_location_credentials(migrate_engine, to_quoted):\n\tmeta = sqlalchemy.schema.MetaData()\n\tmeta.bind = migrate_engine\n\timages_table = sqlalchemy.Table('images', meta, autoload=True)\n\timages = list(images_table.select(images_table.c.location.startswith('swift')).execute())\n\tfor image in images:\n\t\ttry:\n\t\t\tfixed_uri = legacy_parse_uri(image['location'], to_quoted)\n\t\t\timages_table.update().where((images_table.c.id == image['id'])).values(location=fixed_uri).execute()\n\t\texcept exception.BadStoreUri as e:\n\t\t\treason = encodeutils.exception_to_unicode(e)\n\t\t\tmsg = (_LE('Invalid\tstore\turi\tfor\timage:\t%(image_id)s.\tDetails:\t%(reason)s') % {'image_id': image.id, 'reason': reason})\n\t\t\tLOG.exception(msg)\n\t\t\traise\n","migrate location credentials for swift uris between the quoted and unquoted forms ."] (predictor.py:56, main())
[2020-11-20 23:28:27]    INFO >> ["def get_scene_absolute_numbering(indexer_id, indexer, absolute_number, fallback_to_xem=True):\n\tif ((indexer_id is None) or (absolute_number is None)):\n\t\treturn absolute_number\n\tindexer_id = int(indexer_id)\n\tindexer = int(indexer)\n\tshowObj = findCertainShow(sickrage.srCore.SHOWLIST, indexer_id)\n\tif (showObj and (not showObj.is_scene)):\n\t\treturn absolute_number\n\tresult = find_scene_absolute_numbering(indexer_id, indexer, absolute_number)\n\tif result:\n\t\treturn result\n\telse:\n\t\tif fallback_to_xem:\n\t\t\txem_result = find_xem_absolute_numbering(indexer_id, indexer, absolute_number)\n\t\t\tif xem_result:\n\t\t\t\treturn xem_result\n\t\treturn absolute_number\n","returns a tuple ."] (predictor.py:56, main())
[2020-11-20 23:28:27]    INFO >> ["def oracle_old_passwd(password, username, uppercase=True):\n\t(IV, pad) = (('\\x00' * 8), '\\x00')\n\tif isinstance(username, unicode):\n\t\tusername = unicode.encode(username, UNICODE_ENCODING)\n\tif isinstance(password, unicode):\n\t\tpassword = unicode.encode(password, UNICODE_ENCODING)\n\tunistr = ''.join((('\\x00%s' % c) for c in (username + password).upper()))\n\tcipher = des(hexdecode('0123456789ABCDEF'), CBC, IV, pad)\n\tencrypted = cipher.encrypt(unistr)\n\tcipher = des(encrypted[(-8):], CBC, IV, pad)\n\tencrypted = cipher.encrypt(unistr)\n\tretVal = hexencode(encrypted[(-8):])\n\treturn (retVal.upper() if uppercase else retVal.lower())\n","reference(s): url ."] (predictor.py:56, main())
[2020-11-20 23:28:28]    INFO >> ["def get_path_dir_files(dirName, nzbName, proc_type):\n\tpath = u''\n\tdirs = []\n\tfiles = []\n\tif (((dirName == sickbeard.TV_DOWNLOAD_DIR) and (not nzbName)) or (proc_type == u'manual')):\n\t\tfor (path, dirs, files) in ek(os.walk, dirName):\n\t\t\tbreak\n\telse:\n\t\t(path, dirs) = ek(os.path.split, dirName)\n\t\tif ((not ((nzbName is None) or nzbName.endswith(u'.nzb'))) and ek(os.path.isfile, ek(os.path.join, dirName, nzbName))):\n\t\t\tdirs = []\n\t\t\tfiles = [ek(os.path.join, dirName, nzbName)]\n\t\telse:\n\t\t\tdirs = [dirs]\n\t\t\tfiles = []\n\treturn (path, dirs, files)\n","get files in a path ."] (predictor.py:56, main())
[2020-11-20 23:28:28]    INFO >> ["def convDown(hidSums, filters, targets, numModulesX, paddingStart, moduleStride, filterSizeX, imSizeX, numImgColors):\n\tnumGroups = 1\n\tnumFilters = filters.shape[0]\n\tnumImages = hidSums.shape[0]\n\tnumModules = (numModulesX ** 2)\n\tassert (paddingStart >= 0)\n\tassert (targets.shape == (numImages, ((numImgColors * imSizeX) * imSizeX)))\n\t_ConvNet.convDown(hidSums.p_mat, filters.p_mat, targets.p_mat, imSizeX, (- paddingStart), moduleStride, numImgColors, numGroups)\n","hidsums - filters - targets - ."] (predictor.py:56, main())
[2020-11-20 23:28:28]    INFO >> ["def publish_from_doctree(document, destination_path=None, writer=None, writer_name='pseudoxml', settings=None, settings_spec=None, settings_overrides=None, config_section=None, enable_exit_status=False):\n\treader = docutils.readers.doctree.Reader(parser_name='null')\n\tpub = Publisher(reader, None, writer, source=io.DocTreeInput(document), destination_class=io.StringOutput, settings=settings)\n\tif ((not writer) and writer_name):\n\t\tpub.set_writer(writer_name)\n\tpub.process_programmatic_settings(settings_spec, settings_overrides, config_section)\n\tpub.set_destination(None, destination_path)\n\treturn pub.publish(enable_exit_status=enable_exit_status)\n","set up & run a publisher to render from an existing document tree data structure ."] (predictor.py:56, main())
[2020-11-20 23:28:28]    INFO >> ["def site_config_dir(appname=None, appauthor=None, version=None, multipath=False):\n\tif (system in ['win32', 'darwin']):\n\t\tpath = site_data_dir(appname, appauthor)\n\t\tif (appname and version):\n\t\t\tpath = os.path.join(path, version)\n\telse:\n\t\tpath = os.getenv('XDG_CONFIG_DIRS', '\/etc\/xdg')\n\t\tpathlist = [os.path.expanduser(x.rstrip(os.sep)) for x in path.split(os.pathsep)]\n\t\tif appname:\n\t\t\tif version:\n\t\t\t\tappname = os.path.join(appname, version)\n\t\t\tpathlist = [os.sep.join([x, appname]) for x in pathlist]\n\t\tif multipath:\n\t\t\tpath = os.pathsep.join(pathlist)\n\t\telse:\n\t\t\tpath = pathlist[0]\n\treturn path\n","return full path to the user-shared data dir for this application ."] (predictor.py:56, main())
[2020-11-20 23:28:29]    INFO >> ["def _get_default_tempdir():\n\tnamer = _RandomNameSequence()\n\tdirlist = _candidate_tempdir_list()\n\tflags = _text_openflags\n\tfor dir in dirlist:\n\t\tif (dir != _os.curdir):\n\t\t\tdir = _os.path.normcase(_os.path.abspath(dir))\n\t\tfor seq in xrange(100):\n\t\t\tname = namer.next()\n\t\t\tfilename = _os.path.join(dir, name)\n\t\t\ttry:\n\t\t\t\tfd = _os.open(filename, flags, 384)\n\t\t\t\ttry:\n\t\t\t\t\ttry:\n\t\t\t\t\t\twith _io.open(fd, 'wb', closefd=False) as fp:\n\t\t\t\t\t\t\tfp.write('blat')\n\t\t\t\t\tfinally:\n\t\t\t\t\t\t_os.close(fd)\n\t\t\t\tfinally:\n\t\t\t\t\t_os.unlink(filename)\n\t\t\t\treturn dir\n\t\t\texcept (OSError, IOError) as e:\n\t\t\t\tif (e.args[0] != _errno.EEXIST):\n\t\t\t\t\tbreak\n\t\t\t\tpass\n\traise IOError, (_errno.ENOENT, ('No\tusable\ttemporary\tdirectory\tfound\tin\t%s' % dirlist))\n","calculate the default directory to use for temporary files ."] (predictor.py:56, main())
[2020-11-20 23:28:29]    INFO >> ["def CreateBiddingStrategy(client):\n\tbidding_strategy_service = client.GetService('BiddingStrategyService', version='v201607')\n\tshared_bidding_strategy = {'name': ('Maximize\tClicks\t%s' % uuid.uuid4()), 'biddingScheme': {'xsi_type': 'TargetSpendBiddingScheme', 'bidCeiling': {'microAmount': '2000000'}}}\n\toperation = {'operator': 'ADD', 'operand': shared_bidding_strategy}\n\tresponse = bidding_strategy_service.mutate([operation])\n\tnew_bidding_strategy = response['value'][0]\n\tprint (\"Shared\tbidding\tstrategy\twith\tname\t'%s'\tand\tID\t'%s'\tof\ttype\t'%s'was\tcreated.\" % (new_bidding_strategy['name'], new_bidding_strategy['id'], new_bidding_strategy['biddingScheme']['BiddingScheme.Type']))\n\treturn new_bidding_strategy\n","creates a bidding strategy object ."] (predictor.py:56, main())
[2020-11-20 23:28:29]    INFO >> ["def remove_volume_type_access(context, volume_type_id, project_id):\n\tif (volume_type_id is None):\n\t\tmsg = _('volume_type_id\tcannot\tbe\tNone')\n\t\traise exception.InvalidVolumeType(reason=msg)\n\televated = (context if context.is_admin else context.elevated())\n\tif is_public_volume_type(elevated, volume_type_id):\n\t\tmsg = _('Type\taccess\tmodification\tis\tnot\tapplicable\tto\tpublic\tvolume\ttype.')\n\t\traise exception.InvalidVolumeType(reason=msg)\n\tdb.volume_type_access_remove(elevated, volume_type_id, project_id)\n\tnotify_about_volume_type_access_usage(context, volume_type_id, project_id, 'access.remove')\n","remove access to volume type for project_id ."] (predictor.py:56, main())
[2020-11-20 23:28:30]    INFO >> ["def PBKDF2(password, salt, dkLen=16, count=1000, prf=None):\n\tpassword = tobytes(password)\n\tif (prf is None):\n\t\tprf = (lambda p, s: HMAC.new(p, s, SHA1).digest())\n\tkey = b('')\n\ti = 1\n\twhile (len(key) < dkLen):\n\t\tU = previousU = prf(password, (salt + struct.pack('>I', i)))\n\t\tfor j in xrange((count - 1)):\n\t\t\tpreviousU = t = prf(password, previousU)\n\t\t\tU = strxor(U, t)\n\t\tkey += U\n\t\ti = (i + 1)\n\treturn key[:dkLen]\n","derive one or more keys from a password ."] (predictor.py:56, main())
[2020-11-20 23:28:30]    INFO >> ["def chown(path, user, group):\n\tpath = os.path.expanduser(path)\n\tuid = user_to_uid(user)\n\tgid = group_to_gid(group)\n\terr = ''\n\tif (uid == ''):\n\t\tif user:\n\t\t\terr += 'User\tdoes\tnot\texist\\n'\n\t\telse:\n\t\t\tuid = (-1)\n\tif (gid == ''):\n\t\tif group:\n\t\t\terr += 'Group\tdoes\tnot\texist\\n'\n\t\telse:\n\t\t\tgid = (-1)\n\tif (not os.path.exists(path)):\n\t\ttry:\n\t\t\treturn os.lchown(path, uid, gid)\n\t\texcept OSError:\n\t\t\tpass\n\t\terr += 'File\tnot\tfound'\n\tif err:\n\t\treturn err\n\treturn os.chown(path, uid, gid)\n","chown a file ."] (predictor.py:56, main())
[2020-11-20 23:28:31]    INFO >> ["def _fullyQualifiedName(obj):\n\ttry:\n\t\tname = obj.__qualname__\n\texcept AttributeError:\n\t\tname = obj.__name__\n\tif (inspect.isclass(obj) or inspect.isfunction(obj)):\n\t\tmoduleName = obj.__module__\n\t\treturn ('%s.%s' % (moduleName, name))\n\telif inspect.ismethod(obj):\n\t\ttry:\n\t\t\tcls = obj.im_class\n\t\texcept AttributeError:\n\t\t\treturn ('%s.%s' % (obj.__module__, obj.__qualname__))\n\t\telse:\n\t\t\tclassName = _fullyQualifiedName(cls)\n\t\t\treturn ('%s.%s' % (className, name))\n\treturn name\n","return the fully qualified name of a module ."] (predictor.py:56, main())
[2020-11-20 23:28:31]    INFO >> ["def getVector3ByMultiplierPrefix(elementNode, multiplier, prefix, vector3):\n\tif (multiplier == 0.0):\n\t\treturn vector3\n\toldMultipliedValueVector3 = (vector3 * multiplier)\n\tvector3ByPrefix = getVector3ByPrefix(oldMultipliedValueVector3.copy(), elementNode, prefix)\n\tif (vector3ByPrefix == oldMultipliedValueVector3):\n\t\treturn vector3\n\treturn (vector3ByPrefix \/ multiplier)\n","get vector3 from multiplier ."] (predictor.py:56, main())
[2020-11-20 23:28:31]    INFO >> ["def emit(events, stream=None, Dumper=Dumper, canonical=None, indent=None, width=None, allow_unicode=None, line_break=None):\n\tgetvalue = None\n\tif (stream is None):\n\t\tfrom StringIO import StringIO\n\t\tstream = StringIO()\n\t\tgetvalue = stream.getvalue\n\tdumper = Dumper(stream, canonical=canonical, indent=indent, width=width, allow_unicode=allow_unicode, line_break=line_break)\n\tfor event in events:\n\t\tdumper.emit(event)\n\tif getvalue:\n\t\treturn getvalue()\n","emit yaml parsing events into a stream ."] (predictor.py:56, main())
[2020-11-20 23:28:32]    INFO >> ["def test_clone_should_rstrip_trailing_slash_in_repo_url(mocker, clone_dir):\n\tmocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\tmock_subprocess = mocker.patch('cookiecutter.vcs.subprocess.check_output', autospec=True)\n\tvcs.clone('https:\/\/github.com\/foo\/bar\/', clone_to_dir=clone_dir, no_input=True)\n\tmock_subprocess.assert_called_once_with(['git', 'clone', 'https:\/\/github.com\/foo\/bar'], cwd=clone_dir, stderr=subprocess.STDOUT)\n","in clone() ."] (predictor.py:56, main())
[2020-11-20 23:28:33]    INFO >> ["def wait_for_occupied_port(host, port, timeout=None):\n\tif (not host):\n\t\traise ValueError(\"Host\tvalues\tof\t''\tor\tNone\tare\tnot\tallowed.\")\n\tif (timeout is None):\n\t\ttimeout = occupied_port_timeout\n\tfor trial in range(50):\n\t\ttry:\n\t\t\tcheck_port(host, port, timeout=timeout)\n\t\texcept IOError:\n\t\t\treturn\n\t\telse:\n\t\t\ttime.sleep(timeout)\n\tif (host == client_host(host)):\n\t\traise IOError(('Port\t%r\tnot\tbound\ton\t%r' % (port, host)))\n\tmsg = ('Unable\tto\tverify\tthat\tthe\tserver\tis\tbound\ton\t%r' % port)\n\twarnings.warn(msg)\n","wait for the specified port to become active ."] (predictor.py:56, main())
[2020-11-20 23:28:33]    INFO >> ["def ParseResponseEx(response, select_default=False, form_parser_class=FormParser, request_class=_request.Request, entitydefs=None, encoding=DEFAULT_ENCODING, _urljoin=urlparse.urljoin, _urlparse=urlparse.urlparse, _urlunparse=urlparse.urlunparse):\n\treturn _ParseFileEx(response, response.geturl(), select_default, False, form_parser_class, request_class, entitydefs, False, encoding, _urljoin=_urljoin, _urlparse=_urlparse, _urlunparse=_urlunparse)\n","identical to parseresponse ."] (predictor.py:56, main())
[2020-11-20 23:28:33]    INFO >> ["def sslwrap_simple(sock, keyfile=None, certfile=None):\n\tif hasattr(sock, '_sock'):\n\t\tsock = sock._sock\n\tssl_sock = _ssl.sslwrap(sock, 0, keyfile, certfile, CERT_NONE, PROTOCOL_SSLv23, None)\n\ttry:\n\t\tsock.getpeername()\n\texcept:\n\t\tpass\n\telse:\n\t\tssl_sock.do_handshake()\n\treturn ssl_sock\n","a replacement for the old socket ."] (predictor.py:56, main())
[2020-11-20 23:28:34]    INFO >> ["def run_migrations_online():\n\tconnectable = settings.engine\n\twith connectable.connect() as connection:\n\t\tcontext.configure(connection=connection, target_metadata=target_metadata, compare_type=COMPARE_TYPE)\n\t\twith context.begin_transaction():\n\t\t\tcontext.run_migrations()\n","run migrations in online mode ."] (predictor.py:56, main())
[2020-11-20 23:28:35]    INFO >> ["def split_buffer(stream, splitter=None, decoder=(lambda a: a)):\n\tsplitter = (splitter or line_splitter)\n\tbuffered = six.text_type(u'')\n\tfor data in stream_as_text(stream):\n\t\tbuffered += data\n\t\twhile True:\n\t\t\tbuffer_split = splitter(buffered)\n\t\t\tif (buffer_split is None):\n\t\t\t\tbreak\n\t\t\t(item, buffered) = buffer_split\n\t\t\t(yield item)\n\tif buffered:\n\t\ttry:\n\t\t\t(yield decoder(buffered))\n\t\texcept Exception as e:\n\t\t\tlog.error((u'Compose\ttried\tdecoding\tthe\tfollowing\tdata\tchunk,\tbut\tfailed:\\n%s' % repr(buffered)))\n\t\t\traise StreamParseError(e)\n","given a generator which yields strings and a splitter function ."] (predictor.py:56, main())
[2020-11-20 23:28:35]    INFO >> ["def connect_to_region(region_name, **kw_params):\n\tfor region in regions():\n\t\tif (region.name == region_name):\n\t\t\treturn region.connect(**kw_params)\n\treturn None\n","given a valid region name ."] (predictor.py:56, main())
[2020-11-20 23:28:36]    INFO >> ["def path_to_url(path):\n\tpath = os.path.normcase(os.path.abspath(path))\n\tif _drive_re.match(path):\n\t\tpath = ((path[0] + '|') + path[2:])\n\turl = urllib.quote(path)\n\turl = url.replace(os.path.sep, '\/')\n\turl = url.lstrip('\/')\n\treturn ('file:\/\/\/' + url)\n","convert a path to a file: url ."] (predictor.py:56, main())
[2020-11-20 23:28:36]    INFO >> ["def new_document(source_path, settings=None):\n\tfrom docutils import frontend\n\tif (settings is None):\n\t\tsettings = frontend.OptionParser().get_default_values()\n\tsource_path = decode_path(source_path)\n\treporter = new_reporter(source_path, settings)\n\tdocument = nodes.document(settings, reporter, source=source_path)\n\tdocument.note_source(source_path, (-1))\n\treturn document\n","return a new empty document object ."] (predictor.py:56, main())
[2020-11-20 23:28:37]    INFO >> ["def processElementNodeByDerivation(derivation, elementNode):\n\tif (derivation == None):\n\t\tderivation = SolidDerivation(elementNode)\n\telementAttributesCopy = elementNode.attributes.copy()\n\tfor target in derivation.targets:\n\t\ttargetAttributesCopy = target.attributes.copy()\n\t\ttarget.attributes = elementAttributesCopy\n\t\tprocessTarget(target)\n\t\ttarget.attributes = targetAttributesCopy\n","process the xml element by derivation ."] (predictor.py:56, main())
[2020-11-20 23:28:37]    INFO >> ["def model_format_dict(obj):\n\tif isinstance(obj, (models.Model, models.base.ModelBase)):\n\t\topts = obj._meta\n\telif isinstance(obj, models.query.QuerySet):\n\t\topts = obj.model._meta\n\telse:\n\t\topts = obj\n\treturn {'verbose_name': force_unicode(opts.verbose_name), 'verbose_name_plural': force_unicode(opts.verbose_name_plural)}\n","return a dict with keys verbose_name and verbose_name_plural ."] (predictor.py:56, main())
[2020-11-20 23:28:37]    INFO >> ["def instance_info_cache_update(context, instance_uuid, values):\n\treturn IMPL.instance_info_cache_update(context, instance_uuid, values)\n","update an instance info cache record in the table ."] (predictor.py:56, main())
[2020-11-20 23:28:37]    INFO >> ["def quickstart(root=None, script_name='', config=None):\n\tif config:\n\t\t_global_conf_alias.update(config)\n\ttree.mount(root, script_name, config)\n\tengine.signals.subscribe()\n\tengine.start()\n\tengine.block()\n","mount the given root ."] (predictor.py:56, main())
[2020-11-20 23:28:38]    INFO >> ["def get_random_string(length=12, allowed_chars=u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'):\n\tif (not using_sysrandom):\n\t\trandom.seed(hashlib.sha256((u'%s%s%s' % (random.getstate(), time.time(), settings.SECRET_KEY)).encode(u'utf-8')).digest())\n\treturn u''.join([random.choice(allowed_chars) for i in range(length)])\n","returns a securely generated random string ."] (predictor.py:56, main())
[2020-11-20 23:28:38]    INFO >> ["def test_rus_fit():\n\trus = RandomUnderSampler(random_state=RND_SEED)\n\trus.fit(X, Y)\n\tassert_equal(rus.min_c_, 0)\n\tassert_equal(rus.maj_c_, 1)\n\tassert_equal(rus.stats_c_[0], 3)\n\tassert_equal(rus.stats_c_[1], 7)\n","test the fitting method ."] (predictor.py:56, main())
[2020-11-20 23:28:38]    INFO >> ["def test_run_link(start_link, count=1000):\n\tif isinstance(start_link, basestring):\n\t\tstart_link = int(start_link, 36)\n\tlinks = Link._byID(range((start_link - count), start_link), data=True, return_dict=False)\n\tuploader = LinkUploader(g.CLOUDSEARCH_DOC_API, things=links)\n\treturn uploader.inject()\n","inject count number of links ."] (predictor.py:56, main())
[2020-11-20 23:28:39]    INFO >> ["def fit_grid_point(X, y, estimator, parameters, train, test, scorer, verbose, error_score='raise', **fit_params):\n\t(score, n_samples_test, _) = _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, error_score)\n\treturn (score, parameters, n_samples_test)\n","run fit on one set of parameters ."] (predictor.py:56, main())
[2020-11-20 23:28:40]    INFO >> ["def get_stable_hash(obj):\n\tif isinstance(obj, dict):\n\t\treturn get_stable_hash(list(obj.items()))\n\telif isinstance(obj, (list, tuple)):\n\t\tobj = sorted((get_stable_hash(o) for o in obj))\n\treturn md5(unicode(obj).encode('utf8')).hexdigest()\n","return a stable hash for a python data structure ."] (predictor.py:56, main())
[2020-11-20 23:28:40]    INFO >> ["def startMainLoopFromConstructor(repository):\n\tdisplayedDialogFromConstructor = getDisplayedDialogFromConstructor(repository)\n\tif (displayedDialogFromConstructor == None):\n\t\tprint 'Warning,\tdisplayedDialogFromConstructor\tin\tsettings\tis\tnone,\tso\tthe\twindow\twill\tnot\tbe\tdisplayed.'\n\telse:\n\t\tdisplayedDialogFromConstructor.root.mainloop()\n","display the repository dialog and start the main loop ."] (predictor.py:56, main())
[2020-11-20 23:28:41]    INFO >> ["def test_sample_wrong_X():\n\tada = ADASYN(random_state=RND_SEED)\n\tada.fit(X, Y)\n\tassert_raises(RuntimeError, ada.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:28:41]    INFO >> ["def splittype(url):\n\tglobal _typeprog\n\tif (_typeprog is None):\n\t\t_typeprog = re.compile('([^\/:]+):(.*)', re.DOTALL)\n\tmatch = _typeprog.match(url)\n\tif match:\n\t\t(scheme, data) = match.groups()\n\t\treturn (scheme.lower(), data)\n\treturn (None, url)\n","splittype --> type ."] (predictor.py:56, main())
[2020-11-20 23:28:42]    INFO >> ["def _convert_agg_to_wx_bitmap(agg, bbox):\n\tif (bbox is None):\n\t\treturn wxc.BitmapFromBuffer(int(agg.width), int(agg.height), agg.buffer_rgba())\n\telse:\n\t\treturn _WX28_clipped_agg_as_bitmap(agg, bbox)\n","convert the region of the agg buffer bounded by bbox to a wx ."] (predictor.py:56, main())
[2020-11-20 23:28:42]    INFO >> ["def _match(key, value, attrs):\n\tif (key not in attrs):\n\t\treturn False\n\tif (value == '*'):\n\t\treturn True\n\tif (key != 'objectclass'):\n\t\treturn (value in attrs[key])\n\tvalues = _subs(value)\n\tfor v in values:\n\t\tif (v in attrs[key]):\n\t\t\treturn True\n\treturn False\n","match a given key and value against an attribute list ."] (predictor.py:56, main())
[2020-11-20 23:28:43]    INFO >> ["def parse_list_header(value):\n\tresult = []\n\tfor item in _parse_list_header(value):\n\t\tif (item[:1] == item[(-1):] == '\"'):\n\t\t\titem = unquote_header_value(item[1:(-1)])\n\t\tresult.append(item)\n\treturn result\n","parse lists as described by rfc 2068 section 2 ."] (predictor.py:56, main())
[2020-11-20 23:28:43]    INFO >> ["def libvlc_video_filter_list_get(p_instance):\n\tf = (_Cfunctions.get('libvlc_video_filter_list_get', None) or _Cfunction('libvlc_video_filter_list_get', ((1,),), None, ctypes.POINTER(ModuleDescription), Instance))\n\treturn f(p_instance)\n","returns a list of video filters that are available ."] (predictor.py:56, main())
[2020-11-20 23:28:44]    INFO >> ["def col(loc, strg):\n\treturn ((((loc < len(strg)) and (strg[loc] == '\\n')) and 1) or (loc - strg.rfind('\\n', 0, loc)))\n","returns current column within a string ."] (predictor.py:56, main())
[2020-11-20 23:28:45]    INFO >> ["def is_form_media_type(media_type):\n\t(base_media_type, params) = parse_header(media_type.encode(HTTP_HEADER_ENCODING))\n\treturn ((base_media_type == u'application\/x-www-form-urlencoded') or (base_media_type == u'multipart\/form-data'))\n","return true if the media type is a valid form media type ."] (predictor.py:56, main())
[2020-11-20 23:28:45]    INFO >> ["@with_setup(step_runner_environ)\ndef test_successful_behave_as_step_passes():\n\trunnable_step = Step.from_string('Given\tI\thave\ta\tstep\twhich\tcalls\tthe\t\"define\ta\tstep\"\tstep\twith\tbehave_as')\n\trunnable_step.run(True)\n\tassert runnable_step.passed\n","when a step definition calls another step definition with behave_as ."] (predictor.py:56, main())
[2020-11-20 23:28:45]    INFO >> ["def openSerial(port=0, rate=19200, timeout=1):\n\tsnap.openSerial(port=port, rate=rate, tout=timeout)\n","open serial port for snap reprap communications ."] (predictor.py:56, main())
[2020-11-20 23:28:46]    INFO >> ["def setNonBlocking(fd):\n\tflags = fcntl.fcntl(fd, fcntl.F_GETFL)\n\tflags = (flags | os.O_NONBLOCK)\n\tfcntl.fcntl(fd, fcntl.F_SETFL, flags)\n","make a file descriptor non-blocking ."] (predictor.py:56, main())
[2020-11-20 23:28:46]    INFO >> ["def vector(name=None, dtype=None):\n\tif (dtype is None):\n\t\tdtype = config.floatX\n\ttype = TensorType(dtype, (False,))\n\treturn type(name)\n","return a symbolic vector variable ."] (predictor.py:56, main())
[2020-11-20 23:28:46]    INFO >> ["def _findShebang(filename):\n\twith open(filename, 'rU') as f:\n\t\tif (f.read(2) == '#!'):\n\t\t\texe = f.readline(1024).strip('\\n')\n\t\t\treturn exe\n","look for a #! line ."] (predictor.py:56, main())
[2020-11-20 23:28:47]    INFO >> ["def addLevelName(level, levelName):\n\t_acquireLock()\n\ttry:\n\t\t_levelNames[level] = levelName\n\t\t_levelNames[levelName] = level\n\tfinally:\n\t\t_releaseLock()\n","associate levelname with level ."] (predictor.py:56, main())
[2020-11-20 23:28:47]    INFO >> ["def educateBackticks(text, language='en'):\n\tsmart = smartchars(language)\n\ttext = re.sub('``', smart.opquote, text)\n\ttext = re.sub(\"''\", smart.cpquote, text)\n\treturn text\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:28:47]    INFO >> ["@_get_client\ndef image_member_update(client, memb_id, values):\n\treturn client.image_member_update(memb_id=memb_id, values=values)\n","update an imagemember object ."] (predictor.py:56, main())
[2020-11-20 23:28:47]    INFO >> ["def openSerial(port=0, rate=19200, timeout=1):\n\tsnap.openSerial(port=port, rate=rate, tout=timeout)\n","open serial port for snap reprap communications ."] (predictor.py:56, main())
[2020-11-20 23:28:48]    INFO >> ["def intget(integer, default=None):\n\ttry:\n\t\treturn int(integer)\n\texcept (TypeError, ValueError):\n\t\treturn default\n","returns integer as an int or default if it cant ."] (predictor.py:56, main())
[2020-11-20 23:28:49]    INFO >> ["def add_representer(data_type, representer, Dumper=Dumper):\n\tDumper.add_representer(data_type, representer)\n","add a representer for the given type ."] (predictor.py:56, main())
[2020-11-20 23:28:49]    INFO >> ["def makeHTMLTags(tagStr):\n\treturn _makeTags(tagStr, False)\n","helper to construct opening and closing tag expressions for html ."] (predictor.py:56, main())
[2020-11-20 23:28:50]    INFO >> ["def chhomephone(name, homephone):\n\treturn _update_gecos(name, 'homephone', homephone)\n","change the users home phone cli example: ."] (predictor.py:56, main())
[2020-11-20 23:28:50]    INFO >> ["def test_rgb_to_hsl_part_1():\n\tpass\n","test rgb to hsl color function ."] (predictor.py:56, main())
[2020-11-20 23:28:50]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:28:51]    INFO >> ["def people_type():\n\treturn s3_rest_controller()\n","rest controller ."] (predictor.py:56, main())
[2020-11-20 23:28:51]    INFO >> ["def release():\n\treturn uname()[2]\n","returns the systems release ."] (predictor.py:56, main())
[2020-11-20 23:28:51]    INFO >> ["@sensitive_post_parameters()\n@csrf_protect\n@never_cache\ndef login(request, template_name='registration\/login.html', redirect_field_name=REDIRECT_FIELD_NAME, authentication_form=AuthenticationForm, current_app=None, extra_context=None):\n\tredirect_to = request.REQUEST.get(redirect_field_name, '')\n\tif (request.method == 'POST'):\n\t\tform = authentication_form(data=request.POST)\n\t\tif form.is_valid():\n\t\t\tif (not is_safe_url(url=redirect_to, host=request.get_host())):\n\t\t\t\tredirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)\n\t\t\tauth_login(request, form.get_user())\n\t\t\tif request.session.test_cookie_worked():\n\t\t\t\trequest.session.delete_test_cookie()\n\t\t\treturn HttpResponseRedirect(redirect_to)\n\telse:\n\t\tform = authentication_form(request)\n\trequest.session.set_test_cookie()\n\tcurrent_site = get_current_site(request)\n\tcontext = {'form': form, redirect_field_name: redirect_to, 'site': current_site, 'site_name': current_site.name}\n\tif (extra_context is not None):\n\t\tcontext.update(extra_context)\n\treturn TemplateResponse(request, template_name, context, current_app=current_app)\n","displays the login form and handles the login action ."] (predictor.py:56, main())
[2020-11-20 23:28:52]    INFO >> ["def addRackHoles(derivation, elementNode, vector3RackProfiles):\n\tif (len(derivation.gearHolePaths) > 0):\n\t\tvector3RackProfiles += derivation.gearHolePaths\n\t\treturn\n\tif (derivation.rackHoleRadius <= 0.0):\n\t\treturn\n\taddRackHole(derivation, elementNode, vector3RackProfiles, 0.0)\n\trackHoleMargin = (derivation.rackHoleRadius + derivation.rackHoleRadius)\n\trackHoleSteps = int(math.ceil(((derivation.rackDemilength - rackHoleMargin) \/ derivation.rackHoleStep)))\n\tfor rackHoleIndex in xrange(1, rackHoleSteps):\n\t\tx = (float(rackHoleIndex) * derivation.rackHoleStep)\n\t\taddRackHole(derivation, elementNode, vector3RackProfiles, (- x))\n\t\taddRackHole(derivation, elementNode, vector3RackProfiles, x)\n","add rack holes to vector3rackprofiles ."] (predictor.py:56, main())
[2020-11-20 23:28:52]    INFO >> ["def test_hsl_to_rgb_part_6():\n\tassert (hsl_to_rgb(240, 100, 50) == (0, 0, 255))\n\tassert (hsl_to_rgb(252, 100, 50) == (51, 0, 255))\n\tassert (hsl_to_rgb(264, 100, 50) == (102, 0, 255))\n\tassert (hsl_to_rgb(276, 100, 50) == (153, 0, 255))\n\tassert (hsl_to_rgb(288, 100, 50) == (204, 0, 255))\n\tassert (hsl_to_rgb(300, 100, 50) == (255, 0, 255))\n\tassert (hsl_to_rgb(312, 100, 50) == (255, 0, 204))\n\tassert (hsl_to_rgb(324, 100, 50) == (255, 0, 153))\n\tassert (hsl_to_rgb(336, 100, 50) == (255, 0, 102))\n\tassert (hsl_to_rgb(348, 100, 50) == (255, 0, 51))\n\tassert (hsl_to_rgb(360, 100, 50) == (255, 0, 0))\n","test hsl to rgb color function ."] (predictor.py:56, main())
[2020-11-20 23:28:53]    INFO >> ["def configure_mappers():\n\tif (not Mapper._new_mappers):\n\t\treturn\n\t_CONFIGURE_MUTEX.acquire()\n\ttry:\n\t\tglobal _already_compiling\n\t\tif _already_compiling:\n\t\t\treturn\n\t\t_already_compiling = True\n\t\ttry:\n\t\t\tif (not Mapper._new_mappers):\n\t\t\t\treturn\n\t\t\tMapper.dispatch._for_class(Mapper).before_configured()\n\t\t\tfor mapper in list(_mapper_registry):\n\t\t\t\tif getattr(mapper, '_configure_failed', False):\n\t\t\t\t\te = sa_exc.InvalidRequestError((\"One\tor\tmore\tmappers\tfailed\tto\tinitialize\t-\tcan't\tproceed\twith\tinitialization\tof\tother\tmappers.\tTriggering\tmapper:\t'%s'.\tOriginal\texception\twas:\t%s\" % (mapper, mapper._configure_failed)))\n\t\t\t\t\te._configure_failed = mapper._configure_failed\n\t\t\t\t\traise e\n\t\t\t\tif (not mapper.configured):\n\t\t\t\t\ttry:\n\t\t\t\t\t\tmapper._post_configure_properties()\n\t\t\t\t\t\tmapper._expire_memoizations()\n\t\t\t\t\t\tmapper.dispatch.mapper_configured(mapper, mapper.class_)\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\texc = sys.exc_info()[1]\n\t\t\t\t\t\tif (not hasattr(exc, '_configure_failed')):\n\t\t\t\t\t\t\tmapper._configure_failed = exc\n\t\t\t\t\t\traise\n\t\t\tMapper._new_mappers = False\n\t\tfinally:\n\t\t\t_already_compiling = False\n\tfinally:\n\t\t_CONFIGURE_MUTEX.release()\n\tMapper.dispatch._for_class(Mapper).after_configured()\n","initialize the inter-mapper relationships of all mappers that have been constructed thus far ."] (predictor.py:56, main())
[2020-11-20 23:28:53]    INFO >> ["def dirichlet_logpdf_vec(x, alpha):\n\tshape = x.shape\n\tif (len(shape) == 1):\n\t\ttry:\n\t\t\treturn stats.dirichlet.logpdf(x, alpha)\n\t\texcept:\n\t\t\tx[(-1)] = (1.0 - np.sum(x[:(-1)]))\n\t\t\treturn stats.dirichlet.logpdf(x, alpha)\n\telif (len(shape) == 2):\n\t\tsize = shape[0]\n\t\tif (len(alpha.shape) == 1):\n\t\t\treturn np.array([dirichlet_logpdf_vec(x[i, :], alpha) for i in range(size)])\n\t\telse:\n\t\t\treturn np.array([dirichlet_logpdf_vec(x[i, :], alpha[i, :]) for i in range(size)])\n\telif (len(shape) == 3):\n\t\tsize = shape[0]\n\t\treturn np.array([dirichlet_logpdf_vec(x[i, :, :], alpha) for i in range(size)])\n\telse:\n\t\traise NotImplementedError()\n","vectorized version of stats ."] (predictor.py:56, main())
[2020-11-20 23:28:54]    INFO >> ["def normpath(path):\n\tif (path == ''):\n\t\treturn '.'\n\tinitial_slashes = path.startswith('\/')\n\tif (initial_slashes and path.startswith('\/\/') and (not path.startswith('\/\/\/'))):\n\t\tinitial_slashes = 2\n\tcomps = path.split('\/')\n\tnew_comps = []\n\tfor comp in comps:\n\t\tif (comp in ('', '.')):\n\t\t\tcontinue\n\t\tif ((comp != '..') or ((not initial_slashes) and (not new_comps)) or (new_comps and (new_comps[(-1)] == '..'))):\n\t\t\tnew_comps.append(comp)\n\t\telif new_comps:\n\t\t\tnew_comps.pop()\n\tcomps = new_comps\n\tpath = '\/'.join(comps)\n\tif initial_slashes:\n\t\tpath = (('\/' * initial_slashes) + path)\n\treturn (path or '.')\n","normalize path ."] (predictor.py:56, main())
[2020-11-20 23:28:54]    INFO >> ["def arm_and_takeoff(aTargetAltitude):\n\twhile (not vehicle.is_armable):\n\t\tprint '\tWaiting\tfor\tvehicle\tto\tinitialise...'\n\t\ttime.sleep(1)\n\twhile (vehicle.mode.name != 'GUIDED'):\n\t\tvehicle.mode = VehicleMode('GUIDED')\n\t\ttime.sleep(0.1)\n\twhile (not vehicle.armed):\n\t\tvehicle.armed = True\n\t\tprint '\tWaiting\tfor\tarming...'\n\t\ttime.sleep(1)\n\tprint '\tTaking\toff!'\n\tvehicle.simple_takeoff(aTargetAltitude)\n\twhile True:\n\t\trequiredAlt = (aTargetAltitude * 0.95)\n\t\tif (vehicle.location.global_relative_frame.alt >= requiredAlt):\n\t\t\tprint ('\tReached\ttarget\taltitude\tof\t~%f' % aTargetAltitude)\n\t\t\tbreak\n\t\tprint ('\tAltitude:\t%f\t<\t%f' % (vehicle.location.global_relative_frame.alt, requiredAlt))\n\t\ttime.sleep(1)\n","arms vehicle and fly to atargetaltitude ."] (predictor.py:56, main())
[2020-11-20 23:28:54]    INFO >> ["@requires_application()\ndef test_reactive_draw():\n\twith TestingCanvas() as c:\n\t\trpolygon = visuals.RegularPolygon(center=[50, 50, 0.0], radius=20, sides=8, color='yellow', parent=c.scene)\n\t\trpolygon.center = [70, 40, 0.0]\n\t\tassert_image_approved(c.render(), 'visuals\/reactive_regular_polygon1.png')\n\t\trpolygon.radius = 25\n\t\tassert_image_approved(c.render(), 'visuals\/reactive_regular_polygon2.png')\n\t\trpolygon.color = 'red'\n\t\tassert_image_approved(c.render(), 'visuals\/reactive_regular_polygon3.png')\n\t\trpolygon.border_color = 'yellow'\n\t\tassert_image_approved(c.render(), 'visuals\/reactive_regular_polygon4.png')\n\t\trpolygon.sides = 6\n\t\tassert_image_approved(c.render(), 'visuals\/reactive_regular_polygon5.png')\n","test reactive rectpolygon attributes ."] (predictor.py:56, main())
[2020-11-20 23:28:55]    INFO >> ["def addLighteningHoles(derivation, gearHolePaths, negatives, pitchRadius, positives):\n\textrudeDerivation = extrude.ExtrudeDerivation()\n\tpositiveVertexes = matrix.getVertexes(positives)\n\tbottomPath = euclidean.getTopPath(positiveVertexes)\n\ttopPath = euclidean.getBottomPath(positiveVertexes)\n\textrudeDerivation.offsetPathDefault = [Vector3(0.0, 0.0, bottomPath), Vector3(0.0, 0.0, topPath)]\n\textrudeDerivation.setToXMLElement(derivation.copyShallow)\n\tvector3LighteningHoles = getLighteningHoles(derivation, gearHolePaths, pitchRadius)\n\textrude.addNegativesPositives(extrudeDerivation, negatives, vector3LighteningHoles, positives)\n","add lightening holes ."] (predictor.py:56, main())
[2020-11-20 23:28:55]    INFO >> ["def check_config_h():\n\tfrom distutils import sysconfig\n\timport string\n\tif (string.find(sys.version, 'GCC') >= 0):\n\t\treturn (CONFIG_H_OK, \"sys.version\tmentions\t'GCC'\")\n\tfn = sysconfig.get_config_h_filename()\n\ttry:\n\t\tf = open(fn)\n\t\ts = f.read()\n\t\tf.close()\n\texcept IOError as exc:\n\t\treturn (CONFIG_H_UNCERTAIN, (\"couldn't\tread\t'%s':\t%s\" % (fn, exc.strerror)))\n\telse:\n\t\tif (string.find(s, '__GNUC__') >= 0):\n\t\t\treturn (CONFIG_H_OK, (\"'%s'\tmentions\t'__GNUC__'\" % fn))\n\t\telse:\n\t\t\treturn (CONFIG_H_NOTOK, (\"'%s'\tdoes\tnot\tmention\t'__GNUC__'\" % fn))\n","check if the current python installation appears amenable to building extensions with gcc ."] (predictor.py:56, main())
[2020-11-20 23:28:57]    INFO >> ["def fullmodname(path):\n\tcomparepath = os.path.normcase(path)\n\tlongest = ''\n\tfor dir in sys.path:\n\t\tdir = os.path.normcase(dir)\n\t\tif (comparepath.startswith(dir) and (comparepath[len(dir)] == os.sep)):\n\t\t\tif (len(dir) > len(longest)):\n\t\t\t\tlongest = dir\n\tif longest:\n\t\tbase = path[(len(longest) + 1):]\n\telse:\n\t\tbase = path\n\tbase = base.replace(os.sep, '.')\n\tif os.altsep:\n\t\tbase = base.replace(os.altsep, '.')\n\t(filename, ext) = os.path.splitext(base)\n\treturn filename\n","return a plausible module name for the path ."] (predictor.py:56, main())
[2020-11-20 23:28:58]    INFO >> ["def uu_encode(input, errors='strict', filename='<data>', mode=438):\n\tassert (errors == 'strict')\n\tfrom cStringIO import StringIO\n\tfrom binascii import b2a_uu\n\tinfile = StringIO(str(input))\n\toutfile = StringIO()\n\tread = infile.read\n\twrite = outfile.write\n\twrite(('begin\t%o\t%s\\n' % ((mode & 511), filename)))\n\tchunk = read(45)\n\twhile chunk:\n\t\twrite(b2a_uu(chunk))\n\t\tchunk = read(45)\n\twrite('\t\\nend\\n')\n\treturn (outfile.getvalue(), len(input))\n","encodes the object input and returns a tuple ."] (predictor.py:56, main())
[2020-11-20 23:28:58]    INFO >> ["def _ToChannelError(error):\n\terror_map = {channel_service_pb.ChannelServiceError.INVALID_CHANNEL_KEY: InvalidChannelClientIdError, channel_service_pb.ChannelServiceError.BAD_MESSAGE: InvalidMessageError}\n\tif (error.application_error in error_map):\n\t\treturn error_map[error.application_error](error.error_detail)\n\telse:\n\t\treturn error\n","translate an application error to a channel error ."] (predictor.py:56, main())
[2020-11-20 23:28:59]    INFO >> ["def text_to_qcolor(text):\n\tcolor = QColor()\n\ttext = str(text)\n\tif (not is_text_string(text)):\n\t\treturn color\n\tif (text.startswith('#') and (len(text) == 7)):\n\t\tcorrect = '#0123456789abcdef'\n\t\tfor char in text:\n\t\t\tif (char.lower() not in correct):\n\t\t\t\treturn color\n\telif (text not in list(QColor.colorNames())):\n\t\treturn color\n\tcolor.setNamedColor(text)\n\treturn color\n","create a qcolor from specified string avoid warning from qt when an invalid qcolor is instantiated ."] (predictor.py:56, main())
[2020-11-20 23:28:59]    INFO >> ["def mail_managers(subject, message, fail_silently=False, connection=None):\n\tif (not settings.MANAGERS):\n\t\treturn\n\tEmailMessage((u'%s%s' % (settings.EMAIL_SUBJECT_PREFIX, subject)), message, settings.SERVER_EMAIL, [a[1] for a in settings.MANAGERS], connection=connection).send(fail_silently=fail_silently)\n","sends a message to the managers ."] (predictor.py:56, main())
[2020-11-20 23:29:00]    INFO >> ["def log_1_plus_exp(mat, target=None, exact=False):\n\tif (not target):\n\t\ttarget = mat\n\tif exact:\n\t\terr_code = _cudamat.apply_log_1_plus_exp_exact(mat.p_mat, target.p_mat)\n\telse:\n\t\terr_code = _cudamat.apply_log_1_plus_exp(mat.p_mat, target.p_mat)\n\tif err_code:\n\t\traise generate_exception(err_code)\n\treturn target\n","apply log(1+exp(x)) to each element of the matrix mat ."] (predictor.py:56, main())
[2020-11-20 23:29:00]    INFO >> ["def find_credentials(host):\n\tuser_names = [__pillar__['proxy'].get('username', 'root')]\n\tpasswords = __pillar__['proxy']['passwords']\n\tfor user in user_names:\n\t\tfor password in passwords:\n\t\t\ttry:\n\t\t\t\tret = __salt__['vsphere.system_info'](host=host, username=user, password=password)\n\t\t\texcept SaltSystemExit:\n\t\t\t\tcontinue\n\t\t\tif ret:\n\t\t\t\tDETAILS['username'] = user\n\t\t\t\tDETAILS['password'] = password\n\t\t\t\treturn (user, password)\n\traise SaltSystemExit('Cannot\tcomplete\tlogin\tdue\tto\tan\tincorrect\tuser\tname\tor\tpassword.')\n","cycle through all the possible credentials and return the first one that works ."] (predictor.py:56, main())
[2020-11-20 23:29:00]    INFO >> ["def get_comment_app():\n\tcomments_app = get_comment_app_name()\n\tif (comments_app not in settings.INSTALLED_APPS):\n\t\traise ImproperlyConfigured(('The\tCOMMENTS_APP\t(%r)\tmust\tbe\tin\tINSTALLED_APPS' % settings.COMMENTS_APP))\n\ttry:\n\t\tpackage = import_module(comments_app)\n\texcept ImportError:\n\t\traise ImproperlyConfigured('The\tCOMMENTS_APP\tsetting\trefers\tto\ta\tnon-existing\tpackage.')\n\treturn package\n","get the comment app as defined in the settings ."] (predictor.py:56, main())
[2020-11-20 23:29:01]    INFO >> ["def getGeometryOutput(elementNode):\n\tderivation = HeightmapDerivation(elementNode)\n\theightGrid = derivation.heightGrid\n\tif (derivation.fileName != ''):\n\t\theightGrid = getHeightGrid(archive.getAbsoluteFolderPath(elementNode.getOwnerDocument().fileName, derivation.fileName))\n\treturn getGeometryOutputByHeightGrid(derivation, elementNode, heightGrid)\n","get vector3 vertexes from attribute dictionary ."] (predictor.py:56, main())
[2020-11-20 23:29:02]    INFO >> ["def changequery(**kw):\n\tquery = input(_method='get')\n\tfor (k, v) in kw.iteritems():\n\t\tif (v is None):\n\t\t\tquery.pop(k, None)\n\t\telse:\n\t\t\tquery[k] = v\n\tout = ctx.path\n\tif query:\n\t\tout += ('?' + urllib.urlencode(query))\n\treturn out\n","imagine youre at \/foo?a=1&b=2 ."] (predictor.py:56, main())
[2020-11-20 23:29:03]    INFO >> ["def splitnport(host, defport=(-1)):\n\tglobal _nportprog\n\tif (_nportprog is None):\n\t\t_nportprog = re.compile('^(.*):(.*)$')\n\tmatch = _nportprog.match(host)\n\tif match:\n\t\t(host, port) = match.group(1, 2)\n\t\tif port:\n\t\t\ttry:\n\t\t\t\tnport = int(port)\n\t\t\texcept ValueError:\n\t\t\t\tnport = None\n\t\t\treturn (host, nport)\n\treturn (host, defport)\n","split host and port ."] (predictor.py:56, main())
[2020-11-20 23:29:03]    INFO >> ["def hash_password(password):\n\treturn hash_password_PBKDF2(password)\n","hash a password ."] (predictor.py:56, main())
[2020-11-20 23:29:03]    INFO >> ["def get_operation_data(year, quarter):\n\tif (ct._check_input(year, quarter) is True):\n\t\tct._write_head()\n\t\tdata = _get_operation_data(year, quarter, 1, pd.DataFrame())\n\t\tif (data is not None):\n\t\t\tdata['code'] = data['code'].map((lambda x: str(x).zfill(6)))\n\t\treturn data\n","parameters year:int \u5e74\u5ea6 e ."] (predictor.py:56, main())
[2020-11-20 23:29:04]    INFO >> ["def saveNZB(nzbName, nzbString):\n\ttry:\n\t\twith io.open((nzbName + u'.nzb'), u'w') as nzb_fh:\n\t\t\tnzb_fh.write(nzbString)\n\texcept EnvironmentError as e:\n\t\tsickrage.srCore.srLogger.error(u'Unable\tto\tsave\tNZB:\t{}'.format(e.message))\n","save nzb to disk ."] (predictor.py:56, main())
[2020-11-20 23:29:04]    INFO >> ["def action_peek_json(body):\n\ttry:\n\t\tdecoded = jsonutils.loads(body)\n\texcept ValueError:\n\t\tmsg = _('cannot\tunderstand\tJSON')\n\t\traise exception.MalformedRequestBody(reason=msg)\n\tif (len(decoded) != 1):\n\t\tmsg = _('too\tmany\tbody\tkeys')\n\t\traise exception.MalformedRequestBody(reason=msg)\n\treturn list(decoded.keys())[0]\n","determine action to invoke ."] (predictor.py:56, main())
[2020-11-20 23:29:05]    INFO >> ["def get_gem_classified():\n\tdf = fd.get_stock_basics()\n\tdf.reset_index(level=0, inplace=True)\n\tdf = df[ct.FOR_CLASSIFY_B_COLS]\n\tdf = df.ix[(df.code.str[0] == '3')]\n\tdf = df.sort('code').reset_index(drop=True)\n\treturn df\n","return dataframe code :\u80a1\u7968\u4ee3\u7801 name :\u80a1\u7968\u540d\u79f0 ."] (predictor.py:56, main())
[2020-11-20 23:29:05]    INFO >> ["def get_env_var(key):\n\tif (not hasattr(os, 'environ')):\n\t\traise Exception('os.environ\tnot\timplemented!')\n\tl = [os.environ[x] for x in os.environ.keys() if (x.lower() == key.lower())]\n\tif (len(l) > 0):\n\t\treturn l[0]\n\telse:\n\t\treturn None\n","returns the environment variable denoted by key ."] (predictor.py:56, main())
[2020-11-20 23:29:06]    INFO >> ["def _update_query_params(uri, params):\n\tparts = urllib.parse.urlparse(uri)\n\tquery_params = dict(urllib.parse.parse_qsl(parts.query))\n\tquery_params.update(params)\n\tnew_parts = parts._replace(query=urllib.parse.urlencode(query_params))\n\treturn urllib.parse.urlunparse(new_parts)\n","updates a uri with new query parameters ."] (predictor.py:56, main())
[2020-11-20 23:29:06]    INFO >> ["def hooks_namespace(k, v):\n\thookpoint = k.split('.', 1)[0]\n\tif isinstance(v, text_or_bytes):\n\t\tv = cherrypy.lib.attributes(v)\n\tif (not isinstance(v, Hook)):\n\t\tv = Hook(v)\n\tcherrypy.serving.request.hooks[hookpoint].append(v)\n","attach bare hooks declared in config ."] (predictor.py:56, main())
[2020-11-20 23:29:07]    INFO >> ["def getFloatFromCharacterSplitLine(character, splitLine):\n\tlineFromCharacter = gcodec.getStringFromCharacterSplitLine(character, splitLine)\n\tif (lineFromCharacter == None):\n\t\treturn None\n\treturn float(lineFromCharacter)\n","get the float after the first occurence of the character in the split line ."] (predictor.py:56, main())
[2020-11-20 23:29:09]    INFO >> ["def families(root=None):\n\tif (not root):\n\t\troot = Tkinter._default_root\n\treturn root.tk.splitlist(root.tk.call('font', 'families'))\n","get font families ."] (predictor.py:56, main())
[2020-11-20 23:29:09]    INFO >> ["def _getpass(prompt):\n\timport getpass\n\ttry:\n\t\treturn getpass.getpass(prompt)\n\texcept IOError as e:\n\t\tif (e.errno == errno.EINTR):\n\t\t\traise KeyboardInterrupt\n\t\traise\n\texcept EOFError:\n\t\traise KeyboardInterrupt\n","helper to turn ioerrors into keyboardinterrupts ."] (predictor.py:56, main())
[2020-11-20 23:29:10]    INFO >> ["def W3CDTF_to_datetime(formatted_string):\n\tmatch = re.match(RE_W3CDTF, formatted_string)\n\tdigits = list(map(int, match.groups()[:6]))\n\treturn datetime.datetime(*digits)\n","convert from a timestamp string to a datetime object ."] (predictor.py:56, main())
[2020-11-20 23:29:10]    INFO >> ["def _get_target_port(iscsi_string):\n\tif (iscsi_string and (':' in iscsi_string)):\n\t\treturn iscsi_string.split(':')[1]\n\treturn CONF.xenserver.target_port\n","retrieve target port ."] (predictor.py:56, main())
[2020-11-20 23:29:10]    INFO >> ["def get_ha1_dict(user_ha1_dict):\n\tdef get_ha1(realm, username):\n\t\treturn user_ha1_dict.get(user)\n\treturn get_ha1\n","returns a get_ha1 function which obtains a ha1 password hash from a dictionary of the form: {username : ha1} ."] (predictor.py:56, main())
[2020-11-20 23:29:11]    INFO >> ["def getPackedGeometryOutputByLoop(elementNode, sideLoop):\n\tsideLoop.rotate(elementNode)\n\treturn getGeometryOutputByManipulation(elementNode, sideLoop)\n","get packed geometry output by side loop ."] (predictor.py:56, main())
[2020-11-20 23:29:11]    INFO >> ["def matrix(name=None, dtype=None):\n\tif (dtype is None):\n\t\tdtype = config.floatX\n\ttype = TensorType(dtype, (False, False))\n\treturn type(name)\n","return a symbolic matrix variable ."] (predictor.py:56, main())
[2020-11-20 23:29:12]    INFO >> ["def get_organization(organization_id):\n\tif (not organizations_enabled()):\n\t\treturn []\n\tfrom organizations import api as organizations_api\n\treturn organizations_api.get_organization(organization_id)\n","client api operation adapter\/wrapper ."] (predictor.py:56, main())
[2020-11-20 23:29:12]    INFO >> ["def addMenuEntitiesToMenu(menu, menuEntities):\n\tfor menuEntity in menuEntities:\n\t\tmenuEntity.addToMenu(menu)\n","add the menu entities to the menu ."] (predictor.py:56, main())
[2020-11-20 23:29:13]    INFO >> ["def test_ada_init():\n\tratio = 'auto'\n\tada = ADASYN(ratio=ratio, random_state=RND_SEED)\n\tassert_equal(ada.random_state, RND_SEED)\n","test the initialisation of the object ."] (predictor.py:56, main())
[2020-11-20 23:29:13]    INFO >> ["def _organize_states_for_post_update(base_mapper, states, uowtransaction):\n\treturn list(_connections_for_states(base_mapper, uowtransaction, states))\n","make an initial pass across a set of states for update corresponding to post_update ."] (predictor.py:56, main())
[2020-11-20 23:29:13]    INFO >> ["def scopes_to_string(scopes):\n\tif isinstance(scopes, six.string_types):\n\t\treturn scopes\n\telse:\n\t\treturn '\t'.join(scopes)\n","converts scope value to a string ."] (predictor.py:56, main())
[2020-11-20 23:29:15]    INFO >> ["def pretty_name(name):\n\tif (not name):\n\t\treturn ''\n\treturn name.replace('_', '\t').capitalize()\n","converts first_name to first name ."] (predictor.py:56, main())
[2020-11-20 23:29:16]    INFO >> ["def is_hop_by_hop(header_name):\n\treturn (header_name.lower() in _hop_headers)\n","return true if header_name is an http\/1 ."] (predictor.py:56, main())
[2020-11-20 23:29:16]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:29:17]    INFO >> ["def is_server_error(status):\n\treturn ((500 <= status) and (status <= 599))\n","check if http status code is server error ."] (predictor.py:56, main())
[2020-11-20 23:29:17]    INFO >> ["def _p(pp, name):\n\treturn ('%s_%s' % (pp, name))\n","make prefix-appended name ."] (predictor.py:56, main())
[2020-11-20 23:29:17]    INFO >> ["def iteritems_compat(d):\n\treturn iter(getattr(d, _iteritems)())\n","return an iterator over the pairs of a dictionary ."] (predictor.py:56, main())
[2020-11-20 23:29:18]    INFO >> ["def getNewRepository():\n\treturn ExportRepository()\n","get new repository ."] (predictor.py:56, main())
[2020-11-20 23:29:18]    INFO >> ["def getNewRepository():\n\treturn ExportRepository()\n","get new repository ."] (predictor.py:56, main())
[2020-11-20 23:29:19]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:29:20]    INFO >> ["def create_login_url(dest_url=None, _auth_domain=None, federated_identity=None):\n\treq = user_service_pb.CreateLoginURLRequest()\n\tresp = user_service_pb.CreateLoginURLResponse()\n\treq.set_destination_url(dest_url)\n\tif _auth_domain:\n\t\treq.set_auth_domain(_auth_domain)\n\tif federated_identity:\n\t\treq.set_federated_identity(federated_identity)\n\ttry:\n\t\tapiproxy_stub_map.MakeSyncCall('user', 'CreateLoginURL', req, resp)\n\texcept apiproxy_errors.ApplicationError as e:\n\t\tif (e.application_error == user_service_pb.UserServiceError.REDIRECT_URL_TOO_LONG):\n\t\t\traise RedirectTooLongError\n\t\telif (e.application_error == user_service_pb.UserServiceError.NOT_ALLOWED):\n\t\t\traise NotAllowedError\n\t\telse:\n\t\t\traise e\n\treturn resp.login_url()\n","computes the login url for redirection ."] (predictor.py:56, main())
[2020-11-20 23:29:21]    INFO >> ["def serialize_remote_exception(failure_info, log_failure=True):\n\ttb = traceback.format_exception(*failure_info)\n\tfailure = failure_info[1]\n\tif log_failure:\n\t\tLOG.error(_('Returning\texception\t%s\tto\tcaller'), six.text_type(failure))\n\t\tLOG.error(tb)\n\tkwargs = {}\n\tif hasattr(failure, 'kwargs'):\n\t\tkwargs = failure.kwargs\n\tcls_name = str(failure.__class__.__name__)\n\tmod_name = str(failure.__class__.__module__)\n\tif (cls_name.endswith(_REMOTE_POSTFIX) and mod_name.endswith(_REMOTE_POSTFIX)):\n\t\tcls_name = cls_name[:(- len(_REMOTE_POSTFIX))]\n\t\tmod_name = mod_name[:(- len(_REMOTE_POSTFIX))]\n\tdata = {'class': cls_name, 'module': mod_name, 'message': six.text_type(failure), 'tb': tb, 'args': failure.args, 'kwargs': kwargs}\n\tjson_data = jsonutils.dumps(data)\n\treturn json_data\n","prepares exception data to be sent over rpc ."] (predictor.py:56, main())
[2020-11-20 23:29:21]    INFO >> ["def _dnsname_match(dn, hostname, max_wildcards=1):\n\tpats = []\n\tif (not dn):\n\t\treturn False\n\tparts = dn.split('.')\n\tleftmost = parts[0]\n\twildcards = leftmost.count('*')\n\tif (wildcards > max_wildcards):\n\t\traise CertificateError(('too\tmany\twildcards\tin\tcertificate\tDNS\tname:\t' + repr(dn)))\n\tif (not wildcards):\n\t\treturn (dn.lower() == hostname.lower())\n\tif (leftmost == '*'):\n\t\tpats.append('[^.]+')\n\telif (leftmost.startswith('xn--') or hostname.startswith('xn--')):\n\t\tpats.append(re.escape(leftmost))\n\telse:\n\t\tpats.append(re.escape(leftmost).replace('\\\\*', '[^.]*'))\n\tfor frag in parts[1:]:\n\t\tpats.append(re.escape(frag))\n\tpat = re.compile((('\\\\A' + '\\\\.'.join(pats)) + '\\\\Z'), re.IGNORECASE)\n\treturn pat.match(hostname)\n","matching according to rfc 6125 ."] (predictor.py:56, main())
[2020-11-20 23:29:21]    INFO >> ["def data_to_token_ids(data_path, target_path, vocabulary_path, tokenizer=None, normalize_digits=True, UNK_ID=3, _DIGIT_RE=re.compile('\\\\d')):\n\tif (not gfile.Exists(target_path)):\n\t\tprint ('Tokenizing\tdata\tin\t%s' % data_path)\n\t\t(vocab, _) = initialize_vocabulary(vocabulary_path)\n\t\twith gfile.GFile(data_path, mode='rb') as data_file:\n\t\t\twith gfile.GFile(target_path, mode='w') as tokens_file:\n\t\t\t\tcounter = 0\n\t\t\t\tfor line in data_file:\n\t\t\t\t\tcounter += 1\n\t\t\t\t\tif ((counter % 100000) == 0):\n\t\t\t\t\t\tprint ('\t\ttokenizing\tline\t%d' % counter)\n\t\t\t\t\ttoken_ids = sentence_to_token_ids(line, vocab, tokenizer, normalize_digits, UNK_ID=UNK_ID, _DIGIT_RE=_DIGIT_RE)\n\t\t\t\t\ttokens_file.write(('\t'.join([str(tok) for tok in token_ids]) + '\\n'))\n\telse:\n\t\tprint ('Target\tpath\t%s\texists' % target_path)\n","tokenize data file and turn into token-ids using given vocabulary file ."] (predictor.py:56, main())
[2020-11-20 23:29:21]    INFO >> ["def _patch_multiple(target, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs):\n\tdef g_importer():\n\t\treturn _importer(target)\n\tdef g_target():\n\t\treturn target\n\tif (type(target) in (unicode, str)):\n\t\tgetter = g_importer\n\telse:\n\t\tgetter = g_target\n\tif (not kwargs):\n\t\traise ValueError('Must\tsupply\tat\tleast\tone\tkeyword\targument\twith\tpatch.multiple')\n\titems = list(kwargs.items())\n\t(attribute, new) = items[0]\n\tpatcher = _patch(getter, attribute, new, spec, create, spec_set, autospec, new_callable, {})\n\tpatcher.attribute_name = attribute\n\tfor (attribute, new) in items[1:]:\n\t\tthis_patcher = _patch(getter, attribute, new, spec, create, spec_set, autospec, new_callable, {})\n\t\tthis_patcher.attribute_name = attribute\n\t\tpatcher.additional_patchers.append(this_patcher)\n\treturn patcher\n","perform multiple patches in a single call ."] (predictor.py:56, main())
[2020-11-20 23:29:22]    INFO >> ["def select(rlist, wlist, xlist, timeout=None):\n\tallevents = []\n\ttimeout = Timeout.start_new(timeout)\n\tresult = SelectResult()\n\ttry:\n\t\ttry:\n\t\t\tfor readfd in rlist:\n\t\t\t\tallevents.append(core.read_event(get_fileno(readfd), result.update, arg=readfd))\n\t\t\tfor writefd in wlist:\n\t\t\t\tallevents.append(core.write_event(get_fileno(writefd), result.update, arg=writefd))\n\t\texcept IOError as ex:\n\t\t\traise error(*ex.args)\n\t\tresult.event.wait(timeout=timeout)\n\t\treturn (result.read, result.write, [])\n\tfinally:\n\t\tfor evt in allevents:\n\t\t\tevt.cancel()\n\t\ttimeout.cancel()\n","an implementation of :meth:select ."] (predictor.py:56, main())
[2020-11-20 23:29:23]    INFO >> ["def file_upload_view_verify(request):\n\tform_data = request.POST.copy()\n\tform_data.update(request.FILES)\n\tfor (key, value) in form_data.items():\n\t\tif key.endswith(u'_hash'):\n\t\t\tcontinue\n\t\tif ((key + u'_hash') not in form_data):\n\t\t\tcontinue\n\t\tsubmitted_hash = form_data[(key + u'_hash')]\n\t\tif isinstance(value, UploadedFile):\n\t\t\tnew_hash = hashlib.sha1(value.read()).hexdigest()\n\t\telse:\n\t\t\tnew_hash = hashlib.sha1(force_bytes(value)).hexdigest()\n\t\tif (new_hash != submitted_hash):\n\t\t\treturn HttpResponseServerError()\n\tlargefile = request.FILES[u'file_field2']\n\tobj = FileModel()\n\tobj.testfile.save(largefile.name, largefile)\n\treturn HttpResponse(u'')\n","use the sha digest hash to verify the uploaded contents ."] (predictor.py:56, main())
[2020-11-20 23:29:24]    INFO >> ["def initialize_decorator(init):\n\tdef initialize(self, *args, **kwargs):\n\t\tcls = type(self)\n\t\tfor (k, v) in kwargs.items():\n\t\t\tif hasattr(cls, k):\n\t\t\t\tattr = getattr(cls, k)\n\t\t\t\tif isinstance(attr, InstrumentedAttribute):\n\t\t\t\t\tcolumn = attr.property.columns[0]\n\t\t\t\t\tif isinstance(column.type, String):\n\t\t\t\t\t\tif (not isinstance(v, six.text_type)):\n\t\t\t\t\t\t\tv = six.text_type(v)\n\t\t\t\t\t\tif (column.type.length and (column.type.length < len(v))):\n\t\t\t\t\t\t\traise exception.StringLengthExceeded(string=v, type=k, length=column.type.length)\n\t\tinit(self, *args, **kwargs)\n\treturn initialize\n","ensure that the length of string field do not exceed the limit ."] (predictor.py:56, main())
[2020-11-20 23:29:26]    INFO >> ["def insert_data(test_case, host, port):\n\td = get_postgres_connection(host, port)\n\tdef create_database(connection):\n\t\tconnection.autocommit = True\n\t\tcursor = connection.cursor()\n\t\tcursor.execute('CREATE\tDATABASE\tflockertest;')\n\t\tcursor.close()\n\t\tconnection.close()\n\td.addCallback(create_database)\n\td.addCallback((lambda _: get_postgres_connection(host, port, u'flockertest')))\n\tdef add_data(connection):\n\t\tcursor = connection.cursor()\n\t\tcursor.execute('CREATE\tTABLE\ttesttable\t(testcolumn\tint);')\n\t\tcursor.execute('INSERT\tINTO\ttesttable\t(testcolumn)\tVALUES\t(123);')\n\t\tconnection.commit()\n\t\tconnection.close()\n\td.addCallback(add_data)\n\treturn d\n","insert some data into the database ."] (predictor.py:56, main())
[2020-11-20 23:29:26]    INFO >> ["def make_step_decorator(context, instance, update_instance_progress, total_offset=0):\n\tstep_info = dict(total=total_offset, current=0)\n\tdef bump_progress():\n\t\tstep_info['current'] += 1\n\t\tupdate_instance_progress(context, instance, step_info['current'], step_info['total'])\n\tdef step_decorator(f):\n\t\tstep_info['total'] += 1\n\t\t@functools.wraps(f)\n\t\tdef inner(*args, **kwargs):\n\t\t\trv = f(*args, **kwargs)\n\t\t\tbump_progress()\n\t\t\treturn rv\n\t\treturn inner\n\treturn step_decorator\n","factory to create a decorator that records instance progress as a series of discrete steps ."] (predictor.py:56, main())
[2020-11-20 23:29:27]    INFO >> ["def read_cached_file(filename, cache_info, reload_func=None):\n\tmtime = os.path.getmtime(filename)\n\tif ((not cache_info) or (mtime != cache_info.get('mtime'))):\n\t\tLOG.debug((_('Reloading\tcached\tfile\t%s') % filename))\n\t\twith open(filename) as fap:\n\t\t\tcache_info['data'] = fap.read()\n\t\tcache_info['mtime'] = mtime\n\t\tif reload_func:\n\t\t\treload_func(cache_info['data'])\n\treturn cache_info['data']\n","read from a file if it has been modified ."] (predictor.py:56, main())
[2020-11-20 23:29:27]    INFO >> ["def with_polymorphic(base, classes, selectable=False, flat=False, polymorphic_on=None, aliased=False, innerjoin=False, _use_mapper_path=False):\n\tprimary_mapper = _class_to_mapper(base)\n\t(mappers, selectable) = primary_mapper._with_polymorphic_args(classes, selectable, innerjoin=innerjoin)\n\tif (aliased or flat):\n\t\tselectable = selectable.alias(flat=flat)\n\treturn AliasedClass(base, selectable, with_polymorphic_mappers=mappers, with_polymorphic_discriminator=polymorphic_on, use_mapper_path=_use_mapper_path)\n","produce an :class: ."] (predictor.py:56, main())
[2020-11-20 23:29:28]    INFO >> ["def random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):\n\tif (dtype is None):\n\t\tdtype = floatx()\n\tshape = tuple(map(int, shape))\n\ttf_dtype = _convert_string_dtype(dtype)\n\tif (seed is None):\n\t\tseed = np.random.randint(1000000000.0)\n\tvalue = tf.random_normal_initializer(mean, scale, dtype=tf_dtype, seed=seed)(shape)\n\treturn variable(value, dtype=dtype, name=name)\n","instantiates an keras variable filled with samples drawn from a normal distribution and returns it ."] (predictor.py:56, main())
[2020-11-20 23:29:28]    INFO >> ["def copy_missing_vector(a, b, missing, inplace=False, prefix=None):\n\tif (prefix is None):\n\t\tprefix = find_best_blas_type((a, b))[0]\n\tcopy = prefix_copy_missing_vector_map[prefix]\n\tif (not inplace):\n\t\tb = np.copy(b, order='F')\n\ttry:\n\t\tif (not a.is_f_contig()):\n\t\t\traise ValueError()\n\texcept:\n\t\ta = np.asfortranarray(a)\n\tcopy(a, b, np.asfortranarray(missing))\n\treturn b\n","reorder the elements of a time-varying vector where all non-missing values are in the first elements of the vector ."] (predictor.py:56, main())
[2020-11-20 23:29:30]    INFO >> ["def find_drum_group_device(track_or_chain):\n\tinstrument = find_if((lambda d: (d.type == Live.Device.DeviceType.instrument)), track_or_chain.devices)\n\tif instrument:\n\t\tif instrument.can_have_drum_pads:\n\t\t\treturn instrument\n\t\telif instrument.can_have_chains:\n\t\t\treturn find_if(bool, imap(find_drum_group_device, instrument.chains))\n","looks up recursively for a drum_group device in the track ."] (predictor.py:56, main())
[2020-11-20 23:29:30]    INFO >> ["def messageid(uniq=None, N=idGenerator().next):\n\tdatetime = time.strftime('%Y%m%d%H%M%S', time.gmtime())\n\tpid = os.getpid()\n\trand = random.randrange(((2 ** 31L) - 1))\n\tif (uniq is None):\n\t\tuniq = ''\n\telse:\n\t\tuniq = ('.' + uniq)\n\treturn ('<%s.%s.%s%s.%s@%s>' % (datetime, pid, rand, uniq, N(), DNSNAME))\n","return a globally unique random string in rfc 2822 message-id format <datetime ."] (predictor.py:56, main())
[2020-11-20 23:29:30]    INFO >> ["@environmentfilter\ndef do_attr(environment, obj, name):\n\ttry:\n\t\tname = str(name)\n\texcept UnicodeError:\n\t\tpass\n\telse:\n\t\ttry:\n\t\t\tvalue = getattr(obj, name)\n\t\texcept AttributeError:\n\t\t\tpass\n\t\telse:\n\t\t\tif (environment.sandboxed and (not environment.is_safe_attribute(obj, name, value))):\n\t\t\t\treturn environment.unsafe_undefined(obj, name)\n\t\t\treturn value\n\treturn environment.undefined(obj=obj, name=name)\n","get an attribute of an object ."] (predictor.py:56, main())
[2020-11-20 23:29:31]    INFO >> ["def check_random_state(seed):\n\tif ((seed is None) or (seed is np.random)):\n\t\treturn np.random.mtrand._rand\n\tif isinstance(seed, (int, np.integer)):\n\t\treturn np.random.RandomState(seed)\n\tif isinstance(seed, np.random.RandomState):\n\t\treturn seed\n\traise ValueError(('%r\tcannot\tbe\tused\tto\tseed\ta\tnumpy.random.RandomState\tinstance' % seed))\n","turn seed into a np ."] (predictor.py:56, main())
[2020-11-20 23:29:31]    INFO >> ["def picknthweekday(year, month, dayofweek, hour, minute, whichweek):\n\tfirst = datetime.datetime(year, month, 1, hour, minute)\n\tweekdayone = first.replace(day=(((dayofweek - first.isoweekday()) % 7) + 1))\n\twd = (weekdayone + ((whichweek - 1) * ONEWEEK))\n\tif (wd.month != month):\n\t\twd -= ONEWEEK\n\treturn wd\n","dayofweek == 0 means sunday ."] (predictor.py:56, main())
[2020-11-20 23:29:32]    INFO >> ["def bdate_range(start=None, end=None, periods=None, freq='B', tz=None, normalize=True, name=None, closed=None, **kwargs):\n\treturn DatetimeIndex(start=start, end=end, periods=periods, freq=freq, tz=tz, normalize=normalize, name=name, closed=closed, **kwargs)\n","return a fixed frequency datetime index ."] (predictor.py:56, main())
[2020-11-20 23:29:33]    INFO >> ["def wrapper(func, *args, **kwds):\n\tres = None\n\ttry:\n\t\tstdscr = curses.initscr()\n\t\tcurses.noecho()\n\t\tcurses.cbreak()\n\t\tstdscr.keypad(1)\n\t\ttry:\n\t\t\tcurses.start_color()\n\t\texcept:\n\t\t\tpass\n\t\treturn func(stdscr, *args, **kwds)\n\tfinally:\n\t\tstdscr.keypad(0)\n\t\tcurses.echo()\n\t\tcurses.nocbreak()\n\t\tcurses.endwin()\n","wrapper function that initializes curses and calls another function ."] (predictor.py:56, main())
[2020-11-20 23:29:33]    INFO >> ["def changequery(**kw):\n\tquery = input(_method='get')\n\tfor (k, v) in kw.iteritems():\n\t\tif (v is None):\n\t\t\tquery.pop(k, None)\n\t\telse:\n\t\t\tquery[k] = v\n\tout = ctx.path\n\tif query:\n\t\tout += ('?' + urllib.urlencode(query))\n\treturn out\n","imagine youre at \/foo?a=1&b=2 ."] (predictor.py:56, main())
[2020-11-20 23:29:34]    INFO >> ["def cross_from_above(x, threshold):\n\tx = np.asarray(x)\n\tind = np.nonzero(((x[:(-1)] >= threshold) & (x[1:] < threshold)))[0]\n\tif len(ind):\n\t\treturn (ind + 1)\n\telse:\n\t\treturn ind\n","return the indices into *x* where *x* crosses some threshold from below ."] (predictor.py:56, main())
[2020-11-20 23:29:34]    INFO >> ["def directory_browser(request, path='\/'):\n\tdirectories = DojoFileStore(path, dirsonly=True, root=request.GET.get('root', '\/')).items()\n\tcontext = directories\n\tcontent = json.dumps(context)\n\treturn HttpResponse(content, content_type='application\/json')\n","this view provides the ajax driven directory browser callback ."] (predictor.py:56, main())
[2020-11-20 23:29:34]    INFO >> ["def locatedExpr(expr):\n\tlocator = Empty().setParseAction((lambda s, l, t: l))\n\treturn Group(((locator('locn_start') + expr('value')) + locator.copy().leaveWhitespace()('locn_end')))\n","helper to decorate a returned token with its starting and ending locations in the input string ."] (predictor.py:56, main())
[2020-11-20 23:29:35]    INFO >> ["@environmentfilter\ndef do_urlize(environment, value, trim_url_limit=None, nofollow=False):\n\trv = urlize(value, trim_url_limit, nofollow)\n\tif environment.autoescape:\n\t\trv = Markup(rv)\n\treturn rv\n","converts urls in plain text into clickable links ."] (predictor.py:56, main())
[2020-11-20 23:29:35]    INFO >> ["def run_migrations_offline():\n\tset_mysql_engine()\n\tkwargs = dict()\n\tif neutron_config.database.connection:\n\t\tkwargs['url'] = neutron_config.database.connection\n\telse:\n\t\tkwargs['dialect_name'] = neutron_config.database.engine\n\tkwargs['include_object'] = include_object\n\tcontext.configure(**kwargs)\n\twith context.begin_transaction():\n\t\tcontext.run_migrations()\n","run migrations in offline mode ."] (predictor.py:56, main())
[2020-11-20 23:29:35]    INFO >> ["def linebreaksbr(value, autoescape=None):\n\tif (autoescape and (not isinstance(value, SafeData))):\n\t\tfrom google.appengine._internal.django.utils.html import escape\n\t\tvalue = escape(value)\n\treturn mark_safe(value.replace('\\n', '<br\t\/>'))\n","converts all newlines in a piece of plain text to html line breaks ."] (predictor.py:56, main())
[2020-11-20 23:29:36]    INFO >> ["def module_to_dict(module, omittable=(lambda k: k.startswith('_'))):\n\treturn dict(((k, repr(v)) for (k, v) in module.__dict__.items() if (not omittable(k))))\n","converts a module namespace to a python dictionary ."] (predictor.py:56, main())
[2020-11-20 23:29:36]    INFO >> ["def _make_sync_call(service, call, request, response):\n\tresp = apiproxy_stub_map.MakeSyncCall(service, call, request, response)\n\tif (resp is not None):\n\t\treturn resp\n\treturn response\n","the apiproxy entry point for a synchronous api call ."] (predictor.py:56, main())
[2020-11-20 23:29:37]    INFO >> ["def get_language_bidi():\n\tfrom django.conf import settings\n\tbase_lang = get_language().split(u'-')[0]\n\treturn (base_lang in settings.LANGUAGES_BIDI)\n","returns selected languages bidi layout ."] (predictor.py:56, main())
[2020-11-20 23:29:37]    INFO >> ["def test_io_error_if_no_replay_file(mocker, replay_test_dir):\n\twith pytest.raises(IOError):\n\t\treplay.load(replay_test_dir, 'no_replay')\n","test that replay ."] (predictor.py:56, main())
[2020-11-20 23:29:38]    INFO >> ["def autocommit(using=None):\n\twarnings.warn('autocommit\tis\tdeprecated\tin\tfavor\tof\tset_autocommit.', PendingDeprecationWarning, stacklevel=2)\n\tdef entering(using):\n\t\tenter_transaction_management(managed=False, using=using)\n\tdef exiting(exc_type, using):\n\t\tleave_transaction_management(using=using)\n\treturn _transaction_func(entering, exiting, using)\n","decorator that activates commit on save ."] (predictor.py:56, main())
[2020-11-20 23:29:38]    INFO >> ["def _XXX(k, n, s):\n\tx = (s % (string.replace(k.__module__, '.', '_'), k.__name__, n))\n\treturn x\n","string manipulation garbage ."] (predictor.py:56, main())
[2020-11-20 23:29:40]    INFO >> ["def default_expire_time():\n\texpire_delta = datetime.timedelta(seconds=CONF.token.expiration)\n\treturn (timeutils.utcnow() + expire_delta)\n","determine when a fresh token should expire ."] (predictor.py:56, main())
[2020-11-20 23:29:40]    INFO >> ["def _bytes_feature(value):\n\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","wrapper for inserting a bytes feature into a sequenceexample proto ."] (predictor.py:56, main())
[2020-11-20 23:29:40]    INFO >> ["def fixed_ip_get_by_host(context, host):\n\treturn IMPL.fixed_ip_get_by_host(context, host)\n","get fixed ips by compute host ."] (predictor.py:56, main())
[2020-11-20 23:29:40]    INFO >> ["def prepare_bearer_uri(token, uri):\n\treturn add_params_to_uri(uri, [(u'access_token', token)])\n","add a bearer token_ to the request uri ."] (predictor.py:56, main())
[2020-11-20 23:29:42]    INFO >> ["def assembleFormattedText(formatted):\n\treturn _textattributes.flatten(formatted, _FormattingState(), 'toMIRCControlCodes')\n","assemble formatted text from structured information ."] (predictor.py:56, main())
[2020-11-20 23:29:42]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:29:43]    INFO >> ["def urlunquote_plus(quoted_url):\n\treturn force_text(unquote_plus(force_str(quoted_url)))\n","a wrapper for pythons urllib ."] (predictor.py:56, main())
[2020-11-20 23:29:43]    INFO >> ["def is_numlike(obj):\n\ttry:\n\t\t(obj + 1)\n\texcept TypeError:\n\t\treturn False\n\telse:\n\t\treturn True\n","return true if *obj* looks like a number ."] (predictor.py:56, main())
[2020-11-20 23:29:44]    INFO >> ["def cr_uid_ids_context(method):\n\tmethod._api = 'cr_uid_ids_context'\n\treturn method\n","decorate a traditional-style method that takes cr ."] (predictor.py:56, main())
[2020-11-20 23:29:44]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:29:44]    INFO >> ["def test_smote_sk_estimator():\n\tcheck_estimator(SMOTETomek)\n","test the sklearn estimator compatibility ."] (predictor.py:56, main())
[2020-11-20 23:29:45]    INFO >> ["def catalog_item():\n\treturn s3_rest_controller('supply', 'catalog_item', csv_template=('supply', 'catalog_item'), csv_stylesheet=('supply', 'catalog_item.xsl'))\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:29:45]    INFO >> ["def stats_data():\n\treturn s3_rest_controller()\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:29:45]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:29:45]    INFO >> ["def incident_type():\n\treturn s3_rest_controller()\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:29:46]    INFO >> ["def type_():\n\treturn Rebulk().rules(TypeProcessor)\n","builder for rebulk object ."] (predictor.py:56, main())
[2020-11-20 23:29:46]    INFO >> ["def getBevelPath(begin, center, close, end, radius):\n\tbeginComplex = begin.dropAxis()\n\tcenterComplex = center.dropAxis()\n\tendComplex = end.dropAxis()\n\tbeginComplexSegmentLength = abs((centerComplex - beginComplex))\n\tendComplexSegmentLength = abs((centerComplex - endComplex))\n\tminimumRadius = lineation.getMinimumRadius(beginComplexSegmentLength, endComplexSegmentLength, radius)\n\tif (minimumRadius <= close):\n\t\treturn [center]\n\tbeginBevel = (center + ((minimumRadius \/ beginComplexSegmentLength) * (begin - center)))\n\tendBevel = (center + ((minimumRadius \/ endComplexSegmentLength) * (end - center)))\n\tif (radius > 0.0):\n\t\treturn [beginBevel, endBevel]\n\tmidpointComplex = (0.5 * (beginBevel.dropAxis() + endBevel.dropAxis()))\n\tspikeComplex = ((centerComplex + centerComplex) - midpointComplex)\n\treturn [beginBevel, Vector3(spikeComplex.real, spikeComplex.imag, center.z), endBevel]\n","get bevel path ."] (predictor.py:56, main())
[2020-11-20 23:29:47]    INFO >> ["def _handle_ns(packageName, path_item):\n\timporter = get_importer(path_item)\n\tif (importer is None):\n\t\treturn None\n\tloader = importer.find_module(packageName)\n\tif (loader is None):\n\t\treturn None\n\tmodule = sys.modules.get(packageName)\n\tif (module is None):\n\t\tmodule = sys.modules[packageName] = types.ModuleType(packageName)\n\t\tmodule.__path__ = []\n\t\t_set_parent_ns(packageName)\n\telif (not hasattr(module, '__path__')):\n\t\traise TypeError('Not\ta\tpackage:', packageName)\n\thandler = _find_adapter(_namespace_handlers, importer)\n\tsubpath = handler(importer, path_item, packageName, module)\n\tif (subpath is not None):\n\t\tpath = module.__path__\n\t\tpath.append(subpath)\n\t\tloader.load_module(packageName)\n\t\tsys_path = [((p and _normalize_cached(p)) or p) for p in sys.path]\n\t\tdef sort_key(p):\n\t\t\tparts = p.split(os.sep)\n\t\t\tparts = parts[:(- (packageName.count('.') + 1))]\n\t\t\treturn sys_path.index(_normalize_cached(os.sep.join(parts)))\n\t\tpath.sort(key=sort_key)\n\t\tmodule.__path__[:] = [_normalize_cached(p) for p in path]\n\treturn subpath\n","ensure that named package includes a subpath of path_item ."] (predictor.py:56, main())
[2020-11-20 23:29:47]    INFO >> ["def break_around_binary_operator(logical_line, tokens):\n\tdef is_binary_operator(token_type, text):\n\t\treturn (((token_type == tokenize.OP) or (text in ['and', 'or'])) and (text not in '()[]{},:.;@=%'))\n\tline_break = False\n\tunary_context = True\n\tfor (token_type, text, start, end, line) in tokens:\n\t\tif (token_type == tokenize.COMMENT):\n\t\t\tcontinue\n\t\tif ((('\\n' in text) or ('\\r' in text)) and (token_type != tokenize.STRING)):\n\t\t\tline_break = True\n\t\telse:\n\t\t\tif (is_binary_operator(token_type, text) and line_break and (not unary_context)):\n\t\t\t\t(yield (start, 'W503\tline\tbreak\tbefore\tbinary\toperator'))\n\t\t\tunary_context = (text in '([{,;')\n\t\t\tline_break = False\n","avoid breaks before binary operators ."] (predictor.py:56, main())
[2020-11-20 23:29:48]    INFO >> ["def addToProfileMenu(profileSelection, profileType, repository):\n\tpluginFileNames = skeinforge_profile.getPluginFileNames()\n\tcraftTypeName = skeinforge_profile.getCraftTypeName()\n\tpluginModule = skeinforge_profile.getCraftTypePluginModule()\n\tprofilePluginSettings = settings.getReadRepository(pluginModule.getNewRepository())\n\tfor pluginFileName in pluginFileNames:\n\t\tskeinforge_profile.ProfileTypeMenuRadio().getFromMenuButtonDisplay(profileType, pluginFileName, repository, (craftTypeName == pluginFileName))\n\tfor profileName in profilePluginSettings.profileList.value:\n\t\tskeinforge_profile.ProfileSelectionMenuRadio().getFromMenuButtonDisplay(profileSelection, profileName, repository, (profileName == profilePluginSettings.profileListbox.value))\n","add a profile menu ."] (predictor.py:56, main())
[2020-11-20 23:29:49]    INFO >> ["def learn_cache_key(request, response, cache_timeout=None, key_prefix=None, cache=None):\n\tif (key_prefix is None):\n\t\tkey_prefix = settings.CACHE_MIDDLEWARE_KEY_PREFIX\n\tif (cache_timeout is None):\n\t\tcache_timeout = settings.CACHE_MIDDLEWARE_SECONDS\n\tcache_key = _generate_cache_header_key(key_prefix, request)\n\tif (cache is None):\n\t\tcache = get_cache(settings.CACHE_MIDDLEWARE_ALIAS)\n\tif response.has_header('Vary'):\n\t\theaderlist = [('HTTP_' + header.upper().replace('-', '_')) for header in cc_delim_re.split(response['Vary'])]\n\t\tcache.set(cache_key, headerlist, cache_timeout)\n\t\treturn _generate_cache_key(request, request.method, headerlist, key_prefix)\n\telse:\n\t\tcache.set(cache_key, [], cache_timeout)\n\t\treturn _generate_cache_key(request, request.method, [], key_prefix)\n","learns what headers to take into account for some request path from the response object ."] (predictor.py:56, main())
[2020-11-20 23:29:49]    INFO >> ["def _ipconfig_getnode():\n\timport os, re\n\tdirs = ['', 'c:\\\\windows\\\\system32', 'c:\\\\winnt\\\\system32']\n\ttry:\n\t\timport ctypes\n\t\tbuffer = ctypes.create_string_buffer(300)\n\t\tctypes.windll.kernel32.GetSystemDirectoryA(buffer, 300)\n\t\tdirs.insert(0, buffer.value.decode('mbcs'))\n\texcept:\n\t\tpass\n\tfor dir in dirs:\n\t\ttry:\n\t\t\tpipe = os.popen((os.path.join(dir, 'ipconfig') + '\t\/all'))\n\t\texcept IOError:\n\t\t\tcontinue\n\t\tfor line in pipe:\n\t\t\tvalue = line.split(':')[(-1)].strip().lower()\n\t\t\tif re.match('([0-9a-f][0-9a-f]-){5}[0-9a-f][0-9a-f]', value):\n\t\t\t\treturn int(value.replace('-', ''), 16)\n","get the hardware address on windows by running ipconfig ."] (predictor.py:56, main())
[2020-11-20 23:29:50]    INFO >> ["def limited(items, request, max_limit=None):\n\tmax_limit = (max_limit or CONF.osapi_max_limit)\n\t(marker, limit, offset) = get_pagination_params(request.GET.copy(), max_limit)\n\trange_end = (offset + (limit or max_limit))\n\treturn items[offset:range_end]\n","return a slice of items according to requested offset and limit ."] (predictor.py:56, main())
[2020-11-20 23:29:50]    INFO >> ["def emboss_piped_AlignIO_convert(alignments, old_format, new_format):\n\tcline = SeqretCommandline(exes['seqret'], sformat=old_format, osformat=new_format, auto=True, filter=True)\n\tchild = subprocess.Popen(str(cline), stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=(sys.platform != 'win32'))\n\ttry:\n\t\tAlignIO.write(alignments, child.stdin, old_format)\n\texcept Exception as err:\n\t\tchild.stdin.close()\n\t\tchild.stderr.close()\n\t\tchild.stdout.close()\n\t\traise\n\tchild.stdin.close()\n\tchild.stderr.close()\n\ttry:\n\t\taligns = list(AlignIO.parse(child.stdout, new_format))\n\texcept Exception as err:\n\t\tchild.stdout.close()\n\t\traise\n\tchild.stdout.close()\n\treturn aligns\n","run seqret ."] (predictor.py:56, main())
[2020-11-20 23:29:51]    INFO >> ["def parse_query_parts(parts, model_cls):\n\tprefixes = {':': dbcore.query.RegexpQuery}\n\tprefixes.update(plugins.queries())\n\tif ('path' in model_cls._fields):\n\t\tpath_parts = []\n\t\tnon_path_parts = []\n\t\tfor s in parts:\n\t\t\tif (s.find(os.sep, 0, s.find(':')) != (-1)):\n\t\t\t\tpath_parts.append(s)\n\t\t\telse:\n\t\t\t\tnon_path_parts.append(s)\n\telse:\n\t\tpath_parts = ()\n\t\tnon_path_parts = parts\n\t(query, sort) = dbcore.parse_sorted_query(model_cls, non_path_parts, prefixes)\n\tif path_parts:\n\t\tquery.subqueries += [PathQuery('path', s) for s in path_parts]\n\treturn (query, sort)\n","given a beets query string as a list of components ."] (predictor.py:56, main())
[2020-11-20 23:29:52]    INFO >> ["def make_runserver(app_factory, hostname='localhost', port=5000, use_reloader=False, use_debugger=False, use_evalex=True, threaded=False, processes=1, static_files=None, extra_files=None, ssl_context=None):\n\t_deprecated()\n\tdef action(hostname=('h', hostname), port=('p', port), reloader=use_reloader, debugger=use_debugger, evalex=use_evalex, threaded=threaded, processes=processes):\n\t\t'Start\ta\tnew\tdevelopment\tserver.'\n\t\tfrom werkzeug.serving import run_simple\n\t\tapp = app_factory()\n\t\trun_simple(hostname, port, app, use_reloader=reloader, use_debugger=debugger, use_evalex=evalex, extra_files=extra_files, reloader_interval=1, threaded=threaded, processes=processes, static_files=static_files, ssl_context=ssl_context)\n\treturn action\n","returns an action callback that spawns a new development server ."] (predictor.py:56, main())
[2020-11-20 23:29:52]    INFO >> ["def was_modified_since(header=None, mtime=0, size=0):\n\ttry:\n\t\tif (header is None):\n\t\t\traise ValueError\n\t\tmatches = re.match('^([^;]+)(;\tlength=([0-9]+))?$', header, re.IGNORECASE)\n\t\theader_mtime = parse_http_date(matches.group(1))\n\t\theader_len = matches.group(3)\n\t\tif (header_len and (int(header_len) != size)):\n\t\t\traise ValueError\n\t\tif (mtime > header_mtime):\n\t\t\traise ValueError\n\texcept (AttributeError, ValueError, OverflowError):\n\t\treturn True\n\treturn False\n","was something modified since the user last downloaded it? header this is the value of the if-modified-since header ."] (predictor.py:56, main())
[2020-11-20 23:29:53]    INFO >> ["def test_url_completion_delete_bookmark(qtmodeltester, config_stub, web_history, quickmarks, bookmarks, qtbot):\n\tconfig_stub.data['completion'] = {'timestamp-format': '%Y-%m-%d', 'web-history-max-items': 2}\n\tmodel = urlmodel.UrlCompletionModel()\n\tqtmodeltester.data_display_may_return_none = True\n\tqtmodeltester.check(model)\n\tview = _mock_view_index(model, 1, 0, qtbot)\n\tmodel.delete_cur_item(view)\n\tassert ('https:\/\/github.com' not in bookmarks.marks)\n\tassert ('https:\/\/python.org' in bookmarks.marks)\n\tassert ('http:\/\/qutebrowser.org' in bookmarks.marks)\n","test deleting a bookmark from the url completion model ."] (predictor.py:56, main())
[2020-11-20 23:29:54]    INFO >> ["def getTetragridTimesOther(firstTetragrid, otherTetragrid):\n\ttetragridTimesOther = []\n\tfor row in xrange(4):\n\t\tmatrixRow = firstTetragrid[row]\n\t\ttetragridTimesOtherRow = []\n\t\ttetragridTimesOther.append(tetragridTimesOtherRow)\n\t\tfor column in xrange(4):\n\t\t\tdotProduct = 0\n\t\t\tfor elementIndex in xrange(4):\n\t\t\t\tdotProduct += (matrixRow[elementIndex] * otherTetragrid[elementIndex][column])\n\t\t\ttetragridTimesOtherRow.append(dotProduct)\n\treturn tetragridTimesOther\n","get this matrix multiplied by the other matrix ."] (predictor.py:56, main())
[2020-11-20 23:29:55]    INFO >> ["def Deserializer(stream_or_string, **options):\n\tif isinstance(stream_or_string, basestring):\n\t\tstream = StringIO(stream_or_string)\n\telse:\n\t\tstream = stream_or_string\n\tfor obj in PythonDeserializer(yaml.load(stream), **options):\n\t\t(yield obj)\n","deserialize a stream or string of yaml data ."] (predictor.py:56, main())
[2020-11-20 23:29:56]    INFO >> ["def get_kinds(start=None, end=None):\n\tq = Kind.query()\n\tif ((start is not None) and (start != '')):\n\t\tq = q.filter((Kind.key >= Kind.key_for_kind(start)))\n\tif (end is not None):\n\t\tif (end == ''):\n\t\t\treturn []\n\t\tq = q.filter((Kind.key < Kind.key_for_kind(end)))\n\treturn [x.kind_name for x in q]\n","return all kinds in the specified range ."] (predictor.py:56, main())
[2020-11-20 23:29:56]    INFO >> ["def test_write_twoline_no_bookend():\n\tout = StringIO()\n\tascii.write(dat, out, Writer=ascii.FixedWidthTwoLine, bookend=True, delimiter='|')\n\tassert_equal_splitlines(out.getvalue(), '|Col1|\t\t\t\t\tCol2|Col3|Col4|\\n|----|---------|----|----|\\n|\t1.2|\t\t\"hello\"|\t\t\t1|\t\t\ta|\\n|\t2.4|\\'s\tworlds|\t\t\t2|\t\t\t2|\\n')\n","write a table as a fixed width table with no bookend ."] (predictor.py:56, main())
[2020-11-20 23:29:57]    INFO >> ["def _NewIndexFromIndexSpecPb(index_spec_pb):\n\tsource = _SOURCE_PB_TO_SOURCES_MAP.get(index_spec_pb.source())\n\tindex = None\n\tif index_spec_pb.has_namespace():\n\t\tindex = Index(name=index_spec_pb.name(), namespace=index_spec_pb.namespace(), source=source)\n\telse:\n\t\tindex = Index(name=index_spec_pb.name(), source=source)\n\treturn index\n","creates an index from a search_service_pb ."] (predictor.py:56, main())
[2020-11-20 23:29:57]    INFO >> ["def list_subscriptions(document_class, sub_id_start='', topic=None, max_results=DEFAULT_LIST_SUBSCRIPTIONS_MAX_RESULTS, expires_before=None):\n\tfrom google.appengine.ext import db\n\tif issubclass(document_class, db.Model):\n\t\ttopic = _get_document_topic(document_class, topic)\n\telif issubclass(document_class, datastore.Entity):\n\t\tif (not topic):\n\t\t\traise TopicNotSpecified()\n\telse:\n\t\traise DocumentTypeError()\n\treturn prospective_search_admin.list_subscriptions(topic, max_results, None, sub_id_start, expires_before)\n","list subscriptions on a topic ."] (predictor.py:56, main())
[2020-11-20 23:29:57]    INFO >> ["def split_named_range(range_string):\n\tfor range_string in SPLIT_NAMED_RANGE_RE.split(range_string)[1::2]:\n\t\tmatch = NAMED_RANGE_RE.match(range_string)\n\t\tif (match is None):\n\t\t\traise NamedRangeException(('Invalid\tnamed\trange\tstring:\t\"%s\"' % range_string))\n\t\telse:\n\t\t\tmatch = match.groupdict()\n\t\t\tsheet_name = (match['quoted'] or match['notquoted'])\n\t\t\txlrange = match['range']\n\t\t\tsheet_name = sheet_name.replace(\"''\", \"'\")\n\t\t\t(yield (sheet_name, xlrange))\n","separate a named range into its component parts ."] (predictor.py:56, main())
[2020-11-20 23:29:57]    INFO >> ["def test_sobel_h_horizontal():\n\t(i, j) = np.mgrid[(-5):6, (-5):6]\n\timage = (i >= 0).astype(float)\n\tresult = filters.sobel_h(image)\n\ti[(np.abs(j) == 5)] = 10000\n\tassert np.all((result[(i == 0)] == 1))\n\tassert np.all((result[(np.abs(i) > 1)] == 0))\n","horizontal sobel on an edge should be a horizontal line ."] (predictor.py:56, main())
[2020-11-20 23:29:58]    INFO >> ["def get_random_string(length=12, allowed_chars=u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'):\n\tif (not using_sysrandom):\n\t\trandom.seed(hashlib.sha256((u'%s%s%s' % (random.getstate(), time.time(), settings.SECRET_KEY)).encode(u'utf-8')).digest())\n\treturn u''.join([random.choice(allowed_chars) for i in range(length)])\n","returns a securely generated random string ."] (predictor.py:56, main())
[2020-11-20 23:29:58]    INFO >> ["def _getAccessibleAttribute(attributeName, elementNode):\n\tif (attributeName in globalGetAccessibleAttributeSet):\n\t\treturn getattr(Document(elementNode), attributeName, None)\n\treturn None\n","get the accessible attribute ."] (predictor.py:56, main())
[2020-11-20 23:29:58]    INFO >> ["def cov_hc3(results):\n\th = np.diag(np.dot(results.model.exog, np.dot(results.normalized_cov_params, results.model.exog.T)))\n\thet_scale = ((results.resid \/ (1 - h)) ** 2)\n\tcov_hc3_ = _HCCM(results, het_scale)\n\treturn cov_hc3_\n","see statsmodels ."] (predictor.py:56, main())
[2020-11-20 23:29:59]    INFO >> ["def webob_factory(url):\n\tbase_url = url\n\tdef web_request(url, method=None, body=None):\n\t\treq = webob.Request.blank(('%s%s' % (base_url, url)))\n\t\tif method:\n\t\t\treq.content_type = 'application\/json'\n\t\t\treq.method = method\n\t\tif body:\n\t\t\treq.body = jsonutils.dumps(body)\n\t\treturn req\n\treturn web_request\n","factory for removing duplicate webob code from tests ."] (predictor.py:56, main())
[2020-11-20 23:29:59]    INFO >> ["def newer_pairwise(sources, targets):\n\tif (len(sources) != len(targets)):\n\t\traise ValueError, \"'sources'\tand\t'targets'\tmust\tbe\tsame\tlength\"\n\tn_sources = []\n\tn_targets = []\n\tfor i in range(len(sources)):\n\t\tif newer(sources[i], targets[i]):\n\t\t\tn_sources.append(sources[i])\n\t\t\tn_targets.append(targets[i])\n\treturn (n_sources, n_targets)\n","walk two filename lists in parallel ."] (predictor.py:56, main())
[2020-11-20 23:29:59]    INFO >> ["def reparam(string_, dictionary):\n\tdictionary = dictionary.copy()\n\tresult = []\n\tfor (live, chunk) in _interpolate(string_):\n\t\tif live:\n\t\t\tv = eval(chunk, dictionary)\n\t\t\tresult.append(sqlquote(v))\n\t\telse:\n\t\t\tresult.append(chunk)\n\treturn SQLQuery.join(result, '')\n","takes a string and a dictionary and interpolates the string using values from the dictionary ."] (predictor.py:56, main())
[2020-11-20 23:30:00]    INFO >> ["def test_allknn_sample_wrong_X():\n\tallknn = AllKNN(random_state=RND_SEED)\n\tallknn.fit(X, Y)\n\tassert_raises(RuntimeError, allknn.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:30:00]    INFO >> ["def get_hasher(algorithm=u'default'):\n\tif hasattr(algorithm, u'algorithm'):\n\t\treturn algorithm\n\telif (algorithm == u'default'):\n\t\tif (PREFERRED_HASHER is None):\n\t\t\tload_hashers()\n\t\treturn PREFERRED_HASHER\n\telse:\n\t\tif (HASHERS is None):\n\t\t\tload_hashers()\n\t\tif (algorithm not in HASHERS):\n\t\t\traise ValueError((u\"Unknown\tpassword\thashing\talgorithm\t'%s'.\tDid\tyou\tspecify\tit\tin\tthe\tPASSWORD_HASHERS\tsetting?\" % algorithm))\n\t\treturn HASHERS[algorithm]\n","returns an instance of a loaded password hasher ."] (predictor.py:56, main())
[2020-11-20 23:30:01]    INFO >> ["def _image_entropy(img):\n\thist = img.histogram()\n\thist_size = sum(hist)\n\thist = [(float(h) \/ hist_size) for h in hist]\n\treturn (- sum(((p * math.log(p, 2)) for p in hist if (p != 0))))\n","calculate the entropy of an image ."] (predictor.py:56, main())
[2020-11-20 23:30:02]    INFO >> ["def cooperative_iter(iter):\n\ttry:\n\t\tfor chunk in iter:\n\t\t\tsleep(0)\n\t\t\t(yield chunk)\n\texcept Exception as err:\n\t\twith excutils.save_and_reraise_exception():\n\t\t\tmsg = (_LE('Error:\tcooperative_iter\texception\t%s') % err)\n\t\t\tLOG.error(msg)\n","return an iterator which schedules after each iteration ."] (predictor.py:56, main())
[2020-11-20 23:30:03]    INFO >> ["def _get_md5(name, path, run_func):\n\toutput = run_func(name, 'md5sum\t{0}'.format(pipes.quote(path)), ignore_retcode=True)['stdout']\n\ttry:\n\t\treturn output.split()[0]\n\texcept IndexError:\n\t\treturn None\n","get the md5 checksum of a file from a container ."] (predictor.py:56, main())
[2020-11-20 23:30:03]    INFO >> ["def find_autosummary_in_files(filenames):\n\tdocumented = []\n\tfor filename in filenames:\n\t\tf = open(filename, 'r')\n\t\tlines = f.read().splitlines()\n\t\tdocumented.extend(find_autosummary_in_lines(lines, filename=filename))\n\t\tf.close()\n\treturn documented\n","find out what items are documented in source\/* ."] (predictor.py:56, main())
[2020-11-20 23:30:04]    INFO >> ["def _getWriters(reactor):\n\tif IReactorFDSet.providedBy(reactor):\n\t\treturn reactor.getWriters()\n\telif ('IOCP' in reactor.__class__.__name__):\n\t\treturn reactor.handles\n\telse:\n\t\traise Exception(('Cannot\tfind\twriters\ton\t%r' % (reactor,)))\n","like l{ireactorfdset ."] (predictor.py:56, main())
[2020-11-20 23:30:04]    INFO >> ["def guess_filename(obj):\n\tname = getattr(obj, 'name', None)\n\tif (name and isinstance(name, builtin_str) and (name[0] != '<') and (name[(-1)] != '>')):\n\t\treturn os.path.basename(name)\n","tries to guess the filename of the given object ."] (predictor.py:56, main())
[2020-11-20 23:30:04]    INFO >> ["def test_nm2_sample_wt_fit():\n\tratio = 'auto'\n\tnm2 = NearMiss(ratio=ratio, random_state=RND_SEED, version=VERSION_NEARMISS)\n\tassert_raises(RuntimeError, nm2.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:30:05]    INFO >> ["def randomString(length, chrs):\n\tn = len(chrs)\n\treturn ''.join([chrs[randrange(n)] for _ in xrange(length)])\n","produce a string of length random bytes ."] (predictor.py:56, main())
[2020-11-20 23:30:06]    INFO >> ["@register.filter(is_safe=False)\ndef dictsort(value, arg):\n\ttry:\n\t\treturn sorted(value, key=Variable(arg).resolve)\n\texcept (TypeError, VariableDoesNotExist):\n\t\treturn u''\n","takes a list of dicts ."] (predictor.py:56, main())
[2020-11-20 23:30:07]    INFO >> ["def _template_func(setup, func):\n\tdef inner(_it, _timer, _func=func):\n\t\tsetup()\n\t\t_t0 = _timer()\n\t\tfor _i in _it:\n\t\t\t_func()\n\t\t_t1 = _timer()\n\t\treturn (_t1 - _t0)\n\treturn inner\n","create a timer function ."] (predictor.py:56, main())
[2020-11-20 23:30:07]    INFO >> ["def test_continuous_error():\n\ty = np.linspace(0, 1, 20)\n\tcnn = CondensedNearestNeighbour(random_state=RND_SEED)\n\tassert_warns(UserWarning, cnn.fit, X, y)\n","test either if an error is raised when the target are continuous type ."] (predictor.py:56, main())
[2020-11-20 23:30:08]    INFO >> ["def has_inherited_table(cls):\n\tfor class_ in cls.__mro__[1:]:\n\t\tif (getattr(class_, '__table__', None) is not None):\n\t\t\treturn True\n\treturn False\n","given a class ."] (predictor.py:56, main())
[2020-11-20 23:30:08]    INFO >> ["def rsub(self, rhs):\n\tif isinstance(rhs, variable.Variable):\n\t\treturn Sub()(rhs, self)\n\t_check_constant_type(rhs)\n\treturn SubFromConstant(rhs)(self)\n","element-wise subtraction ."] (predictor.py:56, main())
[2020-11-20 23:30:09]    INFO >> ["def smart_unicode(s, strings_only=False, errors='strict'):\n\treturn django.utils.encoding.smart_unicode(s, get_site_encoding(), strings_only, errors)\n","wrapper around djangos version ."] (predictor.py:56, main())
[2020-11-20 23:30:11]    INFO >> ["def ProfileEntryFromString(xml_string):\n\treturn atom.core.parse(ProfileEntry, xml_string)\n","converts an xml string into a profileentry object ."] (predictor.py:56, main())
[2020-11-20 23:30:11]    INFO >> ["def fixed_ip_get(context, id, get_network=False):\n\treturn IMPL.fixed_ip_get(context, id, get_network)\n","get fixed ip by id or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:30:11]    INFO >> ["def onCellAppData(key, value):\n\tDEBUG_MSG(('onCellAppData:\t%s' % key))\n","kbengine method ."] (predictor.py:56, main())
[2020-11-20 23:30:12]    INFO >> ["def voidptr_output(func, argtypes, errcheck=True):\n\tfunc.argtypes = argtypes\n\tfunc.restype = c_void_p\n\tif errcheck:\n\t\tfunc.errcheck = check_pointer\n\treturn func\n","for functions that return c_void_p ."] (predictor.py:56, main())
[2020-11-20 23:30:12]    INFO >> ["def clear_site_cache(sender, **kwargs):\n\tinstance = kwargs['instance']\n\tusing = kwargs['using']\n\ttry:\n\t\tdel SITE_CACHE[instance.pk]\n\texcept KeyError:\n\t\tpass\n\ttry:\n\t\tdel SITE_CACHE[Site.objects.using(using).get(pk=instance.pk).domain]\n\texcept (KeyError, Site.DoesNotExist):\n\t\tpass\n","clears the cache each time a site is saved or deleted ."] (predictor.py:56, main())
[2020-11-20 23:30:12]    INFO >> ["def is_hop_by_hop_header(header):\n\treturn (header.lower() in _hop_by_hop_headers)\n","check if a header is an http\/1 ."] (predictor.py:56, main())
[2020-11-20 23:30:13]    INFO >> ["def verbose_print(arg):\n\tif support.verbose:\n\t\twith _print_mutex:\n\t\t\tprint arg\n","helper function for printing out debugging output ."] (predictor.py:56, main())
[2020-11-20 23:30:14]    INFO >> ["def processElementNode(elementNode):\n\tpath.convertElementNode(elementNode, getGeometryOutput(None, elementNode))\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:30:14]    INFO >> ["def comment(parser, token):\n\tparser.skip_past('endcomment')\n\treturn CommentNode()\n","ignores everything between {% comment %} and {% endcomment %} ."] (predictor.py:56, main())
[2020-11-20 23:30:15]    INFO >> ["def getatime(filename):\n\treturn os.stat(filename).st_atime\n","return the last access time of a file ."] (predictor.py:56, main())
[2020-11-20 23:30:15]    INFO >> ["def getNewMouseTool():\n\treturn ViewpointRotate()\n","get a new mouse tool ."] (predictor.py:56, main())
[2020-11-20 23:30:15]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:30:15]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:30:16]    INFO >> ["def getNewRepository():\n\treturn ExportRepository()\n","get new repository ."] (predictor.py:56, main())
[2020-11-20 23:30:16]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:30:16]    INFO >> ["def wordcount(value):\n\treturn len(value.split())\n","returns the number of words ."] (predictor.py:56, main())
[2020-11-20 23:30:17]    INFO >> ["def capacity_indicator():\n\treturn s3_rest_controller()\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:30:18]    INFO >> ["def nlargest(n, iterable, key=None):\n\tif (n == 1):\n\t\tit = iter(iterable)\n\t\thead = list(islice(it, 1))\n\t\tif (not head):\n\t\t\treturn []\n\t\tif (key is None):\n\t\t\treturn [max(chain(head, it))]\n\t\treturn [max(chain(head, it), key=key)]\n\ttry:\n\t\tsize = len(iterable)\n\texcept (TypeError, AttributeError):\n\t\tpass\n\telse:\n\t\tif (n >= size):\n\t\t\treturn sorted(iterable, key=key, reverse=True)[:n]\n\tif (key is None):\n\t\tit = izip(iterable, imap(neg, count()))\n\t\tresult = _nlargest(n, it)\n\t\treturn map(itemgetter(0), result)\n\t(in1, in2) = tee(iterable)\n\tit = izip(imap(key, in1), imap(neg, count()), in2)\n\tresult = _nlargest(n, it)\n\treturn map(itemgetter(2), result)\n","find the n largest elements in a dataset ."] (predictor.py:56, main())
[2020-11-20 23:30:19]    INFO >> ["def retry_over_time(fun, catch, args=[], kwargs={}, errback=None, max_retries=None, interval_start=2, interval_step=2, interval_max=30, callback=None):\n\tretries = 0\n\tinterval_range = fxrange(interval_start, (interval_max + interval_start), interval_step, repeatlast=True)\n\tfor retries in count():\n\t\ttry:\n\t\t\treturn fun(*args, **kwargs)\n\t\texcept catch as exc:\n\t\t\tif (max_retries and (retries >= max_retries)):\n\t\t\t\traise\n\t\t\tif callback:\n\t\t\t\tcallback()\n\t\t\ttts = float((errback(exc, interval_range, retries) if errback else next(interval_range)))\n\t\t\tif tts:\n\t\t\t\tfor _ in range(int(tts)):\n\t\t\t\t\tif callback:\n\t\t\t\t\t\tcallback()\n\t\t\t\t\tsleep(1.0)\n\t\t\t\tsleep(abs((int(tts) - tts)))\n","retry the function over and over until max retries is exceeded ."] (predictor.py:56, main())
[2020-11-20 23:30:19]    INFO >> ["def localize_input(value, default=None):\n\tif isinstance(value, (decimal.Decimal, float, int, long)):\n\t\treturn number_format(value)\n\tif isinstance(value, datetime.datetime):\n\t\tvalue = datetime_safe.new_datetime(value)\n\t\tformat = smart_str((default or get_format('DATETIME_INPUT_FORMATS')[0]))\n\t\treturn value.strftime(format)\n\telif isinstance(value, datetime.date):\n\t\tvalue = datetime_safe.new_date(value)\n\t\tformat = smart_str((default or get_format('DATE_INPUT_FORMATS')[0]))\n\t\treturn value.strftime(format)\n\telif isinstance(value, datetime.time):\n\t\tformat = smart_str((default or get_format('TIME_INPUT_FORMATS')[0]))\n\t\treturn value.strftime(format)\n\treturn value\n","checks if an input value is a localizable type and returns it formatted with the appropriate formatting string of the current locale ."] (predictor.py:56, main())
[2020-11-20 23:30:20]    INFO >> ["def pbkdf2_bin(data, salt, iterations=1000, keylen=24, hashfunc=None):\n\thashfunc = (hashfunc or hashlib.sha1)\n\tmac = hmac.new(data, None, hashfunc)\n\tdef _pseudorandom(x, mac=mac):\n\t\th = mac.copy()\n\t\th.update(x)\n\t\treturn map(ord, h.digest())\n\tbuf = []\n\tfor block in xrange(1, ((- ((- keylen) \/\/ mac.digest_size)) + 1)):\n\t\trv = u = _pseudorandom((salt + _pack_int(block)))\n\t\tfor i in xrange((iterations - 1)):\n\t\t\tu = _pseudorandom(''.join(map(chr, u)))\n\t\t\trv = starmap(xor, izip(rv, u))\n\t\tbuf.extend(rv)\n\treturn ''.join(map(chr, buf))[:keylen]\n","returns a binary digest for the pbkdf2 hash algorithm of data with the given salt ."] (predictor.py:56, main())
[2020-11-20 23:30:21]    INFO >> ["def _process_image(filename, coder):\n\twith tf.gfile.FastGFile(filename, 'r') as f:\n\t\timage_data = f.read()\n\tif _is_png(filename):\n\t\tprint(('Converting\tPNG\tto\tJPEG\tfor\t%s' % filename))\n\t\timage_data = coder.png_to_jpeg(image_data)\n\timage = coder.decode_jpeg(image_data)\n\tassert (len(image.shape) == 3)\n\theight = image.shape[0]\n\twidth = image.shape[1]\n\tassert (image.shape[2] == 3)\n\treturn (image_data, height, width)\n","process a single image file ."] (predictor.py:56, main())
[2020-11-20 23:30:22]    INFO >> ["def syslog(server, enable=True):\n\tif (enable and __execute_cmd('config\t-g\tcfgRemoteHosts\t-o\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcfgRhostsSyslogEnable\t1')):\n\t\treturn __execute_cmd('config\t-g\tcfgRemoteHosts\t-o\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcfgRhostsSyslogServer1\t{0}'.format(server))\n\treturn __execute_cmd('config\t-g\tcfgRemoteHosts\t-o\tcfgRhostsSyslogEnable\t0')\n","configure syslog remote logging ."] (predictor.py:56, main())
[2020-11-20 23:30:22]    INFO >> ["def make_server(host=None, port=None, app=None, threaded=False, processes=1, request_handler=None, passthrough_errors=False, ssl_context=None, fd=None):\n\tif (threaded and (processes > 1)):\n\t\traise ValueError('cannot\thave\ta\tmultithreaded\tand\tmulti\tprocess\tserver.')\n\telif threaded:\n\t\treturn ThreadedWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd)\n\telif (processes > 1):\n\t\treturn ForkingWSGIServer(host, port, app, processes, request_handler, passthrough_errors, ssl_context, fd=fd)\n\telse:\n\t\treturn BaseWSGIServer(host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd)\n","create a new server instance that is either threaded ."] (predictor.py:56, main())
[2020-11-20 23:30:22]    INFO >> ["def get_ranges(headervalue, content_length):\n\tif (not headervalue):\n\t\treturn None\n\tresult = []\n\t(bytesunit, byteranges) = headervalue.split('=', 1)\n\tfor brange in byteranges.split(','):\n\t\t(start, stop) = [x.strip() for x in brange.split('-', 1)]\n\t\tif start:\n\t\t\tif (not stop):\n\t\t\t\tstop = (content_length - 1)\n\t\t\t(start, stop) = (int(start), int(stop))\n\t\t\tif (start >= content_length):\n\t\t\t\tcontinue\n\t\t\tif (stop < start):\n\t\t\t\treturn None\n\t\t\tresult.append((start, (stop + 1)))\n\t\telse:\n\t\t\tif (not stop):\n\t\t\t\treturn None\n\t\t\tresult.append(((content_length - int(stop)), content_length))\n\treturn result\n","return a list of indices from a range header ."] (predictor.py:56, main())
[2020-11-20 23:30:23]    INFO >> ["def was_modified_since(header=None, mtime=0, size=0):\n\ttry:\n\t\tif (header is None):\n\t\t\traise ValueError\n\t\tmatches = re.match('^([^;]+)(;\tlength=([0-9]+))?$', header, re.IGNORECASE)\n\t\theader_mtime = parse_http_date(matches.group(1))\n\t\theader_len = matches.group(3)\n\t\tif (header_len and (int(header_len) != size)):\n\t\t\traise ValueError\n\t\tif (mtime > header_mtime):\n\t\t\traise ValueError\n\texcept (AttributeError, ValueError, OverflowError):\n\t\treturn True\n\treturn False\n","was something modified since the user last downloaded it? header this is the value of the if-modified-since header ."] (predictor.py:56, main())
[2020-11-20 23:30:23]    INFO >> ["def use_setuptools(version=DEFAULT_VERSION, download_base=DEFAULT_URL, to_dir=os.curdir):\n\ttry:\n\t\timport setuptools\n\t\tif (setuptools.__version__ == '0.0.1'):\n\t\t\tprint >>sys.stderr, 'You\thave\tan\tobsolete\tversion\tof\tsetuptools\tinstalled.\t\tPlease\\nremove\tit\tfrom\tyour\tsystem\tentirely\tbefore\trerunning\tthis\tscript.'\n\t\t\tsys.exit(2)\n\texcept ImportError:\n\t\tegg = download_setuptools(version, download_base, to_dir)\n\t\tsys.path.insert(0, egg)\n\t\timport setuptools\n\t\tsetuptools.bootstrap_install_from = egg\n\timport pkg_resources\n\ttry:\n\t\tpkg_resources.require(('setuptools>=' + version))\n\texcept pkg_resources.VersionConflict:\n\t\tprint >>sys.stderr, (\"The\trequired\tversion\tof\tsetuptools\t(>=%s)\tis\tnot\tavailable,\tand\\ncan't\tbe\tinstalled\twhile\tthis\tscript\tis\trunning.\tPlease\tinstall\\n\ta\tmore\trecent\tversion\tfirst.\" % version)\n\t\tsys.exit(2)\n","automatically find\/download setuptools and make it available on sys ."] (predictor.py:56, main())
[2020-11-20 23:30:24]    INFO >> ["def make_vals(val, klass, klass_inst=None, prop=None, part=False, base64encode=False):\n\tcinst = None\n\tif isinstance(val, dict):\n\t\tcinst = klass().loadd(val, base64encode=base64encode)\n\telse:\n\t\ttry:\n\t\t\tcinst = klass().set_text(val)\n\t\texcept ValueError:\n\t\t\tif (not part):\n\t\t\t\tcis = [make_vals(sval, klass, klass_inst, prop, True, base64encode) for sval in val]\n\t\t\t\tsetattr(klass_inst, prop, cis)\n\t\t\telse:\n\t\t\t\traise\n\tif part:\n\t\treturn cinst\n\telif cinst:\n\t\tcis = [cinst]\n\t\tsetattr(klass_inst, prop, cis)\n","creates a class instance with a specified value ."] (predictor.py:56, main())
[2020-11-20 23:30:25]    INFO >> ["def _getlabel(object_alias):\n\tfinder = _getfinder()\n\targs = {}\n\tattrs = {}\n\taeobj_00 = aetypes.ObjectSpecifier(want=aetypes.Type('cobj'), form='alis', seld=object_alias, fr=None)\n\taeobj_01 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('labi'), fr=aeobj_00)\n\targs['----'] = aeobj_01\n\t(_reply, args, attrs) = finder.send('core', 'getd', args, attrs)\n\tif args.has_key('errn'):\n\t\traise Error, aetools.decodeerror(args)\n\tif args.has_key('----'):\n\t\treturn args['----']\n","label: get the label for the object ."] (predictor.py:56, main())
[2020-11-20 23:30:26]    INFO >> ["def serialize_remote_exception(failure_info, log_failure=True):\n\ttb = traceback.format_exception(*failure_info)\n\tfailure = failure_info[1]\n\tif log_failure:\n\t\tLOG.error(_('Returning\texception\t%s\tto\tcaller'), six.text_type(failure))\n\t\tLOG.error(tb)\n\tkwargs = {}\n\tif hasattr(failure, 'kwargs'):\n\t\tkwargs = failure.kwargs\n\tcls_name = str(failure.__class__.__name__)\n\tmod_name = str(failure.__class__.__module__)\n\tif (cls_name.endswith(_REMOTE_POSTFIX) and mod_name.endswith(_REMOTE_POSTFIX)):\n\t\tcls_name = cls_name[:(- len(_REMOTE_POSTFIX))]\n\t\tmod_name = mod_name[:(- len(_REMOTE_POSTFIX))]\n\tdata = {'class': cls_name, 'module': mod_name, 'message': six.text_type(failure), 'tb': tb, 'args': failure.args, 'kwargs': kwargs}\n\tjson_data = jsonutils.dumps(data)\n\treturn json_data\n","prepares exception data to be sent over rpc ."] (predictor.py:56, main())
[2020-11-20 23:30:26]    INFO >> ["def test_senn_bad_ratio():\n\tratio = (-1.0)\n\tsmote = SMOTEENN(ratio=ratio)\n\tassert_raises(ValueError, smote.fit, X, Y)\n\tratio = 100.0\n\tsmote = SMOTEENN(ratio=ratio)\n\tassert_raises(ValueError, smote.fit, X, Y)\n\tratio = 'rnd'\n\tsmote = SMOTEENN(ratio=ratio)\n\tassert_raises(ValueError, smote.fit, X, Y)\n\tratio = [0.5, 0.5]\n\tsmote = SMOTEENN(ratio=ratio)\n\tassert_raises(ValueError, smote.fit, X, Y)\n","test either if an error is raised with a wrong decimal value for the ratio ."] (predictor.py:56, main())
[2020-11-20 23:30:27]    INFO >> ["def _mkstemp_inner(dir, pre, suf, flags):\n\tnames = _get_candidate_names()\n\tfor seq in xrange(TMP_MAX):\n\t\tname = names.next()\n\t\tfile = _os.path.join(dir, ((pre + name) + suf))\n\t\ttry:\n\t\t\tfd = _os.open(file, flags, 384)\n\t\t\t_set_cloexec(fd)\n\t\t\treturn (fd, _os.path.abspath(file))\n\t\texcept OSError as e:\n\t\t\tif (e.errno == _errno.EEXIST):\n\t\t\t\tcontinue\n\t\t\tif ((_os.name == 'nt') and (e.errno == _errno.EACCES)):\n\t\t\t\tcontinue\n\t\t\traise\n\traise IOError, (_errno.EEXIST, 'No\tusable\ttemporary\tfile\tname\tfound')\n","code common to mkstemp ."] (predictor.py:56, main())
[2020-11-20 23:30:27]    INFO >> ["def addListsToCraftTypeRepository(fileNameHelp, repository):\n\tsettings.addListsToRepositoryByFunction(fileNameHelp, getProfileDirectory, repository)\n\tdotsMinusOne = (fileNameHelp.count('.') - 1)\n\tx = 0\n\txAddition = 400\n\tfor step in xrange(dotsMinusOne):\n\t\tx += xAddition\n\t\txAddition \/= 2\n\trepository.windowPosition.value = ('%s+0' % x)\n","add the value to the lists ."] (predictor.py:56, main())
[2020-11-20 23:30:28]    INFO >> ["def equal_attributes(obj1, obj2, attributes):\n\tif (not attributes):\n\t\treturn False\n\tfor attr in attributes:\n\t\tif callable(attr):\n\t\t\tif (not (attr(obj1) == attr(obj2))):\n\t\t\t\treturn False\n\t\telse:\n\t\t\tif (not hasattr(obj1, attr)):\n\t\t\t\treturn False\n\t\t\tif (not hasattr(obj2, attr)):\n\t\t\t\treturn False\n\t\t\tif (not (getattr(obj1, attr) == getattr(obj2, attr))):\n\t\t\t\treturn False\n\treturn True\n","compare two objects attributes ."] (predictor.py:56, main())
[2020-11-20 23:30:28]    INFO >> ["def exec_command_all(*cmdargs, **kwargs):\n\tproc = subprocess.Popen(cmdargs, bufsize=(-1), stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)\n\t(out, err) = proc.communicate()\n\tif is_py3:\n\t\tencoding = kwargs.get('encoding')\n\t\tif encoding:\n\t\t\tout = out.decode(encoding)\n\t\t\terr = err.decode(encoding)\n\t\telse:\n\t\t\tout = os.fsdecode(out)\n\t\t\terr = os.fsdecode(err)\n\treturn (proc.returncode, out, err)\n","run the command specified by the passed positional arguments ."] (predictor.py:56, main())
[2020-11-20 23:30:30]    INFO >> ["def add_metaclass(metaclass):\n\tdef wrapper(cls):\n\t\torig_vars = cls.__dict__.copy()\n\t\torig_vars.pop('__dict__', None)\n\t\torig_vars.pop('__weakref__', None)\n\t\tfor slots_var in orig_vars.get('__slots__', ()):\n\t\t\torig_vars.pop(slots_var)\n\t\treturn metaclass(cls.__name__, cls.__bases__, orig_vars)\n\treturn wrapper\n","class decorator for creating a class with a metaclass ."] (predictor.py:56, main())
[2020-11-20 23:30:30]    INFO >> ["def mktemp(suffix='', prefix=template, dir=None):\n\tif (dir is None):\n\t\tdir = gettempdir()\n\tnames = _get_candidate_names()\n\tfor seq in range(TMP_MAX):\n\t\tname = next(names)\n\t\tfile = _os.path.join(dir, ((prefix + name) + suffix))\n\t\tif (not _exists(file)):\n\t\t\treturn file\n\traise FileExistsError(_errno.EEXIST, 'No\tusable\ttemporary\tfilename\tfound')\n","user-callable function to return a unique temporary file name ."] (predictor.py:56, main())
[2020-11-20 23:30:30]    INFO >> ["def getnode():\n\tglobal _node\n\tif (_node is not None):\n\t\treturn _node\n\timport sys\n\tif (sys.platform == 'win32'):\n\t\tgetters = [_windll_getnode, _netbios_getnode, _ipconfig_getnode]\n\telse:\n\t\tgetters = [_unixdll_getnode, _ifconfig_getnode]\n\tfor getter in (getters + [_random_getnode]):\n\t\ttry:\n\t\t\t_node = getter()\n\t\texcept:\n\t\t\tcontinue\n\t\tif (_node is not None):\n\t\t\treturn _node\n","get the hardware address as a 48-bit positive integer ."] (predictor.py:56, main())
[2020-11-20 23:30:31]    INFO >> ["def dyld_find(name, executable_path=None, env=None):\n\tname = ensure_utf8(name)\n\texecutable_path = ensure_utf8(executable_path)\n\tfor path in dyld_image_suffix_search(chain(dyld_override_search(name, env), dyld_executable_path_search(name, executable_path), dyld_default_search(name, env)), env):\n\t\tif os.path.isfile(path):\n\t\t\treturn path\n\traise ValueError(('dylib\t%s\tcould\tnot\tbe\tfound' % (name,)))\n","find a library or framework using dyld semantics ."] (predictor.py:56, main())
[2020-11-20 23:30:31]    INFO >> ["def getOutput(gcodeText, binary16ByteRepository=None):\n\tif (gcodeText == ''):\n\t\treturn ''\n\tif (binary16ByteRepository == None):\n\t\tbinary16ByteRepository = Binary16ByteRepository()\n\t\tsettings.getReadRepository(binary16ByteRepository)\n\treturn Binary16ByteSkein().getCraftedGcode(gcodeText, binary16ByteRepository)\n","get the exported version of a gcode file ."] (predictor.py:56, main())
[2020-11-20 23:30:32]    INFO >> ["def expand_makefile_vars(s, vars):\n\twhile 1:\n\t\tm = (_findvar1_rx.search(s) or _findvar2_rx.search(s))\n\t\tif m:\n\t\t\t(beg, end) = m.span()\n\t\t\ts = ((s[0:beg] + vars.get(m.group(1))) + s[end:])\n\t\telse:\n\t\t\tbreak\n\treturn s\n","expand makefile-style variables -- \"${foo}\" or \"$\" -- in string according to vars ."] (predictor.py:56, main())
[2020-11-20 23:30:33]    INFO >> ["def _format_range_context(start, stop):\n\tbeginning = (start + 1)\n\tlength = (stop - start)\n\tif (not length):\n\t\tbeginning -= 1\n\tif (length <= 1):\n\t\treturn '{}'.format(beginning)\n\treturn '{},{}'.format(beginning, ((beginning + length) - 1))\n","convert range to the \"ed\" format ."] (predictor.py:56, main())
[2020-11-20 23:30:34]    INFO >> ["def _get_epochs():\n\traw = read_raw_fif(raw_fname)\n\traw.add_proj([], remove_existing=True)\n\tevents = read_events(event_name)\n\tpicks = _get_picks(raw)\n\tpicks = picks[np.round(np.linspace(0, (len(picks) - 1), n_chan)).astype(int)]\n\tpicks = np.concatenate([[2, 3, 4, 6, 7], picks])\n\tepochs = Epochs(raw, events[:5], event_id, tmin, tmax, picks=picks)\n\tepochs.info['bads'] = [epochs.ch_names[(-1)]]\n\treturn epochs\n","get epochs ."] (predictor.py:56, main())
[2020-11-20 23:30:34]    INFO >> ["def PrintUsageExit(code):\n\tprint (sys.modules['__main__'].__doc__ % sys.argv[0])\n\tsys.stdout.flush()\n\tsys.stderr.flush()\n\tsys.exit(code)\n","prints usage information and exits with a status code ."] (predictor.py:56, main())
[2020-11-20 23:30:35]    INFO >> ["def get_ladder_capture(state):\n\tfeature = np.zeros((1, state.size, state.size))\n\tfor (x, y) in state.get_legal_moves():\n\t\tfeature[(0, x, y)] = state.is_ladder_capture((x, y))\n\treturn feature\n","a feature wrapping gamestate ."] (predictor.py:56, main())
[2020-11-20 23:30:35]    INFO >> ["def catalog():\n\tglobal _default\n\tt = getattr(_active, u'value', None)\n\tif (t is not None):\n\t\treturn t\n\tif (_default is None):\n\t\tfrom django.conf import settings\n\t\t_default = translation(settings.LANGUAGE_CODE)\n\treturn _default\n","returns the current active catalog for further processing ."] (predictor.py:56, main())
[2020-11-20 23:30:35]    INFO >> ["def IE_Dispatcher(s):\n\tif (len(s) < 1):\n\t\treturn Raw(s)\n\tietype = ord(s[0])\n\tcls = ietypecls.get(ietype, Raw)\n\tif ((cls == Raw) and ((ietype & 128) == 128)):\n\t\tcls = IE_NotImplementedTLV\n\treturn cls(s)\n","choose the correct information element class ."] (predictor.py:56, main())
[2020-11-20 23:30:36]    INFO >> ["def dictsortreversed(value, arg):\n\tdecorated = [(resolve_variable(('var.' + arg), {'var': item}), item) for item in value]\n\tdecorated.sort()\n\tdecorated.reverse()\n\treturn [item[1] for item in decorated]\n","takes a list of dicts ."] (predictor.py:56, main())
[2020-11-20 23:30:36]    INFO >> ["def getSelectedPluginModuleFromPath(filePath, plugins):\n\tfor plugin in plugins:\n\t\tif plugin.value:\n\t\t\treturn gcodec.getModuleFromPath(plugin.name, filePath)\n\treturn None\n","get the selected plugin module ."] (predictor.py:56, main())
[2020-11-20 23:30:37]    INFO >> ["def test_ada_fit_invalid_ratio():\n\tratio = (1.0 \/ 10000.0)\n\tada = ADASYN(ratio=ratio, random_state=RND_SEED)\n\tassert_raises(RuntimeError, ada.fit, X, Y)\n","test either if an error is raised when the balancing ratio to fit is smaller than the one of the data ."] (predictor.py:56, main())
[2020-11-20 23:30:37]    INFO >> ["def cinder_localization_strings(logical_line, tokens):\n\tgen = check_l18n()\n\tnext(gen)\n\ttry:\n\t\tmap(gen.send, tokens)\n\t\tgen.close()\n\texcept LocalizationError as e:\n\t\t(yield e.args)\n","check localization in line ."] (predictor.py:56, main())
[2020-11-20 23:30:38]    INFO >> ["def enabled(name='allprofiles'):\n\tret = {'name': name, 'result': True, 'changes': {}, 'comment': ''}\n\taction = False\n\tcheck_name = None\n\tif (name != 'allprofiles'):\n\t\tcheck_name = True\n\tcurrent_config = __salt__['firewall.get_config']()\n\tif (check_name and (name not in current_config)):\n\t\tret['result'] = False\n\t\tret['comment'] = 'Profile\t{0}\tdoes\tnot\texist\tin\tfirewall.get_config'.format(name)\n\t\treturn ret\n\tfor key in current_config:\n\t\tif (not current_config[key]):\n\t\t\tif (check_name and (key != name)):\n\t\t\t\tcontinue\n\t\t\taction = True\n\t\t\tret['changes'] = {'fw': 'enabled'}\n\t\t\tbreak\n\tif __opts__['test']:\n\t\tret['result'] = ((not action) or None)\n\t\treturn ret\n\tif action:\n\t\tret['result'] = __salt__['firewall.enable'](name)\n\t\tif (not ret['result']):\n\t\t\tif check_name:\n\t\t\t\tmsg = 'Firewall\tprofile\t{0}\tcould\tnot\tbe\tenabled'.format(name)\n\t\t\telse:\n\t\t\t\tmsg = 'Could\tnot\tenable\tthe\tFW'\n\t\t\tret['comment'] = msg\n\telse:\n\t\tif check_name:\n\t\t\tmsg = 'Firewall\tprofile\t{0}\tis\tenabled'.format(name)\n\t\telse:\n\t\t\tmsg = 'All\tthe\tfirewall\tprofiles\tare\tenabled'\n\t\tret['comment'] = msg\n\treturn ret\n","check to see if the named service is enabled to start on boot cli example: ."] (predictor.py:56, main())
[2020-11-20 23:30:39]    INFO >> ["def report_tests(output, flaky_tests):\n\ttests = list((test.id() for (test, _) in flaky_tests))\n\tfor test in sorted(tests):\n\t\toutput.write('{}\\n'.format(test))\n","print all flaky tests ."] (predictor.py:56, main())
[2020-11-20 23:30:39]    INFO >> ["def security_group_get_by_name(context, project_id, group_name, columns_to_join=None):\n\treturn IMPL.security_group_get_by_name(context, project_id, group_name, columns_to_join=None)\n","returns a security group with the specified name from a project ."] (predictor.py:56, main())
[2020-11-20 23:30:39]    INFO >> ["def portableInstall(useGtk=True):\n\treactor = PortableGtkReactor()\n\tfrom twisted.internet.main import installReactor\n\tinstallReactor(reactor)\n\treturn reactor\n","configure the twisted mainloop to be run inside the gtk mainloop ."] (predictor.py:56, main())
[2020-11-20 23:30:40]    INFO >> ["def is_conservative(field):\n\tif (field == Vector(0)):\n\t\treturn True\n\tframe = list(field.separate())[0]\n\treturn (curl(field, frame).simplify() == Vector(0))\n","checks if a field is conservative ."] (predictor.py:56, main())
[2020-11-20 23:30:40]    INFO >> ["def _on_process_docstring(app, what, name, obj, options, lines):\n\tif ((what == 'module') and (name == 'falcon')):\n\t\tlines[:] = []\n\t\treturn\n\tlines[:] = [_process_line(line) for line in lines]\n","process the docstring for a given python object ."] (predictor.py:56, main())
[2020-11-20 23:30:41]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:30:41]    INFO >> ["def get_configured_provider():\n\treturn config.is_provider_configured(__opts__, (__active_provider_name__ or __virtualname__), ('user', 'tenant', 'identity_url', 'compute_region'))\n","return the first configured instance ."] (predictor.py:56, main())
[2020-11-20 23:30:41]    INFO >> ["def _parseClientTCP(**kwargs):\n\tkwargs['port'] = int(kwargs['port'])\n\ttry:\n\t\tkwargs['timeout'] = int(kwargs['timeout'])\n\texcept KeyError:\n\t\tpass\n\treturn kwargs\n","perform any argument value coercion necessary for tcp client parameters ."] (predictor.py:56, main())
[2020-11-20 23:30:42]    INFO >> ["def get_configured_provider():\n\treturn config.is_provider_configured(__opts__, (__active_provider_name__ or __virtualname__), ('user', 'tenant', 'identity_url', 'compute_region'))\n","return the first configured instance ."] (predictor.py:56, main())
[2020-11-20 23:30:42]    INFO >> ["def xkcd_palette(colors):\n\tpalette = [xkcd_rgb[name] for name in colors]\n\treturn color_palette(palette, len(palette))\n","make a palette with color names from the xkcd color survey ."] (predictor.py:56, main())
[2020-11-20 23:30:42]    INFO >> ["def dmp_quo(f, g, u, K):\n\treturn dmp_div(f, g, u, K)[0]\n","returns exact polynomial quotient in k[x] ."] (predictor.py:56, main())
[2020-11-20 23:30:43]    INFO >> ["def get_ipver_str(ip_version):\n\treturn IP_VERSION_DICT.get(ip_version, '')\n","convert an ip version number to a human-friendly string ."] (predictor.py:56, main())
[2020-11-20 23:30:44]    INFO >> ["def quoteArguments(arguments):\n\treturn '\t'.join(map(cmdLineQuote, arguments))\n","quote an iterable of command-line arguments for passing to createprocess or a similar api ."] (predictor.py:56, main())
[2020-11-20 23:30:44]    INFO >> ["def timeuntil(d, now=None):\n\treturn timesince(d, now, reversed=True)\n","like timesince ."] (predictor.py:56, main())
[2020-11-20 23:30:44]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:30:45]    INFO >> ["def iterkeys(d, **kw):\n\treturn iter(getattr(d, _iterkeys)(**kw))\n","return an iterator over the keys of a dictionary ."] (predictor.py:56, main())
[2020-11-20 23:30:45]    INFO >> ["def description():\n\tfor desc in _description.splitlines():\n\t\tprint desc\n","get description of brainstorm dataset ."] (predictor.py:56, main())
[2020-11-20 23:30:45]    INFO >> ["def captured_stdout():\n\treturn captured_output('stdout')\n","capture the output of sys ."] (predictor.py:56, main())
[2020-11-20 23:30:46]    INFO >> ["def captured_stdout():\n\treturn captured_output('stdout')\n","capture the output of sys ."] (predictor.py:56, main())
[2020-11-20 23:30:46]    INFO >> ["def __routes_doctest():\n\tpass\n","dummy function for doctesting routes ."] (predictor.py:56, main())
[2020-11-20 23:30:47]    INFO >> ["def disconnectNetToMs(Facility_presence=0, ProgressIndicator_presence=0, UserUser_presence=0, AllowedActions_presence=0):\n\ta = TpPd(pd=3)\n\tb = MessageType(mesType=37)\n\tc = Cause()\n\tpacket = ((a \/ b) \/ c)\n\tif (Facility_presence is 1):\n\t\td = FacilityHdr(ieiF=28, eightBitF=0)\n\t\tpacket = (packet \/ d)\n\tif (ProgressIndicator_presence is 1):\n\t\te = ProgressIndicatorHdr(ieiPI=30, eightBitPI=0)\n\t\tpacket = (packet \/ e)\n\tif (UserUser_presence is 1):\n\t\tf = UserUserHdr(ieiUU=126, eightBitUU=0)\n\t\tpacket = (packet \/ f)\n\tif (AllowedActions_presence is 1):\n\t\tg = AllowedActionsHdr(ieiAA=123, eightBitAA=0)\n\t\tpacket = (packet \/ g)\n\treturn packet\n","disconnect section 9 ."] (predictor.py:56, main())
[2020-11-20 23:30:48]    INFO >> ["def test_hsl_to_rgb_part_18():\n\tassert (hsl_to_rgb(300, 100, 0) == (0, 0, 0))\n\tassert (hsl_to_rgb(300, 100, 10) == (51, 0, 51))\n\tassert (hsl_to_rgb(300, 100, 20) == (102, 0, 102))\n\tassert (hsl_to_rgb(300, 100, 30) == (153, 0, 153))\n\tassert (hsl_to_rgb(300, 100, 40) == (204, 0, 204))\n\tassert (hsl_to_rgb(300, 100, 50) == (255, 0, 255))\n\tassert (hsl_to_rgb(300, 100, 60) == (255, 51, 255))\n\tassert (hsl_to_rgb(300, 100, 70) == (255, 102, 255))\n\tassert (hsl_to_rgb(300, 100, 80) == (255, 153, 255))\n\tassert (hsl_to_rgb(300, 100, 90) == (255, 204, 255))\n\tassert (hsl_to_rgb(300, 100, 100) == (255, 255, 255))\n","test hsl to rgb color function ."] (predictor.py:56, main())
[2020-11-20 23:30:48]    INFO >> ["def _handle_ns(packageName, path_item):\n\timporter = get_importer(path_item)\n\tif (importer is None):\n\t\treturn None\n\tloader = importer.find_module(packageName)\n\tif (loader is None):\n\t\treturn None\n\tmodule = sys.modules.get(packageName)\n\tif (module is None):\n\t\tmodule = sys.modules[packageName] = types.ModuleType(packageName)\n\t\tmodule.__path__ = []\n\t\t_set_parent_ns(packageName)\n\telif (not hasattr(module, '__path__')):\n\t\traise TypeError('Not\ta\tpackage:', packageName)\n\thandler = _find_adapter(_namespace_handlers, importer)\n\tsubpath = handler(importer, path_item, packageName, module)\n\tif (subpath is not None):\n\t\tpath = module.__path__\n\t\tpath.append(subpath)\n\t\tloader.load_module(packageName)\n\t\tsys_path = [((p and _normalize_cached(p)) or p) for p in sys.path]\n\t\tdef sort_key(p):\n\t\t\tparts = p.split(os.sep)\n\t\t\tparts = parts[:(- (packageName.count('.') + 1))]\n\t\t\treturn sys_path.index(_normalize_cached(os.sep.join(parts)))\n\t\tpath.sort(key=sort_key)\n\t\tmodule.__path__[:] = [_normalize_cached(p) for p in path]\n\treturn subpath\n","ensure that named package includes a subpath of path_item ."] (predictor.py:56, main())
[2020-11-20 23:30:49]    INFO >> ["def _encode_basestring_ascii(s):\n\ttry:\n\t\tif (isinstance(s, str) and (HAS_UTF8.search(s) is not None)):\n\t\t\ts = s.decode('utf-8')\n\texcept:\n\t\tpass\n\tdef replace(match):\n\t\ts = match.group(0)\n\t\ttry:\n\t\t\treturn ESCAPE_DCT[s]\n\t\texcept KeyError:\n\t\t\tn = ord(s)\n\t\t\tif (n < 65536):\n\t\t\t\treturn ('\\\\u%04x' % (n,))\n\t\t\telse:\n\t\t\t\tn -= 65536\n\t\t\t\ts1 = (55296 | ((n >> 10) & 1023))\n\t\t\t\ts2 = (56320 | (n & 1023))\n\t\t\t\treturn ('\\\\u%04x\\\\u%04x' % (s1, s2))\n\treturn (('\"' + str(ESCAPE_ASCII.sub(replace, s))) + '\"')\n","return an ascii-only json representation of a python string ."] (predictor.py:56, main())
[2020-11-20 23:30:49]    INFO >> ["def get_environ_proxies(url):\n\tget_proxy = (lambda k: (os.environ.get(k) or os.environ.get(k.upper())))\n\tno_proxy = get_proxy('no_proxy')\n\tnetloc = urlparse(url).netloc\n\tif no_proxy:\n\t\tno_proxy = no_proxy.split(',')\n\t\tfor host in no_proxy:\n\t\t\tif (netloc.endswith(host) or netloc.split(':')[0].endswith(host)):\n\t\t\t\treturn {}\n\tif proxy_bypass(netloc):\n\t\treturn {}\n\treturn getproxies()\n","return a dict of environment proxies ."] (predictor.py:56, main())
[2020-11-20 23:30:50]    INFO >> ["def disk_usage(path):\n\ttry:\n\t\tst = os.statvfs(path)\n\texcept UnicodeEncodeError:\n\t\tif ((not PY3) and isinstance(path, unicode)):\n\t\t\ttry:\n\t\t\t\tpath = path.encode(sys.getfilesystemencoding())\n\t\t\texcept UnicodeEncodeError:\n\t\t\t\tpass\n\t\t\tst = os.statvfs(path)\n\t\telse:\n\t\t\traise\n\ttotal = (st.f_blocks * st.f_frsize)\n\tavail_to_root = (st.f_bfree * st.f_frsize)\n\tavail_to_user = (st.f_bavail * st.f_frsize)\n\tused = (total - avail_to_root)\n\ttotal_user = (used + avail_to_user)\n\tusage_percent_user = usage_percent(used, total_user, _round=1)\n\treturn sdiskusage(total=total, used=used, free=avail_to_user, percent=usage_percent_user)\n","return disk usage associated with path ."] (predictor.py:56, main())
[2020-11-20 23:30:51]    INFO >> ["def escape_all(v, linkify_only_full=False):\n\tif isinstance(v, basestring):\n\t\tv = jinja2.escape(force_text(v))\n\t\tv = linkify_with_outgoing(v, only_full=linkify_only_full)\n\t\treturn v\n\telif isinstance(v, list):\n\t\tfor (i, lv) in enumerate(v):\n\t\t\tv[i] = escape_all(lv, linkify_only_full=linkify_only_full)\n\telif isinstance(v, dict):\n\t\tfor (k, lv) in v.iteritems():\n\t\t\tv[k] = escape_all(lv, linkify_only_full=linkify_only_full)\n\telif isinstance(v, Translation):\n\t\tv = jinja2.escape(force_text(v))\n\treturn v\n","escape html in json value ."] (predictor.py:56, main())
[2020-11-20 23:30:51]    INFO >> ["def geo_apps(namespace=True, runtests=False):\n\tfrom django.db import connection\n\tfrom django.contrib.gis.geos import GEOS_PREPARE\n\tfrom django.contrib.gis.gdal import HAS_GDAL\n\tapps = ['geoapp', 'relatedapp']\n\tif (not connection.ops.mysql):\n\t\tapps.append('distapp')\n\tif (connection.ops.postgis and connection.ops.geography):\n\t\tapps.append('geogapp')\n\tif HAS_GDAL:\n\t\tif (connection.ops.postgis and GEOS_PREPARE):\n\t\t\tapps.append('geo3d')\n\t\tapps.append('layermap')\n\tif runtests:\n\t\treturn [('django.contrib.gis.tests', app) for app in apps]\n\telif namespace:\n\t\treturn [('django.contrib.gis.tests.%s' % app) for app in apps]\n\telse:\n\t\treturn apps\n","returns a list of geodjango test applications that reside in django ."] (predictor.py:56, main())
[2020-11-20 23:30:52]    INFO >> ["def _collapse_address_list_recursive(addresses):\n\tret_array = []\n\toptimized = False\n\tfor cur_addr in addresses:\n\t\tif (not ret_array):\n\t\t\tret_array.append(cur_addr)\n\t\t\tcontinue\n\t\tif (cur_addr in ret_array[(-1)]):\n\t\t\toptimized = True\n\t\telif (cur_addr == ret_array[(-1)].supernet().subnet()[1]):\n\t\t\tret_array.append(ret_array.pop().supernet())\n\t\t\toptimized = True\n\t\telse:\n\t\t\tret_array.append(cur_addr)\n\tif optimized:\n\t\treturn _collapse_address_list_recursive(ret_array)\n\treturn ret_array\n","loops through the addresses ."] (predictor.py:56, main())
[2020-11-20 23:30:52]    INFO >> ["def nsga2select(population, fitnesses, survivors, allowequality=True):\n\tfronts = const_non_dominated_sort(population, key=(lambda x: fitnesses[x]), allowequality=allowequality)\n\tindividuals = set()\n\tfor front in fronts:\n\t\tremaining = (survivors - len(individuals))\n\t\tif (not (remaining > 0)):\n\t\t\tbreak\n\t\tif (len(front) > remaining):\n\t\t\tcrowd_dist = const_crowding_distance(front, fitnesses)\n\t\t\tfront = sorted(front, key=(lambda x: crowd_dist[x]), reverse=True)\n\t\t\tfront = set(front[:remaining])\n\t\tindividuals |= front\n\treturn list(individuals)\n","the nsga-ii selection strategy ."] (predictor.py:56, main())
[2020-11-20 23:30:53]    INFO >> ["def serve(request, path, document_root=None, insecure=False, **kwargs):\n\tif ((not settings.DEBUG) and (not insecure)):\n\t\traise ImproperlyConfigured(\"The\tstaticfiles\tview\tcan\tonly\tbe\tused\tin\tdebug\tmode\tor\tif\tthe\tthe\t--insecure\toption\tof\t'runserver'\tis\tused\")\n\tnormalized_path = posixpath.normpath(urllib.unquote(path)).lstrip('\/')\n\tabsolute_path = finders.find(normalized_path)\n\tif (not absolute_path):\n\t\tif (path.endswith('\/') or (path == '')):\n\t\t\traise Http404('Directory\tindexes\tare\tnot\tallowed\there.')\n\t\traise Http404((\"'%s'\tcould\tnot\tbe\tfound\" % path))\n\t(document_root, path) = os.path.split(absolute_path)\n\treturn static.serve(request, path, document_root=document_root, **kwargs)\n","serve static files below a given point in the directory structure or from locations inferred from the staticfiles finders ."] (predictor.py:56, main())
[2020-11-20 23:30:53]    INFO >> ["def addSparseEndpoints(doubleExtrusionWidth, endpoints, fillLine, horizontalSegmentLists, infillSolidity, removedEndpoints, solidSurfaceThickness, surroundingXIntersections):\n\thorizontalEndpoints = horizontalSegmentLists[fillLine]\n\tfor segment in horizontalEndpoints:\n\t\taddSparseEndpointsFromSegment(doubleExtrusionWidth, endpoints, fillLine, horizontalSegmentLists, infillSolidity, removedEndpoints, segment, solidSurfaceThickness, surroundingXIntersections)\n","add sparse endpoints ."] (predictor.py:56, main())
[2020-11-20 23:30:54]    INFO >> ["@csrf_protect\n@permission_required('comments.can_moderate')\ndef approve(request, comment_id, next=None):\n\tcomment = get_object_or_404(comments.get_model(), pk=comment_id, site__pk=settings.SITE_ID)\n\tif (request.method == 'POST'):\n\t\tperform_approve(request, comment)\n\t\treturn next_redirect(request, next, approve_done, c=comment.pk)\n\telse:\n\t\treturn render_to_response('comments\/approve.html', {'comment': comment, 'next': next}, template.RequestContext(request))\n","approve a comment ."] (predictor.py:56, main())
[2020-11-20 23:30:54]    INFO >> ["def socket_pair():\n\tport = socket()\n\tport.bind(('', 0))\n\tport.listen(1)\n\tclient = socket()\n\tclient.setblocking(False)\n\tclient.connect_ex(('127.0.0.1', port.getsockname()[1]))\n\tclient.setblocking(True)\n\tserver = port.accept()[0]\n\tserver.send(b('x'))\n\tassert (client.recv(1024) == b('x'))\n\tclient.send(b('y'))\n\tassert (server.recv(1024) == b('y'))\n\tserver.setblocking(False)\n\tclient.setblocking(False)\n\treturn (server, client)\n","establish and return a pair of network sockets connected to each other ."] (predictor.py:56, main())
[2020-11-20 23:30:54]    INFO >> ["def ceil_shift(n, b):\n\tif ((not isinstance(n, (int, long))) or (not isinstance(b, (int, long)))):\n\t\traise TypeError(('unsupported\toperand\ttype(s):\t%r\tand\t%r' % (type(n).__name__, type(b).__name__)))\n\tassert ((n >= 0) and (b >= 0))\n\tmask = ((1L << b) - 1)\n\tif (n & mask):\n\t\treturn ((n >> b) + 1)\n\telse:\n\t\treturn (n >> b)\n","return ceil without performing any floating-point or division operations ."] (predictor.py:56, main())
[2020-11-20 23:30:55]    INFO >> ["def _get_location(vm_=None):\n\tlocations = avail_locations()\n\tvm_location = str(config.get_cloud_config_value('zone', vm_, __opts__, search_global=False))\n\tif (not vm_location):\n\t\traise SaltCloudNotFound('No\tlocation\tspecified\tfor\tthis\tVM.')\n\tif (vm_location in locations):\n\t\treturn vm_location\n\traise SaltCloudNotFound(\"The\tspecified\tlocation,\t'{0}',\tcould\tnot\tbe\tfound.\".format(vm_location))\n","return the vms location ."] (predictor.py:56, main())
[2020-11-20 23:30:55]    INFO >> ["def fire_coroutine_threadsafe(coro, loop):\n\tident = loop.__dict__.get('_thread_ident')\n\tif ((ident is not None) and (ident == threading.get_ident())):\n\t\traise RuntimeError('Cannot\tbe\tcalled\tfrom\twithin\tthe\tevent\tloop')\n\tif (not coroutines.iscoroutine(coro)):\n\t\traise TypeError(('A\tcoroutine\tobject\tis\trequired:\t%s' % coro))\n\tdef callback():\n\t\t'Callback\tto\tfire\tcoroutine.'\n\t\tensure_future(coro, loop=loop)\n\tloop.call_soon_threadsafe(callback)\n\treturn\n","submit a coroutine object to a given event loop ."] (predictor.py:56, main())
[2020-11-20 23:30:56]    INFO >> ["def parse_opcode_signature(env, sig, signode):\n\tm = opcode_sig_re.match(sig)\n\tif (m is None):\n\t\traise ValueError\n\t(opname, arglist) = m.groups()\n\tsignode += addnodes.desc_name(opname, opname)\n\tif (arglist is not None):\n\t\tparamlist = addnodes.desc_parameterlist()\n\t\tsignode += paramlist\n\t\tparamlist += addnodes.desc_parameter(arglist, arglist)\n\treturn opname.strip()\n","transform an opcode signature into rst nodes ."] (predictor.py:56, main())
[2020-11-20 23:30:57]    INFO >> ["def checkcache(filename=None):\n\tif (filename is None):\n\t\tfilenames = list(cache.keys())\n\telif (filename in cache):\n\t\tfilenames = [filename]\n\telse:\n\t\treturn\n\tfor filename in filenames:\n\t\t(size, mtime, lines, fullname) = cache[filename]\n\t\tif (mtime is None):\n\t\t\tcontinue\n\t\ttry:\n\t\t\tstat = os.stat(fullname)\n\t\texcept OSError:\n\t\t\tdel cache[filename]\n\t\t\tcontinue\n\t\tif ((size != stat.st_size) or (mtime != stat.st_mtime)):\n\t\t\tdel cache[filename]\n","discard cache entries that are out of date ."] (predictor.py:56, main())
[2020-11-20 23:30:57]    INFO >> ["def is_opentype_cff_font(filename):\n\tif (os.path.splitext(filename)[1].lower() == u'.otf'):\n\t\tresult = _is_opentype_cff_font_cache.get(filename)\n\t\tif (result is None):\n\t\t\twith open(filename, u'rb') as fd:\n\t\t\t\ttag = fd.read(4)\n\t\t\tresult = (tag == 'OTTO')\n\t\t\t_is_opentype_cff_font_cache[filename] = result\n\t\treturn result\n\treturn False\n","returns true if the given font is a postscript compact font format font embedded in an opentype wrapper ."] (predictor.py:56, main())
[2020-11-20 23:30:57]    INFO >> ["def do_get_current_language_bidi(parser, token):\n\targs = token.contents.split()\n\tif ((len(args) != 3) or (args[1] != 'as')):\n\t\traise TemplateSyntaxError((\"'get_current_language_bidi'\trequires\t'as\tvariable'\t(got\t%r)\" % args))\n\treturn GetCurrentLanguageBidiNode(args[2])\n","this will store the current language layout in the context ."] (predictor.py:56, main())
[2020-11-20 23:30:57]    INFO >> ["def test_bc_fit():\n\tratio = 'auto'\n\tbc = BalanceCascade(ratio=ratio, random_state=RND_SEED)\n\tbc.fit(X, Y)\n\tassert_equal(bc.min_c_, 0)\n\tassert_equal(bc.maj_c_, 1)\n\tassert_equal(bc.stats_c_[0], 8)\n\tassert_equal(bc.stats_c_[1], 12)\n","test the fitting method ."] (predictor.py:56, main())
[2020-11-20 23:30:58]    INFO >> ["def test_iht_sample_wrong_X():\n\tiht = InstanceHardnessThreshold(random_state=RND_SEED)\n\tiht.fit(X, Y)\n\tassert_raises(RuntimeError, iht.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:30:58]    INFO >> ["def _get_data():\n\traw = read_raw_fif(raw_fname).crop(0.0, 5.0).load_data()\n\tdata_picks = pick_types(raw.info, meg=True, eeg=True)\n\tother_picks = pick_types(raw.info, meg=False, stim=True, eog=True)\n\tpicks = np.sort(np.concatenate((data_picks[::16], other_picks)))\n\traw = raw.pick_channels([raw.ch_names[p] for p in picks])\n\traw.info.normalize_proj()\n\tecg = RawArray(np.zeros((1, len(raw.times))), create_info(['ECG\t063'], raw.info['sfreq'], 'ecg'))\n\tfor key in ('dev_head_t', 'buffer_size_sec', 'highpass', 'lowpass', 'dig'):\n\t\tecg.info[key] = raw.info[key]\n\traw.add_channels([ecg])\n\tsrc = read_source_spaces(src_fname)\n\ttrans = read_trans(trans_fname)\n\tsphere = make_sphere_model('auto', 'auto', raw.info)\n\tstc = _make_stc(raw, src)\n\treturn (raw, src, stc, trans, sphere)\n","get data ."] (predictor.py:56, main())
[2020-11-20 23:30:58]    INFO >> ["def H_from_ransac(fp, tp, model, maxiter=1000, match_theshold=10):\n\timport ransac\n\tdata = vstack((fp, tp))\n\t(H, ransac_data) = ransac.ransac(data.T, model, 4, maxiter, match_theshold, 10, return_all=True)\n\treturn (H, ransac_data['inliers'])\n","robust estimation of homography h from point correspondences using ransac ."] (predictor.py:56, main())
[2020-11-20 23:31:00]    INFO >> ["def RemoveFlags(flag_values=FLAGS):\n\tfor flag_name in NamesOfDefinedFlags():\n\t\tmodule_bar.RemoveOneFlag(flag_name, flag_values=flag_values)\n\tmodule_bar.RemoveFlags(flag_values=flag_values)\n","deletes the flag definitions done by the above defineflags() ."] (predictor.py:56, main())
[2020-11-20 23:31:00]    INFO >> ["def getCubicPathByBeginEnd(begin, controlPoints, elementNode, end):\n\treturn svg_reader.getCubicPoints(begin, controlPoints, end, lineation.getNumberOfBezierPoints(begin, elementNode, end))\n","get the cubic path by begin and end ."] (predictor.py:56, main())
[2020-11-20 23:31:00]    INFO >> ["def print_(*strings, **kwargs):\n\tif (not strings):\n\t\tstrings = [u'']\n\tassert isinstance(strings[0], six.text_type)\n\ttxt = u'\t'.join(strings)\n\ttxt += kwargs.get('end', u'\\n')\n\tif six.PY2:\n\t\ttxt = txt.encode(_out_encoding(), 'replace')\n\tsys.stdout.write(txt)\n","like print ."] (predictor.py:56, main())
[2020-11-20 23:31:01]    INFO >> ["def nlargest(n, iterable, key=None):\n\tif (n == 1):\n\t\tit = iter(iterable)\n\t\thead = list(islice(it, 1))\n\t\tif (not head):\n\t\t\treturn []\n\t\tif (key is None):\n\t\t\treturn [max(chain(head, it))]\n\t\treturn [max(chain(head, it), key=key)]\n\ttry:\n\t\tsize = len(iterable)\n\texcept (TypeError, AttributeError):\n\t\tpass\n\telse:\n\t\tif (n >= size):\n\t\t\treturn sorted(iterable, key=key, reverse=True)[:n]\n\tif (key is None):\n\t\tit = izip(iterable, imap(neg, count()))\n\t\tresult = _nlargest(n, it)\n\t\treturn map(itemgetter(0), result)\n\t(in1, in2) = tee(iterable)\n\tit = izip(imap(key, in1), imap(neg, count()), in2)\n\tresult = _nlargest(n, it)\n\treturn map(itemgetter(2), result)\n","find the n largest elements in a dataset ."] (predictor.py:56, main())
[2020-11-20 23:31:01]    INFO >> ["def run_migrations_online():\n\tconnectable = settings.engine\n\twith connectable.connect() as connection:\n\t\tcontext.configure(connection=connection, target_metadata=target_metadata, compare_type=COMPARE_TYPE)\n\t\twith context.begin_transaction():\n\t\t\tcontext.run_migrations()\n","run migrations in online mode ."] (predictor.py:56, main())
[2020-11-20 23:31:02]    INFO >> ["def image_member_delete(context, memb_id, session=None):\n\tsession = (session or get_session())\n\tmember_ref = _image_member_get(context, memb_id, session)\n\t_image_member_delete(context, member_ref, session)\n","delete an imagemember object ."] (predictor.py:56, main())
[2020-11-20 23:31:02]    INFO >> ["def module_to_dict(module, omittable=(lambda k: k.startswith('_'))):\n\treturn dict(((k, repr(v)) for (k, v) in module.__dict__.items() if (not omittable(k))))\n","converts a module namespace to a python dictionary ."] (predictor.py:56, main())
[2020-11-20 23:31:02]    INFO >> ["def test_sobel_v_mask():\n\tnp.random.seed(0)\n\tresult = filters.sobel_v(np.random.uniform(size=(10, 10)), np.zeros((10, 10), bool))\n\tassert_allclose(result, 0)\n","vertical sobel on a masked array should be zero ."] (predictor.py:56, main())
[2020-11-20 23:31:02]    INFO >> ["def check_err(code):\n\tif (code == OGRERR_NONE):\n\t\treturn\n\telif (code in OGRERR_DICT):\n\t\t(e, msg) = OGRERR_DICT[code]\n\t\traise e, msg\n\telse:\n\t\traise OGRException(('Unknown\terror\tcode:\t\"%s\"' % code))\n","checks the given ogrerr ."] (predictor.py:56, main())
[2020-11-20 23:31:03]    INFO >> ["def never_cache(view_func):\n\t@wraps(view_func)\n\tdef _wrapped_view_func(request, *args, **kwargs):\n\t\tresponse = view_func(request, *args, **kwargs)\n\t\tadd_never_cache_headers(response)\n\t\treturn response\n\treturn _wrapped_view_func\n","decorator that adds headers to a response so that it will never be cached ."] (predictor.py:56, main())
[2020-11-20 23:31:03]    INFO >> ["def smart_text(s, encoding='utf-8', strings_only=False, errors='strict'):\n\tif isinstance(s, Promise):\n\t\treturn s\n\treturn force_text(s, encoding, strings_only, errors)\n","returns a text object representing s -- unicode on python 2 and str on python 3 ."] (predictor.py:56, main())
[2020-11-20 23:31:04]    INFO >> ["def iterate(obj, opts):\n\tchildren = obj.get_children(**opts)\n\tif (not children):\n\t\treturn [obj]\n\ttraversal = deque()\n\tstack = deque([obj])\n\twhile stack:\n\t\tt = stack.popleft()\n\t\ttraversal.append(t)\n\t\tfor c in t.get_children(**opts):\n\t\t\tstack.append(c)\n\treturn iter(traversal)\n","traverse the given expression structure ."] (predictor.py:56, main())
[2020-11-20 23:31:04]    INFO >> ["def _getAccessibleAttribute(attributeName, elementNode):\n\tif (attributeName in globalGetAccessibleAttributeSet):\n\t\treturn getattr(Document(elementNode), attributeName, None)\n\treturn None\n","get the accessible attribute ."] (predictor.py:56, main())
[2020-11-20 23:31:05]    INFO >> ["def escapedCDATA(data):\n\tif isinstance(data, unicode):\n\t\tdata = data.encode('utf-8')\n\treturn data.replace(']]>', ']]]]><![CDATA[>')\n","escape cdata for inclusion in a document ."] (predictor.py:56, main())
[2020-11-20 23:31:05]    INFO >> ["def set_rules(rules, overwrite=True, use_conf=False):\n\tinit(use_conf=False)\n\t_ENFORCER.set_rules(rules, overwrite, use_conf)\n","set rules based on the provided dict of rules ."] (predictor.py:56, main())
[2020-11-20 23:31:06]    INFO >> ["def educate_dashes_oldschool_inverted(s):\n\treturn s.replace('---', '&#8211;').replace('--', '&#8212;')\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:31:06]    INFO >> ["def num2strg(num):\n\ts = str(num)\n\tif s.endswith('.0'):\n\t\ts = s[:(-2)]\n\treturn s\n","attempt to emulate excels default conversion from number to string ."] (predictor.py:56, main())
[2020-11-20 23:31:07]    INFO >> ["def educate_ellipses(s):\n\treturn s.replace('...', '&#8230;').replace('.\t.\t.', '&#8230;')\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:31:07]    INFO >> ["def get_bind_addr(conf, default_port=None):\n\treturn (conf.bind_host, (conf.bind_port or default_port))\n","return the host and port to bind to ."] (predictor.py:56, main())
[2020-11-20 23:31:08]    INFO >> ["def _api_get_cats(name, output, kwargs):\n\treturn report(output, keyword='categories', data=list_cats(False))\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:31:08]    INFO >> ["def cmd_list_available(args, opts):\n\tfor x in jsonrpc_call(opts, 'crawler\/spiders', 'list'):\n\t\tprint x\n","list-available - list name of available spiders ."] (predictor.py:56, main())
[2020-11-20 23:31:09]    INFO >> ["def timedelta_to_integral_minutes(delta):\n\treturn (timedelta_to_integral_seconds(delta) \/\/ 60)\n","convert a pd ."] (predictor.py:56, main())
[2020-11-20 23:31:09]    INFO >> ["def format_rfc3339(datetime_instance=None):\n\treturn (datetime_instance.isoformat('T') + 'Z')\n","formats a datetime per rfc 3339 ."] (predictor.py:56, main())
[2020-11-20 23:31:10]    INFO >> ["def ismount(path):\n\ttry:\n\t\treturn ismount_raw(path)\n\texcept OSError:\n\t\treturn False\n","test whether a path is a mount point ."] (predictor.py:56, main())
[2020-11-20 23:31:11]    INFO >> ["def get_config_var(name):\n\treturn get_config_vars().get(name)\n","return the value of a single variable using the dictionary returned by get_config_vars() ."] (predictor.py:56, main())
[2020-11-20 23:31:12]    INFO >> ["def init(mpstate):\n\treturn SerialModule(mpstate)\n","initialise module ."] (predictor.py:56, main())
[2020-11-20 23:31:12]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:31:12]    INFO >> ["def educate_quotes(s):\n\ts = single_quote_start_re.sub('&#8217;', s)\n\ts = double_quote_start_re.sub('&#8221;', s)\n\ts = double_quote_sets_re.sub('&#8220;&#8216;', s)\n\ts = single_quote_sets_re.sub('&#8216;&#8220;', s)\n\ts = decade_abbr_re.sub('&#8217;', s)\n\ts = opening_single_quotes_regex.sub('\\\\1&#8216;', s)\n\ts = closing_single_quotes_regex.sub('\\\\1&#8217;', s)\n\ts = closing_single_quotes_regex_2.sub('\\\\1&#8217;\\\\2', s)\n\ts = s.replace(\"'\", '&#8216;')\n\ts = opening_double_quotes_regex.sub('\\\\1&#8220;', s)\n\ts = closing_double_quotes_regex.sub('&#8221;', s)\n\ts = closing_double_quotes_regex_2.sub('\\\\1&#8221;', s)\n\treturn s.replace('\"', '&#8220;')\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:31:12]    INFO >> ["def get_docstring_and_rest(filename):\n\twith open(filename, 'rb') as fid:\n\t\tcontent = fid.read()\n\tcontent = content.replace('\\r\\n', '\\n')\n\ttry:\n\t\tnode = ast.parse(content)\n\texcept SyntaxError:\n\t\treturn (SYNTAX_ERROR_DOCSTRING, content.decode('utf-8'))\n\tif (not isinstance(node, ast.Module)):\n\t\traise TypeError('This\tfunction\tonly\tsupports\tmodules.\tYou\tprovided\t{0}'.format(node.__class__.__name__))\n\tif (node.body and isinstance(node.body[0], ast.Expr) and isinstance(node.body[0].value, ast.Str)):\n\t\tdocstring_node = node.body[0]\n\t\tdocstring = docstring_node.value.s\n\t\tif hasattr(docstring, 'decode'):\n\t\t\tdocstring = docstring.decode('utf-8')\n\t\trest = content.decode('utf-8').split('\\n', docstring_node.lineno)[(-1)]\n\t\treturn (docstring, rest)\n\telse:\n\t\traise ValueError('Could\tnot\tfind\tdocstring\tin\tfile\t\"{0}\".\tA\tdocstring\tis\trequired\tby\tsphinx-gallery'.format(filename))\n","separate filename content between docstring and the rest strongly inspired from ast ."] (predictor.py:56, main())
[2020-11-20 23:31:13]    INFO >> ["def test_hsl_to_rgb_part_13():\n\tassert (hsl_to_rgb(0, 100, 0) == (0, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 10) == (51, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 20) == (102, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 30) == (153, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 40) == (204, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 50) == (255, 0, 0))\n\tassert (hsl_to_rgb(0, 100, 60) == (255, 51, 51))\n\tassert (hsl_to_rgb(0, 100, 70) == (255, 102, 102))\n\tassert (hsl_to_rgb(0, 100, 80) == (255, 153, 153))\n\tassert (hsl_to_rgb(0, 100, 90) == (255, 204, 204))\n\tassert (hsl_to_rgb(0, 100, 100) == (255, 255, 255))\n","test hsl to rgb color function ."] (predictor.py:56, main())
[2020-11-20 23:31:14]    INFO >> ["def dmp_add(f, g, u, K):\n\tif (not u):\n\t\treturn dup_add(f, g, K)\n\tdf = dmp_degree(f, u)\n\tif (df < 0):\n\t\treturn g\n\tdg = dmp_degree(g, u)\n\tif (dg < 0):\n\t\treturn f\n\tv = (u - 1)\n\tif (df == dg):\n\t\treturn dmp_strip([dmp_add(a, b, v, K) for (a, b) in zip(f, g)], u)\n\telse:\n\t\tk = abs((df - dg))\n\t\tif (df > dg):\n\t\t\t(h, f) = (f[:k], f[k:])\n\t\telse:\n\t\t\t(h, g) = (g[:k], g[k:])\n\t\treturn (h + [dmp_add(a, b, v, K) for (a, b) in zip(f, g)])\n","add dense polynomials in k[x] ."] (predictor.py:56, main())
[2020-11-20 23:31:14]    INFO >> ["def load_pkcs7_data(type, buffer):\n\tif isinstance(buffer, _text_type):\n\t\tbuffer = buffer.encode('ascii')\n\tbio = _new_mem_buf(buffer)\n\tif (type == FILETYPE_PEM):\n\t\tpkcs7 = _lib.PEM_read_bio_PKCS7(bio, _ffi.NULL, _ffi.NULL, _ffi.NULL)\n\telif (type == FILETYPE_ASN1):\n\t\tpkcs7 = _lib.d2i_PKCS7_bio(bio, _ffi.NULL)\n\telse:\n\t\traise ValueError('type\targument\tmust\tbe\tFILETYPE_PEM\tor\tFILETYPE_ASN1')\n\tif (pkcs7 == _ffi.NULL):\n\t\t_raise_current_error()\n\tpypkcs7 = PKCS7.__new__(PKCS7)\n\tpypkcs7._pkcs7 = _ffi.gc(pkcs7, _lib.PKCS7_free)\n\treturn pypkcs7\n","load pkcs7 data from a buffer ."] (predictor.py:56, main())
[2020-11-20 23:31:14]    INFO >> ["def getTransformedPathByPrefix(path, prefix, xmlElement):\n\tif (len(path) < 2):\n\t\tprint 'Warning,\tbug,\tpath\tis\ttoo\tsmall\tin\tevaluate\tin\tsetPathByPrefix.'\n\t\treturn\n\tpathByKey = getTransformedPathByKey((prefix + 'path'), xmlElement)\n\tif (len(pathByKey) < len(path)):\n\t\tfor pointIndex in xrange(len(pathByKey)):\n\t\t\tpath[pointIndex] = pathByKey[pointIndex]\n\telse:\n\t\tpath = pathByKey\n\tpath[0] = getVector3ByPrefix(path[0], (prefix + 'pathStart'), xmlElement)\n\tpath[(-1)] = getVector3ByPrefix(path[(-1)], (prefix + 'pathEnd'), xmlElement)\n\treturn path\n","get path from prefix and xml element ."] (predictor.py:56, main())
[2020-11-20 23:31:14]    INFO >> ["def _CopyQueryOptionsObjectToProtocolBuffer(query, options, params):\n\toffset = 0\n\tweb_safe_string = None\n\tcursor_type = None\n\toffset = options.offset\n\tif options.cursor:\n\t\tcursor = options.cursor\n\t\tif cursor.per_result:\n\t\t\tcursor_type = search_service_pb.SearchParams.PER_RESULT\n\t\telse:\n\t\t\tcursor_type = search_service_pb.SearchParams.SINGLE\n\t\tif (isinstance(cursor, Cursor) and cursor.web_safe_string):\n\t\t\tweb_safe_string = cursor._internal_cursor\n\t_CopyQueryOptionsToProtocolBuffer(query, offset, options.limit, options.number_found_accuracy, web_safe_string, cursor_type, options.ids_only, options.returned_fields, options.snippeted_fields, options.returned_expressions, options.sort_options, params)\n","copies a queryoptions object to a searchparams proto buff ."] (predictor.py:56, main())
[2020-11-20 23:31:15]    INFO >> ["def _space_prefix(pref, full, sep=None, indent=None, include_sep=True):\n\tif (sep is None):\n\t\tsep = os.path.sep\n\tpref = pref.split(sep)\n\tfull = full.split(sep)\n\tpadding = []\n\twhile (pref and full and (pref[0] == full[0])):\n\t\tif (indent is None):\n\t\t\tpadding.append(('\t' * (len(full[0]) + len(sep))))\n\t\telse:\n\t\t\tpadding.append(('\t' * indent))\n\t\tfull.pop(0)\n\t\tpref.pop(0)\n\tif padding:\n\t\tif include_sep:\n\t\t\treturn ((''.join(padding) + sep) + sep.join(full))\n\t\telse:\n\t\t\treturn (''.join(padding) + sep.join(full))\n\telse:\n\t\treturn sep.join(full)\n","anything shared by pref and full will be replaced with spaces in full ."] (predictor.py:56, main())
[2020-11-20 23:31:15]    INFO >> ["def _setwindowsize(folder_alias, (w, h)):\n\tfinder = _getfinder()\n\targs = {}\n\tattrs = {}\n\t_code = 'core'\n\t_subcode = 'setd'\n\taevar00 = [w, h]\n\taeobj_0 = aetypes.ObjectSpecifier(want=aetypes.Type('cfol'), form='alis', seld=folder_alias, fr=None)\n\taeobj_1 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('cwnd'), fr=aeobj_0)\n\taeobj_2 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('ptsz'), fr=aeobj_1)\n\targs['----'] = aeobj_2\n\targs['data'] = aevar00\n\t(_reply, args, attrs) = finder.send(_code, _subcode, args, attrs)\n\tif ('errn' in args):\n\t\traise Error, aetools.decodeerror(args)\n\treturn (w, h)\n","set the size of a finder window for folder to ."] (predictor.py:56, main())
[2020-11-20 23:31:15]    INFO >> ["def add_lazy_relation(cls, field, relation, operation):\n\tif (relation == RECURSIVE_RELATIONSHIP_CONSTANT):\n\t\tapp_label = cls._meta.app_label\n\t\tmodel_name = cls.__name__\n\telse:\n\t\ttry:\n\t\t\t(app_label, model_name) = relation.split('.')\n\t\texcept ValueError:\n\t\t\tapp_label = cls._meta.app_label\n\t\t\tmodel_name = relation\n\t\texcept AttributeError:\n\t\t\tapp_label = relation._meta.app_label\n\t\t\tmodel_name = relation._meta.object_name\n\tmodel = get_model(app_label, model_name, seed_cache=False, only_installed=False)\n\tif model:\n\t\toperation(field, model, cls)\n\telse:\n\t\tkey = (app_label, model_name)\n\t\tvalue = (cls, field, operation)\n\t\tpending_lookups.setdefault(key, []).append(value)\n","adds a lookup on cls when a related field is defined using a string ."] (predictor.py:56, main())
[2020-11-20 23:31:15]    INFO >> ["def dmp_sqf_norm(f, u, K):\n\tif (not u):\n\t\treturn dup_sqf_norm(f, K)\n\tif (not K.is_Algebraic):\n\t\traise DomainError('ground\tdomain\tmust\tbe\talgebraic')\n\tg = dmp_raise(K.mod.rep, (u + 1), 0, K.dom)\n\tF = dmp_raise([K.one, (- K.unit)], u, 0, K)\n\ts = 0\n\twhile True:\n\t\t(h, _) = dmp_inject(f, u, K, front=True)\n\t\tr = dmp_resultant(g, h, (u + 1), K.dom)\n\t\tif dmp_sqf_p(r, u, K.dom):\n\t\t\tbreak\n\t\telse:\n\t\t\t(f, s) = (dmp_compose(f, F, u, K), (s + 1))\n\treturn (s, f, r)\n","square-free norm of f in k[x] ."] (predictor.py:56, main())
[2020-11-20 23:31:16]    INFO >> ["def u(p, r):\n\tif (r not in [1, 2]):\n\t\traise ValueError('Value\tof\tr\tshould\tlie\tbetween\t1\tand\t2')\n\t(p1, p2, p3) = p\n\tif (r == 1):\n\t\tksi = Matrix([[1], [0]])\n\telse:\n\t\tksi = Matrix([[0], [1]])\n\ta = (((((sigma1 * p1) + (sigma2 * p2)) + (sigma3 * p3)) \/ (E + m)) * ksi)\n\tif (a == 0):\n\t\ta = zeros(2, 1)\n\treturn (sqrt((E + m)) * Matrix([[ksi[(0, 0)]], [ksi[(1, 0)]], [a[(0, 0)]], [a[(1, 0)]]]))\n","p = ; r = 0 ."] (predictor.py:56, main())
[2020-11-20 23:31:17]    INFO >> ["def tryall(context, prefix=None):\n\tcontext = context.copy()\n\tresults = {}\n\tfor (k, v) in context.iteritems():\n\t\tif (not hasattr(v, '__call__')):\n\t\t\tcontinue\n\t\tif (prefix and (not k.startswith(prefix))):\n\t\t\tcontinue\n\t\tprint (k + ':'),\n\t\ttry:\n\t\t\tr = v()\n\t\t\tdictincr(results, r)\n\t\t\tprint r\n\t\texcept:\n\t\t\tprint 'ERROR'\n\t\t\tdictincr(results, 'ERROR')\n\t\t\tprint ('\t\t\t' + '\\n\t\t\t'.join(traceback.format_exc().split('\\n')))\n\tprint ('-' * 40)\n\tprint 'results:'\n\tfor (k, v) in results.iteritems():\n\t\tprint ('\t' * 2), (str(k) + ':'), v\n","tries a series of functions and prints their results ."] (predictor.py:56, main())
[2020-11-20 23:31:18]    INFO >> ["def get_script_name(environ):\n\tif (settings.FORCE_SCRIPT_NAME is not None):\n\t\treturn force_text(settings.FORCE_SCRIPT_NAME)\n\tscript_url = get_bytes_from_wsgi(environ, 'SCRIPT_URL', '')\n\tif (not script_url):\n\t\tscript_url = get_bytes_from_wsgi(environ, 'REDIRECT_URL', '')\n\tif script_url:\n\t\tif ('\/\/' in script_url):\n\t\t\tscript_url = _slashes_re.sub('\/', script_url)\n\t\tpath_info = get_bytes_from_wsgi(environ, 'PATH_INFO', '')\n\t\tscript_name = (script_url[:(- len(path_info))] if path_info else script_url)\n\telse:\n\t\tscript_name = get_bytes_from_wsgi(environ, 'SCRIPT_NAME', '')\n\treturn script_name.decode(UTF_8)\n","returns the equivalent of the http requests script_name environment variable ."] (predictor.py:56, main())
[2020-11-20 23:31:18]    INFO >> ["def indentXML(elem, level=0):\n\ti = (u'\\n' + (level * u'\t\t'))\n\tif len(elem):\n\t\tif ((not elem.text) or (not elem.text.strip())):\n\t\t\telem.text = (i + u'\t\t')\n\t\tif ((not elem.tail) or (not elem.tail.strip())):\n\t\t\telem.tail = i\n\t\tfor elem in elem:\n\t\t\tindentXML(elem, (level + 1))\n\t\tif ((not elem.tail) or (not elem.tail.strip())):\n\t\t\telem.tail = i\n\telif (level and ((not elem.tail) or (not elem.tail.strip()))):\n\t\telem.tail = i\n","does our pretty printing ."] (predictor.py:56, main())
[2020-11-20 23:31:18]    INFO >> ["def rldecode(data):\n\tdecoded = []\n\ti = 0\n\twhile (i < len(data)):\n\t\tlength = ord(data[i])\n\t\tif (length == 128):\n\t\t\tbreak\n\t\tif ((length >= 0) and (length < 128)):\n\t\t\trun = data[(i + 1):((i + 1) + (length + 1))]\n\t\t\tdecoded.append(run)\n\t\t\ti = ((i + 1) + (length + 1))\n\t\tif (length > 128):\n\t\t\trun = (data[(i + 1)] * (257 - length))\n\t\t\tdecoded.append(run)\n\t\t\ti = ((i + 1) + 1)\n\treturn ''.join(decoded)\n","runlength decoder implementation based on pdf reference version 1 ."] (predictor.py:56, main())
[2020-11-20 23:31:19]    INFO >> ["def setSVGCarvingCorners(cornerMaximum, cornerMinimum, layerHeight, loopLayers):\n\tfor loopLayer in loopLayers:\n\t\tfor loop in loopLayer.loops:\n\t\t\tfor point in loop:\n\t\t\t\tpointVector3 = Vector3(point.real, point.imag, loopLayer.z)\n\t\t\t\tcornerMaximum.maximize(pointVector3)\n\t\t\t\tcornerMinimum.minimize(pointVector3)\n\thalfLayerThickness = (0.5 * layerHeight)\n\tcornerMaximum.z += halfLayerThickness\n\tcornerMinimum.z -= halfLayerThickness\n","parse svg text and store the layers ."] (predictor.py:56, main())
[2020-11-20 23:31:19]    INFO >> ["def LoadSingleCron(cron_info, open_fn=None):\n\tbuilder = yaml_object.ObjectBuilder(CronInfoExternal)\n\thandler = yaml_builder.BuilderHandler(builder)\n\tlistener = yaml_listener.EventListener(handler)\n\tlistener.Parse(cron_info)\n\tcron_info = handler.GetResults()\n\tif (len(cron_info) < 1):\n\t\traise MalformedCronfigurationFile('Empty\tcron\tconfiguration.')\n\tif (len(cron_info) > 1):\n\t\traise MalformedCronfigurationFile('Multiple\tcron\tsections\tin\tconfiguration.')\n\treturn cron_info[0]\n","load a cron ."] (predictor.py:56, main())
[2020-11-20 23:31:19]    INFO >> ["def fix_uri_credentials(uri, to_quoted):\n\tif (not uri):\n\t\treturn\n\tlocation = glance.store.swift.StoreLocation({})\n\tif to_quoted:\n\t\tlocation.parse_uri = types.MethodType(legacy_parse_uri, location)\n\telse:\n\t\tlocation._get_credstring = types.MethodType(legacy__get_credstring, location)\n\tdecrypted_uri = None\n\ttry:\n\t\tdecrypted_uri = decrypt_location(uri)\n\texcept (TypeError, ValueError) as e:\n\t\traise exception.Invalid(str(e))\n\tlocation.parse_uri(decrypted_uri)\n\treturn encrypt_location(location.get_uri())\n","fix the given uris embedded credentials by round-tripping with storelocation ."] (predictor.py:56, main())
[2020-11-20 23:31:19]    INFO >> ["def update_qos(tenant_id, qos_id, new_qos_name=None):\n\tsession = db.get_session()\n\ttry:\n\t\tqos = session.query(l2network_models.QoS).filter_by(tenant_id=tenant_id).filter_by(qos_id=qos_id).one()\n\t\tif new_qos_name:\n\t\t\tqos['qos_name'] = new_qos_name\n\t\tsession.merge(qos)\n\t\tsession.flush()\n\t\treturn qos\n\texcept exc.NoResultFound:\n\t\traise c_exc.QosNotFound(qos_id=qos_id, tenant_id=tenant_id)\n","updates a qos to tenant association ."] (predictor.py:56, main())
[2020-11-20 23:31:20]    INFO >> ["def _processproperty(processname, property):\n\tfinder = _getfinder()\n\targs = {}\n\tattrs = {}\n\taeobj_00 = aetypes.ObjectSpecifier(want=aetypes.Type('prcs'), form='name', seld=processname, fr=None)\n\taeobj_01 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type(property), fr=aeobj_00)\n\targs['----'] = aeobj_01\n\t(_reply, args, attrs) = finder.send('core', 'getd', args, attrs)\n\tif ('errn' in args):\n\t\traise Error, aetools.decodeerror(args)\n\tif ('----' in args):\n\t\treturn args['----']\n","return the partition size and memory used for processname ."] (predictor.py:56, main())
[2020-11-20 23:31:20]    INFO >> ["def stub_out_http_backend(stubs):\n\tclass FakeHTTPConnection(object, ):\n\t\tdef __init__(self, *args, **kwargs):\n\t\t\tpass\n\t\tdef getresponse(self):\n\t\t\tif len(FAKE_RESPONSE_STACK):\n\t\t\t\treturn FAKE_RESPONSE_STACK.pop()\n\t\t\treturn utils.FakeHTTPResponse()\n\t\tdef request(self, *_args, **_kwargs):\n\t\t\tpass\n\t\tdef close(self):\n\t\t\tpass\n\tdef fake_get_conn_class(self, *args, **kwargs):\n\t\treturn FakeHTTPConnection\n\tstubs.Set(Store, '_get_conn_class', fake_get_conn_class)\n","stubs out the httplib ."] (predictor.py:56, main())
[2020-11-20 23:31:21]    INFO >> ["def _syscmd_file(target, default=''):\n\tif (sys.platform in ('dos', 'win32', 'win16', 'os2')):\n\t\treturn default\n\ttarget = _follow_symlinks(target)\n\ttry:\n\t\tf = os.popen(('file\t\"%s\"\t2>\t\/dev\/null' % target))\n\texcept (AttributeError, os.error):\n\t\treturn default\n\toutput = string.strip(f.read())\n\trc = f.close()\n\tif ((not output) or rc):\n\t\treturn default\n\telse:\n\t\treturn output\n","interface to the systems file command ."] (predictor.py:56, main())
[2020-11-20 23:31:22]    INFO >> ["def test_retry_on_normal_error(collect):\n\tkey_name = 'test-key-name'\n\tb = B(name=key_name)\n\tcollect.inject(Exception('Normal\terror'))\n\td = wabs_deleter.Deleter(BlobService('test', 'ing'), 'test-container')\n\td.delete(b)\n\twhile (len(collect.aborted_keys) < 2):\n\t\tgevent.sleep(0.1)\n\tassert (not collect.deleted_keys)\n\tcollect.inject(None)\n\td.close()\n\tassert (collect.deleted_keys == [key_name])\n","ensure retries are processed for most errors ."] (predictor.py:56, main())
[2020-11-20 23:31:22]    INFO >> ["def mkdtemp(suffix='', prefix=template, dir=None):\n\tif (dir is None):\n\t\tdir = gettempdir()\n\tnames = _get_candidate_names()\n\tfor seq in xrange(TMP_MAX):\n\t\tname = names.next()\n\t\tfile = _os.path.join(dir, ((prefix + name) + suffix))\n\t\ttry:\n\t\t\t_os.mkdir(file, 448)\n\t\t\treturn file\n\t\texcept OSError as e:\n\t\t\tif (e.errno == _errno.EEXIST):\n\t\t\t\tcontinue\n\t\t\traise\n\traise IOError, (_errno.EEXIST, 'No\tusable\ttemporary\tdirectory\tname\tfound')\n","user-callable function to create and return a unique temporary directory ."] (predictor.py:56, main())
[2020-11-20 23:31:22]    INFO >> ["def keep_lazy(*resultclasses):\n\tif (not resultclasses):\n\t\traise TypeError('You\tmust\tpass\tat\tleast\tone\targument\tto\tkeep_lazy().')\n\tdef decorator(func):\n\t\tlazy_func = lazy(func, *resultclasses)\n\t\t@wraps(func)\n\t\tdef wrapper(*args, **kwargs):\n\t\t\tfor arg in (list(args) + list(kwargs.values())):\n\t\t\t\tif isinstance(arg, Promise):\n\t\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\treturn func(*args, **kwargs)\n\t\t\treturn lazy_func(*args, **kwargs)\n\t\treturn wrapper\n\treturn decorator\n","a decorator that allows a function to be called with one or more lazy arguments ."] (predictor.py:56, main())
[2020-11-20 23:31:23]    INFO >> ["def rank(X, cond=1e-12):\n\tX = np.asarray(X)\n\tif (len(X.shape) == 2):\n\t\tD = scipy.linalg.svdvals(X)\n\t\treturn int(np.add.reduce(np.greater((D \/ D.max()), cond).astype(np.int32)))\n\telse:\n\t\treturn int((not np.alltrue(np.equal(X, 0.0))))\n","return the rank of a matrix x based on its generalized inverse ."] (predictor.py:56, main())
[2020-11-20 23:31:23]    INFO >> ["def test_allknn_fit():\n\tallknn = AllKNN(random_state=RND_SEED)\n\tallknn.fit(X, Y)\n\tassert_equal(allknn.min_c_, 0)\n\tassert_equal(allknn.maj_c_, 2)\n\tassert_equal(allknn.stats_c_[0], 4)\n\tassert_equal(allknn.stats_c_[1], 16)\n\tassert_equal(allknn.stats_c_[2], 20)\n","test the fitting method ."] (predictor.py:56, main())
[2020-11-20 23:31:23]    INFO >> ["def unwrap_order_by(clause):\n\tcols = util.column_set()\n\tresult = []\n\tstack = deque([clause])\n\twhile stack:\n\t\tt = stack.popleft()\n\t\tif (isinstance(t, ColumnElement) and ((not isinstance(t, UnaryExpression)) or (not operators.is_ordering_modifier(t.modifier)))):\n\t\t\tif isinstance(t, _label_reference):\n\t\t\t\tt = t.element\n\t\t\tif isinstance(t, _textual_label_reference):\n\t\t\t\tcontinue\n\t\t\tif (t not in cols):\n\t\t\t\tcols.add(t)\n\t\t\t\tresult.append(t)\n\t\telse:\n\t\t\tfor c in t.get_children():\n\t\t\t\tstack.append(c)\n\treturn result\n","break up an order by expression into individual column-expressions ."] (predictor.py:56, main())
[2020-11-20 23:31:24]    INFO >> ["def splithost(url):\n\tglobal _hostprog\n\tif (_hostprog is None):\n\t\timport re\n\t\t_hostprog = re.compile('^\/\/([^\/?]*)(.*)$')\n\tmatch = _hostprog.match(url)\n\tif match:\n\t\thost_port = match.group(1)\n\t\tpath = match.group(2)\n\t\tif (path and (not path.startswith('\/'))):\n\t\t\tpath = ('\/' + path)\n\t\treturn (host_port, path)\n\treturn (None, url)\n","splithost --> host[:port] ."] (predictor.py:56, main())
[2020-11-20 23:31:24]    INFO >> ["def loadValueFromFile(filename, variable, passphrase=None):\n\tif passphrase:\n\t\tmode = 'rb'\n\telse:\n\t\tmode = 'r'\n\tfileObj = open(filename, mode)\n\td = {'__file__': filename}\n\tif passphrase:\n\t\tdata = fileObj.read()\n\t\tdata = _decrypt(passphrase, data)\n\t\texec data in d, d\n\telse:\n\t\texec fileObj in d, d\n\tvalue = d[variable]\n\treturn value\n","load the value of a variable in a python file ."] (predictor.py:56, main())
[2020-11-20 23:31:25]    INFO >> ["def check_random_state(seed):\n\tif ((seed is None) or (seed is np.random)):\n\t\treturn np.random.mtrand._rand\n\tif isinstance(seed, (int, np.integer)):\n\t\treturn np.random.RandomState(seed)\n\tif isinstance(seed, np.random.RandomState):\n\t\treturn seed\n\traise ValueError(('%r\tcannot\tbe\tused\tto\tseed\ta\tnumpy.random.RandomState\tinstance' % seed))\n","turn seed into a np ."] (predictor.py:56, main())
[2020-11-20 23:31:25]    INFO >> ["def hashPasswordTuple(password, digestMod=hashlib.sha512, iterations=10000, saltSize=32):\n\tsalt = os.urandom(saltSize)\n\tpassword = password.encode(u'utf-8')\n\thash = pbkdf2(password, salt, iterations, digestMod)\n\tdigestname = digestMod.__name__.replace(u'openssl_', u'')\n\treturn (digestname, iterations, salt, hash)\n","module function to hash a password according to the pbkdf2 specification ."] (predictor.py:56, main())
[2020-11-20 23:31:25]    INFO >> ["def header_elements(fieldname, fieldvalue):\n\tif (not fieldvalue):\n\t\treturn []\n\tresult = []\n\tfor element in RE_HEADER_SPLIT.split(fieldvalue):\n\t\tif (fieldname.startswith('Accept') or (fieldname == 'TE')):\n\t\t\thv = AcceptElement.from_str(element)\n\t\telse:\n\t\t\thv = HeaderElement.from_str(element)\n\t\tresult.append(hv)\n\treturn list(reversed(sorted(result)))\n","return a sorted headerelement list from a comma-separated header string ."] (predictor.py:56, main())
[2020-11-20 23:31:26]    INFO >> ["def parse_dict_header(value):\n\tresult = {}\n\tfor item in _parse_list_header(value):\n\t\tif ('=' not in item):\n\t\t\tresult[item] = None\n\t\t\tcontinue\n\t\t(name, value) = item.split('=', 1)\n\t\tif (value[:1] == value[(-1):] == '\"'):\n\t\t\tvalue = unquote_header_value(value[1:(-1)])\n\t\tresult[name] = value\n\treturn result\n","parse lists of key ."] (predictor.py:56, main())
[2020-11-20 23:31:27]    INFO >> ["def _generate_cache_key(request, headerlist, key_prefix):\n\tctx = md5.new()\n\tfor header in headerlist:\n\t\tvalue = request.META.get(header, None)\n\t\tif (value is not None):\n\t\t\tctx.update(value)\n\treturn ('views.decorators.cache.cache_page.%s.%s.%s' % (key_prefix, request.path, ctx.hexdigest()))\n","returns a cache key from the headers given in the header list ."] (predictor.py:56, main())
[2020-11-20 23:31:27]    INFO >> ["def find_free_port(interface='127.0.0.1', socket_family=socket.AF_INET, socket_type=socket.SOCK_STREAM):\n\taddress = socket.getaddrinfo(interface, 0)[0][4]\n\tprobe = socket.socket(socket_family, socket_type)\n\ttry:\n\t\tprobe.bind(address)\n\t\treturn probe.getsockname()\n\tfinally:\n\t\tprobe.close()\n","ask the platform to allocate a free port on the specified interface ."] (predictor.py:56, main())
[2020-11-20 23:31:28]    INFO >> ["def libvlc_audio_set_format_callbacks(mp, setup, cleanup):\n\tf = (_Cfunctions.get('libvlc_audio_set_format_callbacks', None) or _Cfunction('libvlc_audio_set_format_callbacks', ((1,), (1,), (1,)), None, None, MediaPlayer, AudioSetupCb, AudioCleanupCb))\n\treturn f(mp, setup, cleanup)\n","set decoded audio format ."] (predictor.py:56, main())
[2020-11-20 23:31:28]    INFO >> ["def image_property_delete(context, prop_ref, image_ref, session=None):\n\tsession = (session or get_session())\n\tprop = session.query(models.ImageProperty).filter_by(image_id=image_ref, name=prop_ref).one()\n\tprop.delete(session=session)\n\treturn prop\n","used internally by image_property_create and image_property_update ."] (predictor.py:56, main())
[2020-11-20 23:31:29]    INFO >> ["def test_sample_wrong_X():\n\tada = ADASYN(random_state=RND_SEED)\n\tada.fit(X, Y)\n\tassert_raises(RuntimeError, ada.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:31:29]    INFO >> ["def urlsafe_decrypt(key, ciphertext):\n\tciphertext = base64.urlsafe_b64decode(str(ciphertext))\n\tcypher = AES.new(key, AES.MODE_CBC, ciphertext[:16])\n\tpadded = cypher.decrypt(ciphertext[16:])\n\treturn padded[:padded.rfind(chr(0))]\n","decrypts url-safe base64 encoded ciphertext ."] (predictor.py:56, main())
[2020-11-20 23:31:29]    INFO >> ["def new_figure_manager(num, *args, **kwargs):\n\t_focus = windowing.FocusManager()\n\tFigureClass = kwargs.pop('FigureClass', Figure)\n\tfigure = FigureClass(*args, **kwargs)\n\twindow = Tk.Tk()\n\tcanvas = FigureCanvasTkAgg(figure, master=window)\n\tfigManager = FigureManagerTkAgg(canvas, num, window)\n\tif matplotlib.is_interactive():\n\t\tfigManager.show()\n\treturn figManager\n","create a new figure manager instance ."] (predictor.py:56, main())
[2020-11-20 23:31:30]    INFO >> ["def convert_image(source, dest, out_format, run_as_root=False):\n\tcmd = ('qemu-img', 'convert', '-O', out_format, source, dest)\n\tutils.execute(run_as_root=run_as_root, *cmd)\n","convert image to other format ."] (predictor.py:56, main())
[2020-11-20 23:31:30]    INFO >> ["def compress_kml(kml):\n\tkmz = cStringIO.StringIO()\n\tzf = zipfile.ZipFile(kmz, 'a', zipfile.ZIP_DEFLATED)\n\tzf.writestr('doc.kml', kml.encode(settings.DEFAULT_CHARSET))\n\tzf.close()\n\tkmz.seek(0)\n\treturn kmz.read()\n","returns compressed kmz from the given kml string ."] (predictor.py:56, main())
[2020-11-20 23:31:30]    INFO >> ["def new_figure_manager_given_figure(num, figure):\n\tcanvas = FigureCanvasGDK(figure)\n\tmanager = FigureManagerBase(canvas, num)\n\treturn manager\n","create a new figure manager instance for the given figure ."] (predictor.py:56, main())
[2020-11-20 23:31:31]    INFO >> ["def python_3000_has_key(logical_line, noqa):\n\tpos = logical_line.find('.has_key(')\n\tif ((pos > (-1)) and (not noqa)):\n\t\t(yield (pos, \"W601\t.has_key()\tis\tdeprecated,\tuse\t'in'\"))\n","the {} ."] (predictor.py:56, main())
[2020-11-20 23:31:31]    INFO >> ["def new_figure_manager_given_figure(num, figure):\n\tcanvas = FigureCanvasGDK(figure)\n\tmanager = FigureManagerBase(canvas, num)\n\treturn manager\n","create a new figure manager instance for the given figure ."] (predictor.py:56, main())
[2020-11-20 23:31:32]    INFO >> ["def _unpack_ipv4(ip_str):\n\tif (not ip_str.lower().startswith('0000:0000:0000:0000:0000:ffff:')):\n\t\treturn None\n\treturn ip_str.rsplit(':', 1)[1]\n","unpack an ipv4 address that was mapped in a compressed ipv6 address ."] (predictor.py:56, main())
[2020-11-20 23:31:32]    INFO >> ["def urlizetrunc(value, limit):\n\tfrom django.utils.html import urlize\n\treturn urlize(value, trim_url_limit=int(limit), nofollow=True)\n","converts urls into clickable links ."] (predictor.py:56, main())
[2020-11-20 23:31:32]    INFO >> ["def header_decode(s):\n\ts = s.replace('_', '\t')\n\treturn re.sub('=\\\\w{2}', _unquote_match, s)\n","decode a string encoded with rfc 2045 mime header q encoding ."] (predictor.py:56, main())
[2020-11-20 23:31:33]    INFO >> ["def getMaximumSpan(loop):\n\textent = (getMaximumByPathComplex(loop) - getMinimumByPathComplex(loop))\n\treturn max(extent.real, extent.imag)\n","get the maximum span of the loop ."] (predictor.py:56, main())
[2020-11-20 23:31:34]    INFO >> ["def draw_if_interactive():\n\tif matplotlib.is_interactive():\n\t\tfigManager = Gcf.get_active()\n\t\tif (figManager is not None):\n\t\t\tfigManager.canvas.invalidate()\n","is called after every pylab drawing command ."] (predictor.py:56, main())
[2020-11-20 23:31:34]    INFO >> ["def store_rendered_templates(store, signal, sender, template, context, **kwargs):\n\tstore.setdefault('template', []).append(template)\n\tstore.setdefault('context', ContextList()).append(context)\n","stores templates and contexts that are rendered ."] (predictor.py:56, main())
[2020-11-20 23:31:34]    INFO >> ["def _reinstall_default_lookups():\n\t_install_lookups(dict(instance_state=_default_state_getter, instance_dict=_default_dict_getter, manager_of_class=_default_manager_getter))\n\t_instrumentation_factory._extended = False\n","restore simplified lookups ."] (predictor.py:56, main())
[2020-11-20 23:31:34]    INFO >> ["def _initialize_builtins():\n\tfor filename in os.listdir(_handler_dir):\n\t\tif os.path.isfile(_get_yaml_path(filename, '')):\n\t\t\t_available_builtins.append(filename)\n","scan the immediate subdirectories of the builtins module ."] (predictor.py:56, main())
[2020-11-20 23:31:35]    INFO >> ["def _remove_dead_thread_references():\n\tfor thread_reference in set(_thread_references):\n\t\tif (thread_reference() is None):\n\t\t\t_thread_references.discard(thread_reference)\n","remove inactive threads from _thread_references ."] (predictor.py:56, main())
[2020-11-20 23:31:35]    INFO >> ["def __virtual__():\n\tif (HAS_NAPALM and ('proxy' in __opts__)):\n\t\treturn __virtualname__\n\telse:\n\t\treturn (False, 'The\tnetwork\tNTP\tstate\t(netntp)\tcannot\tbe\tloaded:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNAPALM\tor\tproxy\tcould\tnot\tbe\tloaded.')\n","napalm library must be installed for this module to work ."] (predictor.py:56, main())
[2020-11-20 23:31:36]    INFO >> ["def article(word, function=INDEFINITE):\n\treturn (((function == DEFINITE) and definite_article(word)) or indefinite_article(word))\n","returns the indefinite or definite article for the given word ."] (predictor.py:56, main())
[2020-11-20 23:31:36]    INFO >> ["def outerjoin(left, right, onclause=None, join_to_left=None):\n\treturn _ORMJoin(left, right, onclause, True)\n","produce a left outer join between left and right clauses ."] (predictor.py:56, main())
[2020-11-20 23:31:36]    INFO >> ["def packRequest_window_change(geometry):\n\t(rows, cols, xpixel, ypixel) = geometry\n\treturn struct.pack('>4L', cols, rows, xpixel, ypixel)\n","pack a window-change request so that it is suitable for sending ."] (predictor.py:56, main())
[2020-11-20 23:31:37]    INFO >> ["def getAlterationFileLineBlindly(fileName):\n\treturn ('(<alterationFile>)\t%s\t(<\/alterationFile>)' % fileName)\n","get the alteration file line from the filename ."] (predictor.py:56, main())
[2020-11-20 23:31:37]    INFO >> ["def quality_parsed(mime_type, parsed_ranges):\n\treturn fitness_and_quality_parsed(mime_type, parsed_ranges)[1]\n","find the best match for a given mime-type against a list of media_ranges that have already been parsed by parse_media_range() ."] (predictor.py:56, main())
[2020-11-20 23:31:37]    INFO >> ["def cmd_list_resources(args, opts):\n\tfor x in json_get(opts, '')['resources']:\n\t\tprint(x)\n","list-resources - list available web service resources ."] (predictor.py:56, main())
[2020-11-20 23:31:38]    INFO >> ["def target_update(target, deps, cmd):\n\tif target_outdated(target, deps):\n\t\tsystem(cmd)\n","update a target with a given command given a list of dependencies ."] (predictor.py:56, main())
[2020-11-20 23:31:38]    INFO >> ["def remove_file_failed(failed_file):\n\ttry:\n\t\tek(os.remove, failed_file)\n\texcept Exception:\n\t\tpass\n","remove file from filesystem ."] (predictor.py:56, main())
[2020-11-20 23:31:38]    INFO >> ["def reload_localzone():\n\tglobal _cache_tz\n\t_cache_tz = pytz.timezone(get_localzone_name())\n","reload the cached localzone ."] (predictor.py:56, main())
[2020-11-20 23:31:39]    INFO >> ["def default_user_agent():\n\t_implementation = platform.python_implementation()\n\tif (_implementation == 'CPython'):\n\t\t_implementation_version = platform.python_version()\n\telif (_implementation == 'PyPy'):\n\t\t_implementation_version = ('%s.%s.%s' % (sys.pypy_version_info.major, sys.pypy_version_info.minor, sys.pypy_version_info.micro))\n\t\tif (sys.pypy_version_info.releaselevel != 'final'):\n\t\t\t_implementation_version = ''.join([_implementation_version, sys.pypy_version_info.releaselevel])\n\telif (_implementation == 'Jython'):\n\t\t_implementation_version = platform.python_version()\n\telif (_implementation == 'IronPython'):\n\t\t_implementation_version = platform.python_version()\n\telse:\n\t\t_implementation_version = 'Unknown'\n\ttry:\n\t\tp_system = platform.system()\n\t\tp_release = platform.release()\n\texcept IOError:\n\t\tp_system = 'Unknown'\n\t\tp_release = 'Unknown'\n\treturn '\t'.join([('python-requests\/%s' % __version__), ('%s\/%s' % (_implementation, _implementation_version)), ('%s\/%s' % (p_system, p_release))])\n","return a string representing the default user agent ."] (predictor.py:56, main())
[2020-11-20 23:31:40]    INFO >> ["def get_scheme_names():\n\tschemes = _INSTALL_SCHEMES.keys()\n\tschemes.sort()\n\treturn tuple(schemes)\n","return a tuple containing the schemes names ."] (predictor.py:56, main())
[2020-11-20 23:31:40]    INFO >> ["def sector():\n\treturn s3_rest_controller('org', 'sector')\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:31:40]    INFO >> ["def cooperate(iterator):\n\treturn _theCooperator.cooperate(iterator)\n","start running the given iterator as a long-running cooperative task ."] (predictor.py:56, main())
[2020-11-20 23:31:41]    INFO >> ["def coiterate(iterator):\n\treturn _theCooperator.coiterate(iterator)\n","cooperatively iterate over the given iterator ."] (predictor.py:56, main())
[2020-11-20 23:31:41]    INFO >> ["def generate_timestamp():\n\treturn unicode_type(int(time.time()))\n","get seconds since epoch ."] (predictor.py:56, main())
[2020-11-20 23:31:42]    INFO >> ["def multicall(conf, context, topic, msg, timeout, connection_pool):\n\tLOG.debug(_('Making\tsynchronous\tcall\ton\t%s\t...'), topic)\n\tmsg_id = uuid.uuid4().hex\n\tmsg.update({'_msg_id': msg_id})\n\tLOG.debug((_('MSG_ID\tis\t%s') % msg_id))\n\t_add_unique_id(msg)\n\tpack_context(msg, context)\n\twith _reply_proxy_create_sem:\n\t\tif (not connection_pool.reply_proxy):\n\t\t\tconnection_pool.reply_proxy = ReplyProxy(conf, connection_pool)\n\tmsg.update({'_reply_q': connection_pool.reply_proxy.get_reply_q()})\n\twait_msg = MulticallProxyWaiter(conf, msg_id, timeout, connection_pool)\n\twith ConnectionContext(conf, connection_pool) as conn:\n\t\tconn.topic_send(topic, rpc_common.serialize_msg(msg), timeout)\n\treturn wait_msg\n","make a call that returns multiple times ."] (predictor.py:56, main())
[2020-11-20 23:31:42]    INFO >> ["def addFacesByConvexBottomTopLoop(faces, indexedLoopBottom, indexedLoopTop):\n\tif ((len(indexedLoopBottom) == 0) or (len(indexedLoopTop) == 0)):\n\t\treturn\n\tfor indexedPointIndex in xrange(max(len(indexedLoopBottom), len(indexedLoopTop))):\n\t\tindexedConvex = []\n\t\tif (len(indexedLoopBottom) > 1):\n\t\t\tindexedConvex.append(indexedLoopBottom[indexedPointIndex])\n\t\t\tindexedConvex.append(indexedLoopBottom[((indexedPointIndex + 1) % len(indexedLoopBottom))])\n\t\telse:\n\t\t\tindexedConvex.append(indexedLoopBottom[0])\n\t\tif (len(indexedLoopTop) > 1):\n\t\t\tindexedConvex.append(indexedLoopTop[((indexedPointIndex + 1) % len(indexedLoopTop))])\n\t\t\tindexedConvex.append(indexedLoopTop[indexedPointIndex])\n\t\telse:\n\t\t\tindexedConvex.append(indexedLoopTop[0])\n\t\taddFacesByConvex(faces, indexedConvex)\n","add faces from loops ."] (predictor.py:56, main())
[2020-11-20 23:31:43]    INFO >> ["def _dict_pprinter_factory(start, end, basetype=None):\n\tdef inner(obj, p, cycle):\n\t\ttyp = type(obj)\n\t\tif ((basetype is not None) and (typ is not basetype) and (typ.__repr__ != basetype.__repr__)):\n\t\t\treturn p.text(typ.__repr__(obj))\n\t\tif cycle:\n\t\t\treturn p.text('{...}')\n\t\tp.begin_group(1, start)\n\t\tkeys = obj.keys()\n\t\tif (not (p.max_seq_length and (len(obj) >= p.max_seq_length))):\n\t\t\ttry:\n\t\t\t\tkeys = sorted(keys)\n\t\t\texcept Exception:\n\t\t\t\tpass\n\t\tfor (idx, key) in p._enumerate(keys):\n\t\t\tif idx:\n\t\t\t\tp.text(',')\n\t\t\t\tp.breakable()\n\t\t\tp.pretty(key)\n\t\t\tp.text(':\t')\n\t\t\tp.pretty(obj[key])\n\t\tp.end_group(1, end)\n\treturn inner\n","factory that returns a pprint function used by the default pprint of dicts and dict proxies ."] (predictor.py:56, main())
[2020-11-20 23:31:44]    INFO >> ["def _handle_ns(packageName, path_item):\n\timporter = get_importer(path_item)\n\tif (importer is None):\n\t\treturn None\n\tloader = importer.find_module(packageName)\n\tif (loader is None):\n\t\treturn None\n\tmodule = sys.modules.get(packageName)\n\tif (module is None):\n\t\tmodule = sys.modules[packageName] = types.ModuleType(packageName)\n\t\tmodule.__path__ = []\n\t\t_set_parent_ns(packageName)\n\telif (not hasattr(module, '__path__')):\n\t\traise TypeError('Not\ta\tpackage:', packageName)\n\thandler = _find_adapter(_namespace_handlers, importer)\n\tsubpath = handler(importer, path_item, packageName, module)\n\tif (subpath is not None):\n\t\tpath = module.__path__\n\t\tpath.append(subpath)\n\t\tloader.load_module(packageName)\n\t\tsys_path = [((p and _normalize_cached(p)) or p) for p in sys.path]\n\t\tdef sort_key(p):\n\t\t\tparts = p.split(os.sep)\n\t\t\tparts = parts[:(- (packageName.count('.') + 1))]\n\t\t\treturn sys_path.index(_normalize_cached(os.sep.join(parts)))\n\t\tpath.sort(key=sort_key)\n\t\tmodule.__path__[:] = [_normalize_cached(p) for p in path]\n\treturn subpath\n","ensure that named package includes a subpath of path_item ."] (predictor.py:56, main())
[2020-11-20 23:31:45]    INFO >> ["def get_nav_close(fund_type='all', sub_type='all'):\n\tct._write_head()\n\tnums = _get_fund_num((ct.SINA_NAV_COUNT_URL % (ct.P_TYPE['http'], ct.DOMAINS['vsf'], ct.NAV_CLOSE_KEY, ct.NAV_CLOSE_API, ct.NAV_CLOSE_T2[fund_type], ct.NAV_CLOSE_T3[sub_type])))\n\tfund_df = _parse_fund_data((ct.SINA_NAV_DATA_URL % (ct.P_TYPE['http'], ct.DOMAINS['vsf'], ct.NAV_OPEN_KEY, ct.NAV_CLOSE_API, nums, ct.NAV_CLOSE_T2[fund_type], ct.NAV_CLOSE_T3[sub_type])), 'close')\n\treturn fund_df\n","parameters type:string 1 ."] (predictor.py:56, main())
[2020-11-20 23:31:45]    INFO >> ["def verify_rsa_sha1(request, rsa_public_key):\n\tnorm_params = normalize_parameters(request.params)\n\turi = normalize_base_string_uri(request.uri)\n\tmessage = construct_base_string(request.http_method, uri, norm_params).encode(u'utf-8')\n\tsig = binascii.a2b_base64(request.signature.encode(u'utf-8'))\n\talg = _jwt_rs1_signing_algorithm()\n\tkey = _prepare_key_plus(alg, rsa_public_key)\n\treturn alg.verify(message, key, sig)\n","verify a rsassa-pkcs #1 v1 ."] (predictor.py:56, main())
[2020-11-20 23:31:46]    INFO >> ["def filter_type_between(left, right, supports_midi=False, is_drum_pad=False, supports_instrument=False):\n\tTypes = Live.Browser.FilterType\n\tif (right and (right.type in (DeviceType.instrument, DeviceType.midi_effect))):\n\t\treturn Types.midi_effect_hotswap\n\tif (left and (left.type in (DeviceType.instrument, DeviceType.audio_effect))):\n\t\treturn Types.audio_effect_hotswap\n\tif supports_midi:\n\t\tif supports_instrument:\n\t\t\treturn (Types.drum_pad_hotswap if is_drum_pad else Types.instrument_hotswap)\n\t\telse:\n\t\t\treturn Types.midi_effect_hotswap\n\treturn Types.audio_effect_hotswap\n","given left and right are two consecutive devices in a valid device chain ."] (predictor.py:56, main())
[2020-11-20 23:31:47]    INFO >> ["def _convert_to_idn(url):\n\tparts = list(urlparse.urlsplit(url))\n\ttry:\n\t\tparts[1].encode(u'ascii')\n\texcept UnicodeEncodeError:\n\t\thost = parts[1].rsplit(u':', 1)\n\t\tnewhost = []\n\t\tport = u''\n\t\tif (len(host) == 2):\n\t\t\tport = host.pop()\n\t\tfor h in host[0].split(u'.'):\n\t\t\tnewhost.append(h.encode(u'idna').decode(u'utf-8'))\n\t\tparts[1] = u'.'.join(newhost)\n\t\tif port:\n\t\t\tparts[1] += (u':' + port)\n\t\treturn urlparse.urlunsplit(parts)\n\telse:\n\t\treturn url\n","convert a url to idn notation ."] (predictor.py:56, main())
[2020-11-20 23:31:47]    INFO >> ["def serve(request, path, document_root=None, insecure=False, **kwargs):\n\tif ((not settings.DEBUG) and (not insecure)):\n\t\traise ImproperlyConfigured(\"The\tstaticfiles\tview\tcan\tonly\tbe\tused\tin\tdebug\tmode\tor\tif\tthe\tthe\t--insecure\toption\tof\t'runserver'\tis\tused\")\n\tnormalized_path = posixpath.normpath(urllib.unquote(path)).lstrip('\/')\n\tabsolute_path = finders.find(normalized_path)\n\tif (not absolute_path):\n\t\tif (path.endswith('\/') or (path == '')):\n\t\t\traise Http404('Directory\tindexes\tare\tnot\tallowed\there.')\n\t\traise Http404((\"'%s'\tcould\tnot\tbe\tfound\" % path))\n\t(document_root, path) = os.path.split(absolute_path)\n\treturn static.serve(request, path, document_root=document_root, **kwargs)\n","serve static files below a given point in the directory structure or from locations inferred from the staticfiles finders ."] (predictor.py:56, main())
[2020-11-20 23:31:47]    INFO >> ["def runWithWarningsSuppressed(suppressedWarnings, f, *a, **kw):\n\tfor (args, kwargs) in suppressedWarnings:\n\t\twarnings.filterwarnings(*args, **kwargs)\n\taddedFilters = warnings.filters[:len(suppressedWarnings)]\n\ttry:\n\t\tresult = f(*a, **kw)\n\texcept:\n\t\texc_info = sys.exc_info()\n\t\t_resetWarningFilters(None, addedFilters)\n\t\traise exc_info[0], exc_info[1], exc_info[2]\n\telse:\n\t\tif isinstance(result, defer.Deferred):\n\t\t\tresult.addBoth(_resetWarningFilters, addedFilters)\n\t\telse:\n\t\t\t_resetWarningFilters(None, addedFilters)\n\t\treturn result\n","run the function c{f} ."] (predictor.py:56, main())
[2020-11-20 23:31:48]    INFO >> ["def framework_find(fn, executable_path=None, env=None):\n\ttry:\n\t\treturn dyld_find(fn, executable_path=executable_path, env=env)\n\texcept ValueError:\n\t\tpass\n\tfmwk_index = fn.rfind('.framework')\n\tif (fmwk_index == (-1)):\n\t\tfmwk_index = len(fn)\n\t\tfn += '.framework'\n\tfn = os.path.join(fn, os.path.basename(fn[:fmwk_index]))\n\treturn dyld_find(fn, executable_path=executable_path, env=env)\n","find a framework using dyld semantics in a very loose manner ."] (predictor.py:56, main())
[2020-11-20 23:31:49]    INFO >> ["def extract_views_from_urlpatterns(urlpatterns, base=''):\n\tviews = []\n\tfor p in urlpatterns:\n\t\tif hasattr(p, '_get_callback'):\n\t\t\ttry:\n\t\t\t\tviews.append((p._get_callback(), (base + p.regex.pattern)))\n\t\t\texcept ViewDoesNotExist:\n\t\t\t\tcontinue\n\t\telif hasattr(p, '_get_url_patterns'):\n\t\t\ttry:\n\t\t\t\tpatterns = p.url_patterns\n\t\t\texcept ImportError:\n\t\t\t\tcontinue\n\t\t\tviews.extend(extract_views_from_urlpatterns(patterns, (base + p.regex.pattern)))\n\t\telse:\n\t\t\traise TypeError((_('%s\tdoes\tnot\tappear\tto\tbe\ta\turlpattern\tobject') % p))\n\treturn views\n","return a list of views from a list of urlpatterns ."] (predictor.py:56, main())
[2020-11-20 23:31:49]    INFO >> ["def normpath(path):\n\tif (path == ''):\n\t\treturn '.'\n\tinitial_slashes = path.startswith('\/')\n\tif (initial_slashes and path.startswith('\/\/') and (not path.startswith('\/\/\/'))):\n\t\tinitial_slashes = 2\n\tcomps = path.split('\/')\n\tnew_comps = []\n\tfor comp in comps:\n\t\tif (comp in ('', '.')):\n\t\t\tcontinue\n\t\tif ((comp != '..') or ((not initial_slashes) and (not new_comps)) or (new_comps and (new_comps[(-1)] == '..'))):\n\t\t\tnew_comps.append(comp)\n\t\telif new_comps:\n\t\t\tnew_comps.pop()\n\tcomps = new_comps\n\tpath = '\/'.join(comps)\n\tif initial_slashes:\n\t\tpath = (('\/' * initial_slashes) + path)\n\treturn (path or '.')\n","normalize path ."] (predictor.py:56, main())
[2020-11-20 23:31:50]    INFO >> ["def set_query_params(url, param_dict):\n\t(scheme, netloc, path, query_string, fragment) = urlsplit(url)\n\tquery_params = parse_qs(query_string, keep_blank_values=True)\n\tfor (param_name, param_value) in param_dict.items():\n\t\tif (param_value is None):\n\t\t\tdel query_params[param_name]\n\t\telse:\n\t\t\tquery_params[param_name] = [param_value]\n\tnew_query_string = urlencode(query_params, doseq=True)\n\treturn urlunsplit((scheme, netloc, path, new_query_string, fragment))\n","given a url ."] (predictor.py:56, main())
[2020-11-20 23:31:50]    INFO >> ["def constant_time_compare(val1, val2):\n\tif (len(val1) != len(val2)):\n\t\treturn False\n\tresult = 0\n\tif (six.PY3 and isinstance(val1, bytes) and isinstance(val2, bytes)):\n\t\tfor (x, y) in zip(val1, val2):\n\t\t\tresult |= (x ^ y)\n\telse:\n\t\tfor (x, y) in zip(val1, val2):\n\t\t\tresult |= (ord(x) ^ ord(y))\n\treturn (result == 0)\n","returns true if the two strings are equal ."] (predictor.py:56, main())
[2020-11-20 23:31:51]    INFO >> ["def get_fun(fun):\n\tserv = _get_serv(ret=None)\n\tret = {}\n\tfor minion in serv.smembers('minions'):\n\t\tind_str = '{0}:{1}'.format(minion, fun)\n\t\ttry:\n\t\t\tjid = serv.get(ind_str)\n\t\texcept Exception:\n\t\t\tcontinue\n\t\tif (not jid):\n\t\t\tcontinue\n\t\tdata = serv.get('{0}:{1}'.format(minion, jid))\n\t\tif data:\n\t\t\tret[minion] = json.loads(data)\n\treturn ret\n","return a dict of the last function called for all minions ."] (predictor.py:56, main())
[2020-11-20 23:31:51]    INFO >> ["def is_image_visible(context, image, status=None):\n\tif context.is_admin:\n\t\treturn True\n\tif (image['owner'] is None):\n\t\treturn True\n\tif (image['visibility'] in ['public', 'community']):\n\t\treturn True\n\tif (context.owner is not None):\n\t\tif (context.owner == image['owner']):\n\t\t\treturn True\n\t\tif ('shared' == image['visibility']):\n\t\t\tmembers = image_member_find(context, image_id=image['id'], member=context.owner, status=status)\n\t\t\tif members:\n\t\t\t\treturn True\n\treturn False\n","return true if the image is visible in this context ."] (predictor.py:56, main())
[2020-11-20 23:31:52]    INFO >> ["def _api_change_script(name, output, kwargs):\n\tvalue = kwargs.get('value')\n\tvalue2 = kwargs.get('value2')\n\tif (value and value2):\n\t\tnzo_id = value\n\t\tscript = value2\n\t\tif (script.lower() == 'none'):\n\t\t\tscript = None\n\t\tresult = NzbQueue.do.change_script(nzo_id, script)\n\t\treturn report(output, keyword='status', data=bool((result > 0)))\n\telse:\n\t\treturn report(output, _MSG_NO_VALUE)\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:31:54]    INFO >> ["def splitnport(host, defport=(-1)):\n\tglobal _nportprog\n\tif (_nportprog is None):\n\t\t_nportprog = re.compile('^(.*):(.*)$')\n\tmatch = _nportprog.match(host)\n\tif match:\n\t\t(host, port) = match.group(1, 2)\n\t\tif port:\n\t\t\ttry:\n\t\t\t\tnport = int(port)\n\t\t\texcept ValueError:\n\t\t\t\tnport = None\n\t\t\treturn (host, nport)\n\treturn (host, defport)\n","split host and port ."] (predictor.py:56, main())
[2020-11-20 23:31:54]    INFO >> ["def hardlinkFile(srcFile, destFile):\n\ttry:\n\t\tlink(srcFile, destFile)\n\t\tfixSetGroupID(destFile)\n\texcept Exception as e:\n\t\tsickrage.srCore.srLogger.warning((u'Failed\tto\tcreate\thardlink\tof\t%s\tat\t%s.\tError:\t%r.\tCopying\tinstead' % (srcFile, destFile, e)))\n\t\tcopyFile(srcFile, destFile)\n","create a hard-link between source and destination ."] (predictor.py:56, main())
[2020-11-20 23:31:54]    INFO >> ["def test_nearmiss_init():\n\tratio = 1.0\n\tnm3 = NearMiss(ratio=ratio, random_state=RND_SEED, version=VERSION_NEARMISS)\n\tassert_equal(nm3.version, VERSION_NEARMISS)\n\tassert_equal(nm3.n_neighbors, 3)\n\tassert_equal(nm3.ratio, ratio)\n\tassert_equal(nm3.random_state, RND_SEED)\n","test the initialisation of the object ."] (predictor.py:56, main())
[2020-11-20 23:31:54]    INFO >> ["def dbcheck(exprstr, globals=None, locals=None):\n\tdef decorate(func):\n\t\texpr = compile(exprstr, ('dbcheck-%s' % func.__name__), 'eval')\n\t\tdef check(*args, **kwds):\n\t\t\tif (not eval(expr, globals, locals)):\n\t\t\t\traise DbcheckError(exprstr, func, args, kwds)\n\t\t\treturn func(*args, **kwds)\n\t\treturn check\n\treturn decorate\n","decorator to implement debugging assertions ."] (predictor.py:56, main())
[2020-11-20 23:31:55]    INFO >> ["@with_setup(prepare_stdout)\ndef test_output_when_could_not_find_features_colorless():\n\tpath = fs.relpath(join(abspath(dirname(__file__)), 'no_features', 'unexistent-folder'))\n\trunner = Runner(path, verbosity=3, no_color=True)\n\trunner.run()\n\tassert_stdout_lines(('Oops!\\ncould\tnot\tfind\tfeatures\tat\t.\/%s\\n' % path))\n","testing the colorful output of many successful features colorless ."] (predictor.py:56, main())
[2020-11-20 23:31:55]    INFO >> ["def flatten_blocks(lines, num_indents=(-1)):\n\tINDENTATION = ('\t' * 4)\n\tif (not lines):\n\t\treturn ''\n\tif isinstance(lines, six.string_types):\n\t\treturn ((INDENTATION * num_indents) + lines)\n\treturn '\\n'.join([flatten_blocks(line, (num_indents + 1)) for line in lines])\n","takes a list or string and flattens it into a string with indentation ."] (predictor.py:56, main())
[2020-11-20 23:31:55]    INFO >> ["def trailing_whitespace(physical_line):\n\tphysical_line = physical_line.rstrip('\\n')\n\tphysical_line = physical_line.rstrip('\\r')\n\tphysical_line = physical_line.rstrip('\\x0c')\n\tstripped = physical_line.rstrip('\t DCTB \\x0b')\n\tif (physical_line != stripped):\n\t\tif stripped:\n\t\t\treturn (len(stripped), 'W291\ttrailing\twhitespace')\n\t\telse:\n\t\t\treturn (0, 'W293\tblank\tline\tcontains\twhitespace')\n","jcr: trailing whitespace is superfluous ."] (predictor.py:56, main())
[2020-11-20 23:31:56]    INFO >> ["def b64decode(s, altchars=None):\n\tif (altchars is not None):\n\t\ts = _translate(s, {altchars[0]: '+', altchars[1]: '\/'})\n\ttry:\n\t\treturn binascii.a2b_base64(s)\n\texcept binascii.Error as msg:\n\t\traise TypeError(msg)\n","decode a base64 encoded string ."] (predictor.py:56, main())
[2020-11-20 23:31:56]    INFO >> ["def libvlc_media_player_new(p_libvlc_instance):\n\tf = (_Cfunctions.get('libvlc_media_player_new', None) or _Cfunction('libvlc_media_player_new', ((1,),), class_result(MediaPlayer), ctypes.c_void_p, Instance))\n\treturn f(p_libvlc_instance)\n","create an empty media player object ."] (predictor.py:56, main())
[2020-11-20 23:31:56]    INFO >> ["def _get_hash(filename, block_size=(2 ** 20), hash=hashlib.md5):\n\tf = open(filename, 'rb')\n\thash_ = hash()\n\twhile True:\n\t\tdata = f.read(block_size)\n\t\tif (not data):\n\t\t\tbreak\n\t\thash_.update(data)\n\treturn hash_.hexdigest()\n","returns an md5 hash for a filename ."] (predictor.py:56, main())
[2020-11-20 23:31:57]    INFO >> ["def truncate_name(name, length=None, hash_len=4):\n\tif ((length is None) or (len(name) <= length)):\n\t\treturn name\n\thash = md5_constructor(name).hexdigest()[:hash_len]\n\treturn ('%s%s' % (name[:(length - hash_len)], hash))\n","shortens a string to a repeatable mangled version with the given length ."] (predictor.py:56, main())
[2020-11-20 23:31:57]    INFO >> ["def libvlc_video_get_spu_description(p_mi):\n\tf = (_Cfunctions.get('libvlc_video_get_spu_description', None) or _Cfunction('libvlc_video_get_spu_description', ((1,),), None, ctypes.POINTER(TrackDescription), MediaPlayer))\n\treturn f(p_mi)\n","get the description of available video subtitles ."] (predictor.py:56, main())
[2020-11-20 23:31:57]    INFO >> ["def new_figure_manager(num, *args, **kwargs):\n\t_focus = windowing.FocusManager()\n\tFigureClass = kwargs.pop('FigureClass', Figure)\n\tfigure = FigureClass(*args, **kwargs)\n\twindow = Tk.Tk()\n\tcanvas = FigureCanvasTkAgg(figure, master=window)\n\tfigManager = FigureManagerTkAgg(canvas, num, window)\n\tif matplotlib.is_interactive():\n\t\tfigManager.show()\n\treturn figManager\n","create a new figure manager instance ."] (predictor.py:56, main())
[2020-11-20 23:31:59]    INFO >> ["def test_cnn_fit_single_class():\n\tcnn = CondensedNearestNeighbour(random_state=RND_SEED)\n\ty_single_class = np.zeros((X.shape[0],))\n\tassert_warns(UserWarning, cnn.fit, X, y_single_class)\n","test either if an error when there is a single class ."] (predictor.py:56, main())
[2020-11-20 23:31:59]    INFO >> ["def enforce(context, action, target):\n\tinit()\n\tmatch_list = (('rule:%s' % action),)\n\tcredentials = context.to_dict()\n\tpolicy.enforce(match_list, target, credentials, exception.PolicyNotAuthorized, action=action)\n","verifies that the action is valid on the target in this context ."] (predictor.py:56, main())
[2020-11-20 23:32:00]    INFO >> ["def test_continuous_error():\n\ty = np.linspace(0, 1, 20)\n\tcnn = CondensedNearestNeighbour(random_state=RND_SEED)\n\tassert_warns(UserWarning, cnn.fit, X, y)\n","test either if an error is raised when the target are continuous type ."] (predictor.py:56, main())
[2020-11-20 23:32:00]    INFO >> ["def get_auth_from_url(url):\n\tparsed = urlparse(url)\n\ttry:\n\t\tauth = (unquote(parsed.username), unquote(parsed.password))\n\texcept (AttributeError, TypeError):\n\t\tauth = ('', '')\n\treturn auth\n","given a url with authentication components ."] (predictor.py:56, main())
[2020-11-20 23:32:00]    INFO >> ["def quota_get(context, project_id, resource, user_id=None):\n\treturn IMPL.quota_get(context, project_id, resource, user_id=user_id)\n","retrieve a quota or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:32:01]    INFO >> ["def quota_class_get_all_by_name(context, class_name):\n\treturn IMPL.quota_class_get_all_by_name(context, class_name)\n","retrieve all quotas associated with a given quota class ."] (predictor.py:56, main())
[2020-11-20 23:32:01]    INFO >> ["def import_stages():\n\tstages = []\n\tfor plugin in find_plugins():\n\t\tif hasattr(plugin, 'import_stages'):\n\t\t\tstages += plugin.import_stages\n\treturn stages\n","get a list of import stage functions defined by plugins ."] (predictor.py:56, main())
[2020-11-20 23:32:01]    INFO >> ["def recipr0(X):\n\ttest = np.equal(np.asarray(X), 0)\n\treturn np.where(test, 0, (1.0 \/ X))\n","return the reciprocal of an array ."] (predictor.py:56, main())
[2020-11-20 23:32:01]    INFO >> ["def warning(msg, *args, **kwargs):\n\tif (len(root.handlers) == 0):\n\t\tbasicConfig()\n\troot.warning(msg, *args, **kwargs)\n","log a message with severity warning on the root logger ."] (predictor.py:56, main())
[2020-11-20 23:32:02]    INFO >> ["def heapify(x):\n\tn = len(x)\n\tfor i in reversed(xrange((n \/\/ 2))):\n\t\t_siftup(x, i)\n","transform list into a heap ."] (predictor.py:56, main())
[2020-11-20 23:32:02]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:32:03]    INFO >> ["@loader_option()\ndef undefer(loadopt, key):\n\treturn loadopt.set_column_strategy((key,), {'deferred': False, 'instrument': True})\n","indicate that the given column-oriented attribute should be undeferred ."] (predictor.py:56, main())
[2020-11-20 23:32:05]    INFO >> ["def fnmatchcase(name, pat):\n\tmatch = _compile_pattern(pat)\n\treturn (match(name) is not None)\n","test whether filename matches pattern ."] (predictor.py:56, main())
[2020-11-20 23:32:05]    INFO >> ["def add_never_cache_headers(response):\n\tpatch_response_headers(response, cache_timeout=(-1))\n","adds headers to a response to indicate that a page should never be cached ."] (predictor.py:56, main())
[2020-11-20 23:32:05]    INFO >> ["def expose_api_raw(func):\n\treturn expose_api(func, to_json=False)\n","expose this function via the api but dont dump the results to json ."] (predictor.py:56, main())
[2020-11-20 23:32:06]    INFO >> ["def divisibleby(value, arg):\n\treturn ((int(value) % int(arg)) == 0)\n","returns true if the value is devisible by the argument ."] (predictor.py:56, main())
[2020-11-20 23:32:06]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:32:07]    INFO >> ["@register.filter('escapejs')\n@stringfilter\ndef escapejs_filter(value):\n\treturn escapejs(value)\n","hex encodes characters for use in javascript strings ."] (predictor.py:56, main())
[2020-11-20 23:32:07]    INFO >> ["def R(seqn):\n\tfor i in seqn:\n\t\t(yield i)\n","regular generator ."] (predictor.py:56, main())
[2020-11-20 23:32:09]    INFO >> ["def concatenate(tensor_list, axis=0):\n\tconcat_size = sum((tt.shape[axis] for tt in tensor_list))\n\toutput_shape = ()\n\tfor k in range(axis):\n\t\toutput_shape += (tensor_list[0].shape[k],)\n\toutput_shape += (concat_size,)\n\tfor k in range((axis + 1), tensor_list[0].ndim):\n\t\toutput_shape += (tensor_list[0].shape[k],)\n\tout = tensor.zeros(output_shape)\n\toffset = 0\n\tfor tt in tensor_list:\n\t\tindices = ()\n\t\tfor k in range(axis):\n\t\t\tindices += (slice(None),)\n\t\tindices += (slice(offset, (offset + tt.shape[axis])),)\n\t\tfor k in range((axis + 1), tensor_list[0].ndim):\n\t\t\tindices += (slice(None),)\n\t\tout = tensor.set_subtensor(out[indices], tt)\n\t\toffset += tt.shape[axis]\n\treturn out\n","alternative implementation of theano ."] (predictor.py:56, main())
[2020-11-20 23:32:09]    INFO >> ["def getPathByPrefix(path, prefix, xmlElement):\n\tif (len(path) < 2):\n\t\tprint 'Warning,\tbug,\tpath\tis\ttoo\tsmall\tin\tevaluate\tin\tsetPathByPrefix.'\n\t\treturn\n\tpathByKey = getPathByKey((prefix + 'path'), xmlElement)\n\tif (len(pathByKey) < len(path)):\n\t\tfor pointIndex in xrange(len(pathByKey)):\n\t\t\tpath[pointIndex] = pathByKey[pointIndex]\n\telse:\n\t\tpath = pathByKey\n\tpath[0] = getVector3ByPrefix(path[0], (prefix + 'pathStart'), xmlElement)\n\tpath[(-1)] = getVector3ByPrefix(path[(-1)], (prefix + 'pathEnd'), xmlElement)\n\treturn path\n","get path from prefix and xml element ."] (predictor.py:56, main())
[2020-11-20 23:32:10]    INFO >> ["def find_referenced_templates(ast):\n\tfor node in ast.find_all((nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include)):\n\t\tif (isinstance(node.template, nodes.Const) and isinstance(node.template.value, basestring)):\n\t\t\t(yield node.template.value)\n\t\telse:\n\t\t\t(yield None)\n","finds all the referenced templates from the ast ."] (predictor.py:56, main())
[2020-11-20 23:32:13]    INFO >> ["def test_enn_fit_sample():\n\tenn = EditedNearestNeighbours(random_state=RND_SEED)\n\t(X_resampled, y_resampled) = enn.fit_sample(X, Y)\n\tX_gt = np.array([[(-0.10903849), (-0.12085181)], [0.01936241, 0.17799828], [2.59928271, 0.93323465], [1.92365863, 0.82718767], [0.25738379, 0.95564169], [0.78318102, 2.59153329], [0.52726792, (-0.38735648)]])\n\ty_gt = np.array([0, 0, 1, 1, 2, 2, 2])\n\tassert_array_equal(X_resampled, X_gt)\n\tassert_array_equal(y_resampled, y_gt)\n","test the fit sample routine ."] (predictor.py:56, main())
[2020-11-20 23:32:13]    INFO >> ["def patch_response_headers(response, cache_timeout=None):\n\tif (cache_timeout is None):\n\t\tcache_timeout = settings.CACHE_MIDDLEWARE_SECONDS\n\tnow = datetime.datetime.utcnow()\n\tif (not response.has_header('ETag')):\n\t\tresponse['ETag'] = md5.new(response.content).hexdigest()\n\tif (not response.has_header('Last-Modified')):\n\t\tresponse['Last-Modified'] = now.strftime('%a,\t%d\t%b\t%Y\t%H:%M:%S\tGMT')\n\tif (not response.has_header('Expires')):\n\t\texpires = (now + datetime.timedelta(0, cache_timeout))\n\t\tresponse['Expires'] = expires.strftime('%a,\t%d\t%b\t%Y\t%H:%M:%S\tGMT')\n\tif (cache_timeout < 0):\n\t\tcache_timeout = 0\n\tpatch_cache_control(response, max_age=cache_timeout)\n","adds some useful headers to the given httpresponse object: etag ."] (predictor.py:56, main())
[2020-11-20 23:32:13]    INFO >> ["def prune_dirs(path, root=None, clutter=('.DS_Store', 'Thumbs.db')):\n\tpath = normpath(path)\n\tif (root is not None):\n\t\troot = normpath(root)\n\tancestors = ancestry(path)\n\tif (root is None):\n\t\tancestors = []\n\telif (root in ancestors):\n\t\tancestors = ancestors[(ancestors.index(root) + 1):]\n\telse:\n\t\treturn\n\tancestors.append(path)\n\tancestors.reverse()\n\tfor directory in ancestors:\n\t\tdirectory = syspath(directory)\n\t\tif (not os.path.exists(directory)):\n\t\t\tcontinue\n\t\tclutter = [bytestring_path(c) for c in clutter]\n\t\tmatch_paths = [bytestring_path(d) for d in os.listdir(directory)]\n\t\tif fnmatch_all(match_paths, clutter):\n\t\t\ttry:\n\t\t\t\tshutil.rmtree(directory)\n\t\t\texcept OSError:\n\t\t\t\tbreak\n\t\telse:\n\t\t\tbreak\n","if path is an empty directory ."] (predictor.py:56, main())
[2020-11-20 23:32:15]    INFO >> ["def check_valid_naming(pattern=None, multi=None, anime_type=None):\n\tif (pattern is None):\n\t\tpattern = sickbeard.NAMING_PATTERN\n\tif (anime_type is None):\n\t\tanime_type = sickbeard.NAMING_ANIME\n\tlogger.log(((u'Checking\twhether\tthe\tpattern\t' + pattern) + u'\tis\tvalid\tfor\ta\tsingle\tepisode'), logger.DEBUG)\n\tvalid = validate_name(pattern, None, anime_type)\n\tif (multi is not None):\n\t\tlogger.log(((u'Checking\twhether\tthe\tpattern\t' + pattern) + u'\tis\tvalid\tfor\ta\tmulti\tepisode'), logger.DEBUG)\n\t\tvalid = (valid and validate_name(pattern, multi, anime_type))\n\treturn valid\n","checks if the name is can be parsed back to its original form for both single and multi episodes ."] (predictor.py:56, main())
[2020-11-20 23:32:17]    INFO >> ["def extract_params(raw):\n\tif (isinstance(raw, bytes_type) or isinstance(raw, unicode_type)):\n\t\ttry:\n\t\t\tparams = urldecode(raw)\n\t\texcept ValueError:\n\t\t\tparams = None\n\telif hasattr(raw, u'__iter__'):\n\t\ttry:\n\t\t\tdict(raw)\n\t\texcept ValueError:\n\t\t\tparams = None\n\t\texcept TypeError:\n\t\t\tparams = None\n\t\telse:\n\t\t\tparams = list((raw.items() if isinstance(raw, dict) else raw))\n\t\t\tparams = decode_params_utf8(params)\n\telse:\n\t\tparams = None\n\treturn params\n","extract parameters and return them as a list of 2-tuples ."] (predictor.py:56, main())
[2020-11-20 23:32:17]    INFO >> ["@task(help={'args': 'Command\tline\targs\tfor\tbehave', 'format': 'Formatter\tto\tuse'})\ndef behave_test(ctx, args='', format=''):\n\tformat = (format or ctx.behave_test.format)\n\toptions = (ctx.behave_test.options or '')\n\targs = (args or ctx.behave_test.args)\n\tbehave = '{python}\tbin\/behave'.format(python=sys.executable)\n\tctx.run('{behave}\t-f\t{format}\t{options}\t{args}'.format(behave=behave, format=format, options=options, args=args), pty=USE_PTY)\n","run behave tests ."] (predictor.py:56, main())
[2020-11-20 23:32:18]    INFO >> ["def getLoopLayers(archivableObjects, importRadius, layerHeight, maximumZ, shouldPrintWarning, z, zoneArrangement):\n\tloopLayers = []\n\twhile (z <= maximumZ):\n\t\ttriangle_mesh.getLoopLayerAppend(loopLayers, z).loops = getEmptyZLoops(archivableObjects, importRadius, True, z, zoneArrangement)\n\t\tz += layerHeight\n\treturn loopLayers\n","get loop layers ."] (predictor.py:56, main())
[2020-11-20 23:32:19]    INFO >> ["def start_remote_debugger(rpcclt, pyshell):\n\tglobal idb_adap_oid\n\tidb_adap_oid = rpcclt.remotecall('exec', 'start_the_debugger', (gui_adap_oid,), {})\n\tidb_proxy = IdbProxy(rpcclt, pyshell, idb_adap_oid)\n\tgui = debugger.Debugger(pyshell, idb_proxy)\n\tgui_adap = GUIAdapter(rpcclt, gui)\n\trpcclt.register(gui_adap_oid, gui_adap)\n\treturn gui\n","start the subprocess debugger ."] (predictor.py:56, main())
[2020-11-20 23:32:19]    INFO >> ["def getOutput(gcodeText, binary16ByteRepository=None):\n\tif (gcodeText == ''):\n\t\treturn ''\n\tif (binary16ByteRepository == None):\n\t\tbinary16ByteRepository = Binary16ByteRepository()\n\t\tsettings.getReadRepository(binary16ByteRepository)\n\treturn Binary16ByteSkein().getCraftedGcode(gcodeText, binary16ByteRepository)\n","get the exported version of a gcode file ."] (predictor.py:56, main())
[2020-11-20 23:32:21]    INFO >> ["def versions_from_parentdir(parentdir_prefix, root, verbose):\n\tdirname = os.path.basename(root)\n\tif (not dirname.startswith(parentdir_prefix)):\n\t\tif verbose:\n\t\t\tprint((\"guessing\trootdir\tis\t'%s',\tbut\t'%s'\tdoesn't\tstart\twith\tprefix\t'%s'\" % (root, dirname, parentdir_prefix)))\n\t\traise NotThisMethod(\"rootdir\tdoesn't\tstart\twith\tparentdir_prefix\")\n\treturn {'version': dirname[len(parentdir_prefix):], 'full-revisionid': None, 'dirty': False, 'error': None}\n","try to determine the version from the parent directory name ."] (predictor.py:56, main())
[2020-11-20 23:32:22]    INFO >> ["def _parse_version(text):\n\t(major, major2, minor) = VERSION_RE.search(text).groups()\n\ttry:\n\t\treturn (int(major), int(major2), int(minor))\n\texcept (ValueError, TypeError):\n\t\treturn (int(major), int(major2), None)\n","internal parsing method ."] (predictor.py:56, main())
[2020-11-20 23:32:22]    INFO >> ["def _py_convert_agg_to_wx_image(agg, bbox):\n\timage = wx.EmptyImage(int(agg.width), int(agg.height))\n\timage.SetData(agg.tostring_rgb())\n\tif (bbox is None):\n\t\treturn image\n\telse:\n\t\treturn wx.ImageFromBitmap(_clipped_image_as_bitmap(image, bbox))\n","convert the region of the agg buffer bounded by bbox to a wx ."] (predictor.py:56, main())
[2020-11-20 23:32:23]    INFO >> ["def has_purchased(f):\n\t@functools.wraps(f)\n\tdef wrapper(request, addon, *args, **kw):\n\t\tif (addon.is_premium() and (not addon.has_purchased(request.user))):\n\t\t\tlog.info(('Not\tpurchased:\t%d' % addon.pk))\n\t\t\traise PermissionDenied\n\t\treturn f(request, addon, *args, **kw)\n\treturn wrapper\n","if the addon is premium ."] (predictor.py:56, main())
[2020-11-20 23:32:23]    INFO >> ["def set_clean(using=None):\n\tget_connection(using).set_clean()\n","resets a dirty flag for the current thread and code streak ."] (predictor.py:56, main())
[2020-11-20 23:32:23]    INFO >> ["def get_all_qoss(tenant_id):\n\tLOG.debug(_('get_all_qoss()\tcalled'))\n\tsession = db.get_session()\n\ttry:\n\t\tqoss = session.query(l2network_models.QoS).filter_by(tenant_id=tenant_id).all()\n\t\treturn qoss\n\texcept exc.NoResultFound:\n\t\treturn []\n","lists all the qos to tenant associations ."] (predictor.py:56, main())
[2020-11-20 23:32:24]    INFO >> ["def test_ioerror_if_replay_dir_creation_fails(mock_ensure_failure, replay_test_dir):\n\twith pytest.raises(IOError):\n\t\treplay.dump(replay_test_dir, 'foo', {'cookiecutter': {'hello': 'world'}})\n\tmock_ensure_failure.assert_called_once_with(replay_test_dir)\n","test that replay ."] (predictor.py:56, main())
[2020-11-20 23:32:24]    INFO >> ["def getOutput(gcodeText, binary16ByteRepository=None):\n\tif (gcodeText == ''):\n\t\treturn ''\n\tif (binary16ByteRepository == None):\n\t\tbinary16ByteRepository = Binary16ByteRepository()\n\t\tsettings.getReadRepository(binary16ByteRepository)\n\treturn Binary16ByteSkein().getCraftedGcode(gcodeText, binary16ByteRepository)\n","get the exported version of a gcode file ."] (predictor.py:56, main())
[2020-11-20 23:32:25]    INFO >> ["def splittype(url):\n\tglobal _typeprog\n\tif (_typeprog is None):\n\t\t_typeprog = re.compile('([^\/:]+):(.*)', re.DOTALL)\n\tmatch = _typeprog.match(url)\n\tif match:\n\t\t(scheme, data) = match.groups()\n\t\treturn (scheme.lower(), data)\n\treturn (None, url)\n","splittype --> type ."] (predictor.py:56, main())
[2020-11-20 23:32:25]    INFO >> ["def getAroundsFromPath(path, radius, thresholdRatio=0.9):\n\treturn getAroundsFromPoints(getPointsFromPath(path, (1.01 * abs(radius)), thresholdRatio), radius)\n","get the arounds from the path ."] (predictor.py:56, main())
[2020-11-20 23:32:25]    INFO >> ["def unnotify(thing, possible_recipients=None):\n\tfrom r2.lib import butler\n\terror_message = ('Unable\tto\tunnotify\tthing\tof\ttype:\t%r' % thing)\n\tnotification_handler(thing, notify_function=butler.remove_mention_notification, error_message=error_message, possible_recipients=possible_recipients)\n","given a thing ."] (predictor.py:56, main())
[2020-11-20 23:32:26]    INFO >> ["def next_char(input_iter):\n\tfor ch in input_iter:\n\t\tif (ch != u'\\\\'):\n\t\t\t(yield (ch, False))\n\t\t\tcontinue\n\t\tch = next(input_iter)\n\t\trepresentative = ESCAPE_MAPPINGS.get(ch, ch)\n\t\tif (representative is None):\n\t\t\tcontinue\n\t\t(yield (representative, True))\n","an iterator that yields the next character from \"pattern_iter\" ."] (predictor.py:56, main())
[2020-11-20 23:32:27]    INFO >> ["def user_follower_list(context, data_dict):\n\t_check_access('user_follower_list', context, data_dict)\n\treturn _follower_list(context, data_dict, ckan.logic.schema.default_follow_user_schema(), context['model'].UserFollowingUser)\n","return the list of users that are following the given user ."] (predictor.py:56, main())
[2020-11-20 23:32:27]    INFO >> ["def sslwrap_simple(sock, keyfile=None, certfile=None):\n\tif hasattr(sock, '_sock'):\n\t\tsock = sock._sock\n\tssl_sock = _ssl.sslwrap(sock, 0, keyfile, certfile, CERT_NONE, PROTOCOL_SSLv23, None)\n\ttry:\n\t\tsock.getpeername()\n\texcept:\n\t\tpass\n\telse:\n\t\tssl_sock.do_handshake()\n\treturn ssl_sock\n","a replacement for the old socket ."] (predictor.py:56, main())
[2020-11-20 23:32:28]    INFO >> ["def _reraise_translated_image_exception(image_id):\n\t(_exc_type, exc_value, exc_trace) = sys.exc_info()\n\tnew_exc = _translate_image_exception(image_id, exc_value)\n\tsix.reraise(type(new_exc), new_exc, exc_trace)\n","transform the exception for the image but keep its traceback intact ."] (predictor.py:56, main())
[2020-11-20 23:32:28]    INFO >> ["def _totuple(x):\n\tif isinstance(x, basestring):\n\t\tout = (x,)\n\telif isinstance(x, (int, float)):\n\t\tout = (str(x),)\n\telif (x is None):\n\t\tout = (None,)\n\telse:\n\t\tout = tuple(x)\n\treturn out\n","utility stuff to convert string ."] (predictor.py:56, main())
[2020-11-20 23:32:29]    INFO >> ["def _rshift_nearest(x, shift):\n\t(b, q) = ((1L << shift), (x >> shift))\n\treturn (q + (((2 * (x & (b - 1))) + (q & 1)) > b))\n","given an integer x and a nonnegative integer shift ."] (predictor.py:56, main())
[2020-11-20 23:32:29]    INFO >> ["def convert_DateTimeProperty(model, prop, kwargs):\n\tif (prop.auto_now or prop.auto_now_add):\n\t\treturn None\n\tkwargs.setdefault('format', '%Y-%m-%d\t%H:%M:%S')\n\treturn f.DateTimeField(**kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:32:30]    INFO >> ["def connect_to_region(region_name, **kw_params):\n\tfor region in regions():\n\t\tif (region.name == region_name):\n\t\t\treturn region.connect(**kw_params)\n\treturn None\n","given a valid region name ."] (predictor.py:56, main())
[2020-11-20 23:32:31]    INFO >> ["def _popen(cmd):\n\tp = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE, close_fds=(os.name != 'nt'), universal_newlines=True)\n\treturn p.communicate()\n","friendly wrapper around popen for windows ."] (predictor.py:56, main())
[2020-11-20 23:32:32]    INFO >> ["def hash_user_password(user):\n\tpassword = user.get('password')\n\tif (password is None):\n\t\treturn user\n\treturn dict(user, password=hash_password(password))\n","hash a user dicts password without modifying the passed-in dict ."] (predictor.py:56, main())
[2020-11-20 23:32:32]    INFO >> ["def block_device_mapping_update(context, bdm_id, values, legacy=True):\n\treturn IMPL.block_device_mapping_update(context, bdm_id, values, legacy)\n","update an entry of block device mapping ."] (predictor.py:56, main())
[2020-11-20 23:32:32]    INFO >> ["def processElementNode(elementNode):\n\tpath.convertElementNode(elementNode, getGeometryOutput(None, elementNode))\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:32:33]    INFO >> ["def localize(value):\n\treturn force_unicode(formats.localize(value, use_l10n=True))\n","forces a value to be rendered as a localized value ."] (predictor.py:56, main())
[2020-11-20 23:32:33]    INFO >> ["def _hmacedString(key, string):\n\thash = hmac.HMAC(key, digestmod=sha1)\n\tif isinstance(string, unicode):\n\t\tstring = string.encode('utf-8')\n\thash.update(string)\n\treturn hash.digest()\n","return the sha-1 hmac hash of the given key and string ."] (predictor.py:56, main())
[2020-11-20 23:32:33]    INFO >> ["def validate_int(s):\n\ttry:\n\t\treturn int(s)\n\texcept ValueError:\n\t\traise ValueError(('Could\tnot\tconvert\t\"%s\"\tto\tint' % s))\n","convert s to int or raise ."] (predictor.py:56, main())
[2020-11-20 23:32:34]    INFO >> ["def convert_StringListProperty(model, prop, kwargs):\n\treturn StringListPropertyField(**kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:32:34]    INFO >> ["def _api_resume_pp(name, output, kwargs):\n\tPostProcessor.do.paused = False\n\treturn report(output)\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:32:35]    INFO >> ["def get_current_instance_id():\n\treturn os.environ.get('INSTANCE_ID', None)\n","returns the id of the current instance ."] (predictor.py:56, main())
[2020-11-20 23:32:35]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:32:35]    INFO >> ["def iteritems(d):\n\treturn getattr(d, _iteritems)()\n","return an iterator over the pairs of a dictionary ."] (predictor.py:56, main())
[2020-11-20 23:32:36]    INFO >> ["def isIntersectingLoopsPaths(loops, paths, pointBegin, pointEnd):\n\tnormalizedSegment = (pointEnd.dropAxis() - pointBegin.dropAxis())\n\tnormalizedSegmentLength = abs(normalizedSegment)\n\tif (normalizedSegmentLength == 0.0):\n\t\treturn False\n\tnormalizedSegment \/= normalizedSegmentLength\n\tsegmentYMirror = complex(normalizedSegment.real, (- normalizedSegment.imag))\n\tpointBeginRotated = euclidean.getRoundZAxisByPlaneAngle(segmentYMirror, pointBegin)\n\tpointEndRotated = euclidean.getRoundZAxisByPlaneAngle(segmentYMirror, pointEnd)\n\tif euclidean.isLoopListIntersectingInsideXSegment(loops, pointBeginRotated.real, pointEndRotated.real, segmentYMirror, pointBeginRotated.imag):\n\t\treturn True\n\treturn euclidean.isXSegmentIntersectingPaths(paths, pointBeginRotated.real, pointEndRotated.real, segmentYMirror, pointBeginRotated.imag)\n","determine if the segment between the first and second point is intersecting the loop list ."] (predictor.py:56, main())
[2020-11-20 23:32:38]    INFO >> ["def getRadioPluginsAddPluginGroupFrame(directoryPath, importantFileNames, names, repository):\n\trepository.pluginGroupFrame = settings.PluginGroupFrame()\n\tradioPlugins = []\n\tfor name in names:\n\t\tradioPlugin = settings.RadioPlugin().getFromRadio((name in importantFileNames), repository.pluginGroupFrame.latentStringVar, name, repository, (name == importantFileNames[0]))\n\t\tradioPlugin.updateFunction = repository.pluginGroupFrame.update\n\t\tradioPlugins.append(radioPlugin)\n\tdefaultRadioButton = settings.getSelectedRadioPlugin((importantFileNames + [radioPlugins[0].name]), radioPlugins)\n\trepository.pluginGroupFrame.getFromPath(defaultRadioButton, directoryPath, repository)\n\treturn radioPlugins\n","get the radio plugins and add the plugin frame ."] (predictor.py:56, main())
[2020-11-20 23:32:39]    INFO >> ["def get_exploration_metadata_dicts(exploration_ids, editor_user_id=None):\n\texploration_summaries = exp_services.get_exploration_summaries_matching_ids(exploration_ids)\n\tfiltered_exploration_summaries = []\n\tfor exploration_summary in exploration_summaries:\n\t\tif (exploration_summary is None):\n\t\t\tcontinue\n\t\tif (exploration_summary.status == rights_manager.ACTIVITY_STATUS_PRIVATE):\n\t\t\tif (editor_user_id is None):\n\t\t\t\tcontinue\n\t\t\tif (not rights_manager.Actor(editor_user_id).can_edit(feconf.ACTIVITY_TYPE_EXPLORATION, exploration_summary.id)):\n\t\t\t\tcontinue\n\t\tfiltered_exploration_summaries.append(exploration_summary)\n\treturn [summary.to_metadata_dict() for summary in filtered_exploration_summaries]\n","given a list of exploration ids ."] (predictor.py:56, main())
[2020-11-20 23:32:39]    INFO >> ["def get_declared_fields(bases, attrs, with_base_fields=True):\n\tfields = [(field_name, attrs.pop(field_name)) for (field_name, obj) in list(six.iteritems(attrs)) if isinstance(obj, Field)]\n\tfields.sort(key=(lambda x: x[1].creation_counter))\n\tif with_base_fields:\n\t\tfor base in bases[::(-1)]:\n\t\t\tif hasattr(base, u'base_fields'):\n\t\t\t\tfields = (list(six.iteritems(base.base_fields)) + fields)\n\telse:\n\t\tfor base in bases[::(-1)]:\n\t\t\tif hasattr(base, u'declared_fields'):\n\t\t\t\tfields = (list(six.iteritems(base.declared_fields)) + fields)\n\treturn SortedDict(fields)\n","create a list of form field instances from the passed in attrs ."] (predictor.py:56, main())
[2020-11-20 23:32:40]    INFO >> ["def _run_quiet(cmd, cwd=None, stdin=None, runas=None, shell=DEFAULT_SHELL, python_shell=False, env=None, template=None, umask=None, timeout=None, reset_system_locale=True, saltenv='base', pillarenv=None, pillar_override=None):\n\treturn _run(cmd, runas=runas, cwd=cwd, stdin=stdin, stderr=subprocess.STDOUT, output_loglevel='quiet', log_callback=None, shell=shell, python_shell=python_shell, env=env, template=template, umask=umask, timeout=timeout, reset_system_locale=reset_system_locale, saltenv=saltenv, pillarenv=pillarenv, pillar_override=pillar_override)['stdout']\n","helper for running commands quietly for minion startup ."] (predictor.py:56, main())
[2020-11-20 23:32:40]    INFO >> ["def in6_ctop(addr):\n\tif ((len(addr) != 20) or (not reduce((lambda x, y: (x and y)), map((lambda x: (x in _rfc1924map)), addr)))):\n\t\treturn None\n\ti = 0\n\tfor c in addr:\n\t\tj = _rfc1924map.index(c)\n\t\ti = ((85 * i) + j)\n\tres = []\n\tfor j in xrange(4):\n\t\tres.append(struct.pack('!I', (i % (2 ** 32))))\n\t\ti = (i \/ (2 ** 32))\n\tres.reverse()\n\treturn inet_ntop(socket.AF_INET6, ''.join(res))\n","convert an ipv6 address in compact representation notation to printable representation ;-) returns none on error ."] (predictor.py:56, main())
[2020-11-20 23:32:41]    INFO >> ["def preserve_value(namespace, name):\n\tdef decorator(func):\n\t\tdef resetter_attr(saved_value_internal):\n\t\t\treturn setattr(namespace, name, saved_value_internal)\n\t\tdef resetter_no_attr(saved_value_internal):\n\t\t\tdel saved_value_internal\n\t\t\treturn delattr(namespace, name)\n\t\tdef wrapper(*args, **kwargs):\n\t\t\tsaved_value = None\n\t\t\ttry:\n\t\t\t\tsaved_value = getattr(namespace, name)\n\t\t\t\tresetter = resetter_attr\n\t\t\texcept AttributeError:\n\t\t\t\tresetter = resetter_no_attr\n\t\t\ttry:\n\t\t\t\treturn func(*args, **kwargs)\n\t\t\tfinally:\n\t\t\t\tresetter(saved_value)\n\t\twrapper.__name__ = func.__name__\n\t\twrapper.__doc__ = func.__doc__\n\t\treturn wrapper\n\treturn decorator\n","function decorator to wrap a function that sets a namespace item ."] (predictor.py:56, main())
[2020-11-20 23:32:41]    INFO >> ["def _setlabel(object_alias, index):\n\tfinder = _getfinder()\n\targs = {}\n\tattrs = {}\n\t_code = 'core'\n\t_subcode = 'setd'\n\taeobj_0 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='alis', seld=object_alias, fr=None)\n\taeobj_1 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('labi'), fr=aeobj_0)\n\targs['----'] = aeobj_1\n\targs['data'] = index\n\t(_reply, args, attrs) = finder.send(_code, _subcode, args, attrs)\n\tif ('errn' in args):\n\t\traise Error, aetools.decodeerror(args)\n\treturn index\n","label: set the label for the object ."] (predictor.py:56, main())
[2020-11-20 23:32:42]    INFO >> ["def _run_file(file_path, globals_, script_dir=_SCRIPT_DIR):\n\tscript_name = os.path.basename(file_path)\n\tsys.path = (_SYS_PATH_ADDITIONS[script_name] + sys.path)\n\tif ('google' in sys.modules):\n\t\tdel sys.modules['google']\n\tscript_dir = _SCRIPT_TO_DIR.get(script_name, script_dir)\n\tscript_name = _BOOTSTAP_NAME_TO_REAL_NAME.get(script_name, script_name)\n\tscript_path = os.path.join(script_dir, script_name)\n\texecfile(script_path, globals_)\n\texit(0)\n","execute the file at the specified path with the passed-in globals ."] (predictor.py:56, main())
[2020-11-20 23:32:44]    INFO >> ["@checker('.rst', severity=2)\ndef check_suspicious_constructs(fn, lines):\n\tinprod = False\n\tfor (lno, line) in enumerate(lines):\n\t\tif seems_directive_re.match(line):\n\t\t\t(yield ((lno + 1), 'comment\tseems\tto\tbe\tintended\tas\ta\tdirective'))\n\t\tif ('..\tproductionlist::' in line):\n\t\t\tinprod = True\n\t\telif ((not inprod) and default_role_re.search(line)):\n\t\t\t(yield ((lno + 1), 'default\trole\tused'))\n\t\telif (inprod and (not line.strip())):\n\t\t\tinprod = False\n","check for suspicious rest constructs ."] (predictor.py:56, main())
[2020-11-20 23:32:44]    INFO >> ["def clientFromString(reactor, description):\n\t(args, kwargs) = _parse(description)\n\taname = args.pop(0)\n\tname = aname.upper()\n\tif (name not in _clientParsers):\n\t\tplugin = _matchPluginToPrefix(getPlugins(IStreamClientEndpointStringParserWithReactor), name)\n\t\treturn plugin.parseStreamClient(reactor, *args, **kwargs)\n\tkwargs = _clientParsers[name](*args, **kwargs)\n\treturn _endpointClientFactories[name](reactor, **kwargs)\n","construct a client endpoint from a description string ."] (predictor.py:56, main())
[2020-11-20 23:32:45]    INFO >> ["def aliased(element, alias=None, name=None, flat=False, adapt_on_names=False):\n\tif isinstance(element, expression.FromClause):\n\t\tif adapt_on_names:\n\t\t\traise sa_exc.ArgumentError('adapt_on_names\tonly\tapplies\tto\tORM\telements')\n\t\treturn element.alias(name, flat=flat)\n\telse:\n\t\treturn AliasedClass(element, alias=alias, flat=flat, name=name, adapt_on_names=adapt_on_names)\n","produce an alias of the given element ."] (predictor.py:56, main())
[2020-11-20 23:32:45]    INFO >> ["def getnode():\n\tglobal _node\n\tif (_node is not None):\n\t\treturn _node\n\timport sys\n\tif (sys.platform == 'win32'):\n\t\tgetters = [_windll_getnode, _netbios_getnode, _ipconfig_getnode]\n\telse:\n\t\tgetters = [_unixdll_getnode, _ifconfig_getnode]\n\tfor getter in (getters + [_random_getnode]):\n\t\ttry:\n\t\t\t_node = getter()\n\t\texcept:\n\t\t\tcontinue\n\t\tif (_node is not None):\n\t\t\treturn _node\n","get the hardware address as a 48-bit positive integer ."] (predictor.py:56, main())
[2020-11-20 23:32:46]    INFO >> ["def detachRequest(GmmCause_presence=0):\n\ta = TpPd(pd=3)\n\tb = MessageType(mesType=5)\n\tc = DetachTypeAndForceToStandby()\n\tpacket = ((a \/ b) \/ c)\n\tif (GmmCause_presence is 1):\n\t\te = GmmCause(ieiGC=37)\n\t\tpacket = (packet \/ e)\n\treturn packet\n","detach request section 9 ."] (predictor.py:56, main())
[2020-11-20 23:32:46]    INFO >> ["def iterateInReactor(i):\n\tfrom twisted.internet import reactor\n\td = defer.Deferred()\n\tdef go(last):\n\t\ttry:\n\t\t\tr = next(i)\n\t\texcept StopIteration:\n\t\t\td.callback(last)\n\t\texcept:\n\t\t\td.errback()\n\t\telse:\n\t\t\tif isinstance(r, defer.Deferred):\n\t\t\t\tr.addCallback(go)\n\t\t\telse:\n\t\t\t\treactor.callLater(0, go, r)\n\tgo(None)\n\treturn d\n","consume an interator at most a single iteration per reactor iteration ."] (predictor.py:56, main())
[2020-11-20 23:32:47]    INFO >> ["def _getopt_flags(options):\n\ts = []\n\tl = []\n\tfor o in options:\n\t\tif (o.prefix == '-'):\n\t\t\ts.append(o.name)\n\t\t\tif o.takes_argument:\n\t\t\t\ts.append(':')\n\t\telif o.takes_argument:\n\t\t\tl.append((o.name + '='))\n\t\telse:\n\t\t\tl.append(o.name)\n\treturn (''.join(s), l)\n","convert the option list to a getopt flag string and long opt list ."] (predictor.py:56, main())
[2020-11-20 23:32:47]    INFO >> ["def test_make_imbalance_4():\n\t(X_, y_) = make_imbalance(X, Y, ratio=0.01, min_c_=1)\n\tcounter = Counter(y_)\n\tassert_equal(counter[0], 500)\n\tassert_equal(counter[1], 5)\n\tassert_true(np.all([(X_i in X) for X_i in X_]))\n","test make_imbalance ."] (predictor.py:56, main())
[2020-11-20 23:32:48]    INFO >> ["def _getAccessibleAttribute(attributeName, elementNode):\n\tif (attributeName in globalGetAccessibleAttributeSet):\n\t\treturn getattr(Document(elementNode), attributeName, None)\n\treturn None\n","get the accessible attribute ."] (predictor.py:56, main())
[2020-11-20 23:32:48]    INFO >> ["def inputhook_wx1(context):\n\ttry:\n\t\tapp = wx.GetApp()\n\t\tif (app is not None):\n\t\t\tassert wx.Thread_IsMain()\n\t\t\tevtloop = wx.EventLoop()\n\t\t\tea = wx.EventLoopActivator(evtloop)\n\t\t\twhile evtloop.Pending():\n\t\t\t\tevtloop.Dispatch()\n\t\t\tapp.ProcessIdle()\n\t\t\tdel ea\n\texcept KeyboardInterrupt:\n\t\tpass\n\treturn 0\n","run the wx event loop by processing pending events only ."] (predictor.py:56, main())
[2020-11-20 23:32:50]    INFO >> ["def fetch_stream_from_url(url, config, data=None, handlers=None):\n\t(return_code, return_message, response) = open_url(url, config, data=data, handlers=handlers)\n\tif (return_code and (return_code == httplib.OK)):\n\t\treturn response\n\telse:\n\t\traise URLFetchError(return_message)\n","returns data retrieved from a url ."] (predictor.py:56, main())
[2020-11-20 23:32:50]    INFO >> ["def delete_comment(request, comment_id):\n\t(cc_comment, context) = _get_comment_and_context(request, comment_id)\n\tif can_delete(cc_comment, context):\n\t\tcc_comment.delete()\n\t\tcomment_deleted.send(sender=None, user=request.user, post=cc_comment)\n\telse:\n\t\traise PermissionDenied\n","delete a comment ."] (predictor.py:56, main())
[2020-11-20 23:32:51]    INFO >> ["def test_sample_wrong_X():\n\tada = ADASYN(random_state=RND_SEED)\n\tada.fit(X, Y)\n\tassert_raises(RuntimeError, ada.sample, np.random.random((100, 40)), np.array((([0] * 50) + ([1] * 50))))\n","test either if an error is raised when x is different at fitting and sampling ."] (predictor.py:56, main())
[2020-11-20 23:32:51]    INFO >> ["def word_count(documents):\n\tcollector = defaultdict(list)\n\tfor document in documents:\n\t\tfor (word, count) in wc_mapper(document):\n\t\t\tcollector[word].append(count)\n\treturn [output for (word, counts) in collector.items() for output in wc_reducer(word, counts)]\n","count the words in the input documents using mapreduce ."] (predictor.py:56, main())
[2020-11-20 23:32:51]    INFO >> ["def authenticationRequest():\n\ta = TpPd(pd=5)\n\tb = MessageType(mesType=18)\n\tc = CiphKeySeqNrAndSpareHalfOctets()\n\td = AuthenticationParameterRAND()\n\tpacket = (((a \/ b) \/ c) \/ d)\n\treturn packet\n","authentication request section 9 ."] (predictor.py:56, main())
[2020-11-20 23:32:52]    INFO >> ["def get_stylesheet_reference(settings, relative_to=None):\n\tif settings.stylesheet_path:\n\t\tassert (not settings.stylesheet), 'stylesheet\tand\tstylesheet_path\tare\tmutually\texclusive.'\n\t\tif (relative_to == None):\n\t\t\trelative_to = settings._destination\n\t\treturn relative_path(relative_to, settings.stylesheet_path)\n\telse:\n\t\treturn settings.stylesheet\n","retrieve a stylesheet reference from the settings object ."] (predictor.py:56, main())
[2020-11-20 23:32:52]    INFO >> ["def security_group_rule_get_by_security_group(context, security_group_id):\n\treturn IMPL.security_group_rule_get_by_security_group(context, security_group_id)\n","get all rules for a given security group ."] (predictor.py:56, main())
[2020-11-20 23:32:53]    INFO >> ["def getWinDrives():\n\tassert (os.name == u'nt')\n\tfrom ctypes import windll\n\tdrives = []\n\tbitmask = windll.kernel32.GetLogicalDrives()\n\tfor letter in string.uppercase:\n\t\tif (bitmask & 1):\n\t\t\tdrives.append(letter)\n\t\tbitmask >>= 1\n\treturn drives\n","return list of detected drives ."] (predictor.py:56, main())
[2020-11-20 23:32:53]    INFO >> ["def filter_oauth_params(params):\n\tis_oauth = (lambda kv: kv[0].startswith(u'oauth_'))\n\tif isinstance(params, dict):\n\t\treturn filter(is_oauth, params.items())\n\telse:\n\t\treturn filter(is_oauth, params)\n","removes all non oauth parameters from a dict or a list of params ."] (predictor.py:56, main())
[2020-11-20 23:32:56]    INFO >> ["def test_continuous_error():\n\ty = np.linspace(0, 1, 20)\n\tcnn = CondensedNearestNeighbour(random_state=RND_SEED)\n\tassert_warns(UserWarning, cnn.fit, X, y)\n","test either if an error is raised when the target are continuous type ."] (predictor.py:56, main())
[2020-11-20 23:32:57]    INFO >> ["def set_data_value(datastore, path, data):\n\tif isinstance(path, six.string_types):\n\t\tpath = '\/'.split(path)\n\treturn _proxy_cmd('set_data_value', datastore, path, data)\n","get a data entry in a datastore ."] (predictor.py:56, main())
[2020-11-20 23:32:57]    INFO >> ["def re_subm(pat, repl, string):\n\tr = re_compile(pat)\n\tproxy = _re_subm_proxy()\n\tr.sub(proxy.__call__, string)\n\treturn (r.sub(repl, string), proxy.match)\n","like re ."] (predictor.py:56, main())
[2020-11-20 23:32:57]    INFO >> ["def commit_manually(using=None):\n\twarnings.warn('commit_manually\tis\tdeprecated\tin\tfavor\tof\tset_autocommit.', PendingDeprecationWarning, stacklevel=2)\n\tdef entering(using):\n\t\tenter_transaction_management(using=using)\n\tdef exiting(exc_type, using):\n\t\tleave_transaction_management(using=using)\n\treturn _transaction_func(entering, exiting, using)\n","decorator that activates manual transaction control ."] (predictor.py:56, main())
[2020-11-20 23:32:58]    INFO >> ["def load_module_from_name(dotted_name, path=None, use_sys=1):\n\treturn load_module_from_modpath(dotted_name.split('.'), path, use_sys)\n","load a python module from its name ."] (predictor.py:56, main())
[2020-11-20 23:32:58]    INFO >> ["def _generateX(random, bits):\n\twhile True:\n\t\tx = _getRandomNumber(random, bits)\n\t\tif (2 <= x <= ((2 ** bits) - 2)):\n\t\t\treturn x\n","generate a new value for the private key x ."] (predictor.py:56, main())
[2020-11-20 23:32:58]    INFO >> ["def test_continuous_error():\n\ty = np.linspace(0, 1, 20)\n\tcnn = CondensedNearestNeighbour(random_state=RND_SEED)\n\tassert_warns(UserWarning, cnn.fit, X, y)\n","test either if an error is raised when the target are continuous type ."] (predictor.py:56, main())
[2020-11-20 23:32:58]    INFO >> ["def basic_check_run_complete_f(f):\n\tfilepaths = [l.strip() for l in f]\n\tfor fp in filepaths:\n\t\tif (not exists(fp)):\n\t\t\treturn False\n\treturn True\n","return true if all filepaths exist f: file containing list of filepaths example f: f1 ."] (predictor.py:56, main())
[2020-11-20 23:32:59]    INFO >> ["def test_iht_sample_wt_fit():\n\tiht = InstanceHardnessThreshold(ESTIMATOR, random_state=RND_SEED)\n\tassert_raises(RuntimeError, iht.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:32:59]    INFO >> ["def build_filter(class_name, *args):\n\tif (not hasattr(filters, class_name)):\n\t\treturn None\n\tfilterclass = getattr(filters, class_name)\n\treturn filterclass(*args)\n","returns a filter object of class class_name ."] (predictor.py:56, main())
[2020-11-20 23:33:00]    INFO >> ["def delete_if_exists(pathname):\n\ttry:\n\t\tos.unlink(pathname)\n\texcept OSError as e:\n\t\tif (e.errno == errno.ENOENT):\n\t\t\treturn\n\t\telse:\n\t\t\traise\n","delete a file ."] (predictor.py:56, main())
[2020-11-20 23:33:00]    INFO >> ["def default_key_func(key, key_prefix, version):\n\treturn ('%s:%s:%s' % (key_prefix, version, key))\n","default function to generate keys ."] (predictor.py:56, main())
[2020-11-20 23:33:00]    INFO >> ["def urlquote_plus(url, safe=''):\n\treturn force_unicode(urllib.quote_plus(smart_str(url), safe))\n","a version of pythons urllib ."] (predictor.py:56, main())
[2020-11-20 23:33:01]    INFO >> ["def get_system_username():\n\ttry:\n\t\treturn getpass.getuser().decode(locale.getdefaultlocale()[1])\n\texcept (ImportError, KeyError, UnicodeDecodeError):\n\t\treturn u''\n","try to determine the current system users username ."] (predictor.py:56, main())
[2020-11-20 23:33:01]    INFO >> ["def _api_pause(name, output, kwargs):\n\tscheduler.plan_resume(0)\n\tDownloader.do.pause()\n\treturn report(output)\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:33:02]    INFO >> ["def short_color(color):\n\tif (len(color) > 6):\n\t\treturn color[2:]\n\telse:\n\t\treturn color\n","format a color to its short size ."] (predictor.py:56, main())
[2020-11-20 23:33:02]    INFO >> ["def positive(s, threshold=0.1, **kwargs):\n\treturn (polarity(unicode(s), **kwargs) >= threshold)\n","returns true if the given sentence has a positive sentiment ."] (predictor.py:56, main())
[2020-11-20 23:33:02]    INFO >> ["def FakeUTime(path, times):\n\traise OSError(errno.EPERM, 'Operation\tnot\tpermitted', path)\n","fake version of os ."] (predictor.py:56, main())
[2020-11-20 23:33:03]    INFO >> ["def default_connection_selector(connection, app_blame):\n\treturn handlers.BaseConnectionHandler\n","returns a nogotofail ."] (predictor.py:56, main())
[2020-11-20 23:33:03]    INFO >> ["def with_metaclass(meta, base=object):\n\treturn meta('NewBase', (base,), {})\n","create a base class with a metaclass ."] (predictor.py:56, main())
[2020-11-20 23:33:03]    INFO >> ["def test_ncr_sk_estimator():\n\tcheck_estimator(NeighbourhoodCleaningRule)\n","test the sklearn estimator compatibility ."] (predictor.py:56, main())
[2020-11-20 23:33:04]    INFO >> ["def cbSentMessage(result):\n\tprint('Message\tsent')\n\treactor.stop()\n","called when the message has been sent ."] (predictor.py:56, main())
[2020-11-20 23:33:04]    INFO >> ["def safe_load(stream):\n\treturn load(stream, SafeLoader)\n","parse the first yaml document in a stream and produce the corresponding python object ."] (predictor.py:56, main())
[2020-11-20 23:33:05]    INFO >> ["def getOverhangDirection(belowOutsetLoops, segmentBegin, segmentEnd):\n\tsegment = (segmentEnd - segmentBegin)\n\tnormalizedSegment = euclidean.getNormalized(complex(segment.real, segment.imag))\n\tsegmentYMirror = complex(normalizedSegment.real, (- normalizedSegment.imag))\n\tsegmentBegin = (segmentYMirror * segmentBegin)\n\tsegmentEnd = (segmentYMirror * segmentEnd)\n\tsolidXIntersectionList = []\n\ty = segmentBegin.imag\n\tsolidXIntersectionList.append(euclidean.XIntersectionIndex((-1.0), segmentBegin.real))\n\tsolidXIntersectionList.append(euclidean.XIntersectionIndex((-1.0), segmentEnd.real))\n\tfor belowLoopIndex in xrange(len(belowOutsetLoops)):\n\t\tbelowLoop = belowOutsetLoops[belowLoopIndex]\n\t\trotatedOutset = euclidean.getPointsRoundZAxis(segmentYMirror, belowLoop)\n\t\teuclidean.addXIntersectionIndexesFromLoopY(rotatedOutset, belowLoopIndex, solidXIntersectionList, y)\n\toverhangingSegments = euclidean.getSegmentsFromXIntersectionIndexes(solidXIntersectionList, y)\n\toverhangDirection = complex()\n\tfor overhangingSegment in overhangingSegments:\n\t\toverhangDirection += getDoubledRoundZ(overhangingSegment, normalizedSegment)\n\treturn overhangDirection\n","add to span direction from the endpoint segments which overhang the layer below ."] (predictor.py:56, main())
[2020-11-20 23:33:06]    INFO >> ["@sensitive_post_parameters()\n@csrf_protect\n@never_cache\ndef login(request, template_name='registration\/login.html', redirect_field_name=REDIRECT_FIELD_NAME, authentication_form=AuthenticationForm, current_app=None, extra_context=None):\n\tredirect_to = request.REQUEST.get(redirect_field_name, '')\n\tif (request.method == 'POST'):\n\t\tform = authentication_form(data=request.POST)\n\t\tif form.is_valid():\n\t\t\tif (not is_safe_url(url=redirect_to, host=request.get_host())):\n\t\t\t\tredirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)\n\t\t\tauth_login(request, form.get_user())\n\t\t\tif request.session.test_cookie_worked():\n\t\t\t\trequest.session.delete_test_cookie()\n\t\t\treturn HttpResponseRedirect(redirect_to)\n\telse:\n\t\tform = authentication_form(request)\n\trequest.session.set_test_cookie()\n\tcurrent_site = get_current_site(request)\n\tcontext = {'form': form, redirect_field_name: redirect_to, 'site': current_site, 'site_name': current_site.name}\n\tif (extra_context is not None):\n\t\tcontext.update(extra_context)\n\treturn TemplateResponse(request, template_name, context, current_app=current_app)\n","displays the login form and handles the login action ."] (predictor.py:56, main())
[2020-11-20 23:33:06]    INFO >> ["def test_dnn_tag():\n\tx = T.tensor4()\n\told = theano.config.on_opt_error\n\ttheano.config.on_opt_error = 'raise'\n\tsio = StringIO()\n\thandler = logging.StreamHandler(sio)\n\tlogging.getLogger('theano.compile.tests.test_dnn').addHandler(handler)\n\tlogging.getLogger('theano').removeHandler(theano.logging_default_handler)\n\traised = False\n\ttry:\n\t\tf = theano.function([x], pool_2d(x, ws=(2, 2), ignore_border=True), mode=mode_with_gpu.including('cudnn'))\n\texcept (AssertionError, RuntimeError):\n\t\tassert (not dnn.dnn_available(test_ctx_name))\n\t\traised = True\n\tfinally:\n\t\ttheano.config.on_opt_error = old\n\t\tlogging.getLogger('theano.compile.tests.test_dnn').removeHandler(handler)\n\t\tlogging.getLogger('theano').addHandler(theano.logging_default_handler)\n\tif (not raised):\n\t\tassert dnn.dnn_available(test_ctx_name)\n\t\tassert any([isinstance(n.op, dnn.GpuDnnPool) for n in f.maker.fgraph.toposort()])\n","test that if cudnn isnt avail we crash and that if it is avail ."] (predictor.py:56, main())
[2020-11-20 23:33:06]    INFO >> ["def FindPythonExe(exeAlias, possibleRealNames, searchPaths):\n\timport win32api, regutil, string, os, sys\n\tif (possibleRealNames is None):\n\t\tpossibleRealNames = exeAlias\n\tfound = os.path.join(sys.prefix, possibleRealNames)\n\tif (not FileExists(found)):\n\t\tfound = os.path.join(sys.prefix, 'PCBuild', possibleRealNames)\n\tif (not FileExists(found)):\n\t\tfound = LocateFileName(possibleRealNames, searchPaths)\n\tregistered_ok = 0\n\ttry:\n\t\tregistered = win32api.RegQueryValue(regutil.GetRootKey(), ((regutil.GetAppPathsKey() + '\\\\') + exeAlias))\n\t\tregistered_ok = (found == registered)\n\texcept win32api.error:\n\t\tpass\n\treturn (found, registered_ok)\n","find an exe ."] (predictor.py:56, main())
[2020-11-20 23:33:07]    INFO >> ["def ValidateProperty(name, values, read_only=False):\n\tValidateString(name, 'property\tname', datastore_errors.BadPropertyError)\n\tvalues_type = type(values)\n\tif (values_type is tuple):\n\t\traise datastore_errors.BadValueError(('May\tnot\tuse\ttuple\tproperty\tvalue;\tproperty\t%s\tis\t%s.' % (name, repr(values))))\n\tif (values_type is not list):\n\t\tvalues = [values]\n\tif (not values):\n\t\traise datastore_errors.BadValueError(('May\tnot\tuse\tthe\tempty\tlist\tas\ta\tproperty\tvalue;\tproperty\t%s\tis\t%s.' % (name, repr(values))))\n\ttry:\n\t\tfor v in values:\n\t\t\tprop_validator = _VALIDATE_PROPERTY_VALUES.get(v.__class__)\n\t\t\tif (prop_validator is None):\n\t\t\t\traise datastore_errors.BadValueError(('Unsupported\ttype\tfor\tproperty\t%s:\t%s' % (name, v.__class__)))\n\t\t\tprop_validator(name, v)\n\texcept (KeyError, ValueError, TypeError, IndexError, AttributeError) as msg:\n\t\traise datastore_errors.BadValueError(('Error\ttype\tchecking\tvalues\tfor\tproperty\t%s:\t%s' % (name, msg)))\n","helper function for validating property values ."] (predictor.py:56, main())
[2020-11-20 23:33:08]    INFO >> ["def should_bypass_proxies(url):\n\tget_proxy = (lambda k: (os.environ.get(k) or os.environ.get(k.upper())))\n\tno_proxy = get_proxy('no_proxy')\n\tnetloc = urlparse(url).netloc\n\tif no_proxy:\n\t\tno_proxy = no_proxy.replace('\t', '').split(',')\n\t\tip = netloc.split(':')[0]\n\t\tif is_ipv4_address(ip):\n\t\t\tfor proxy_ip in no_proxy:\n\t\t\t\tif is_valid_cidr(proxy_ip):\n\t\t\t\t\tif address_in_network(ip, proxy_ip):\n\t\t\t\t\t\treturn True\n\t\telse:\n\t\t\tfor host in no_proxy:\n\t\t\t\tif (netloc.endswith(host) or netloc.split(':')[0].endswith(host)):\n\t\t\t\t\treturn True\n\ttry:\n\t\tbypass = proxy_bypass(netloc)\n\texcept (TypeError, socket.gaierror):\n\t\tbypass = False\n\tif bypass:\n\t\treturn True\n\treturn False\n","returns whether we should bypass proxies or not ."] (predictor.py:56, main())
[2020-11-20 23:33:08]    INFO >> ["def default_user_agent():\n\t_implementation = platform.python_implementation()\n\tif (_implementation == 'CPython'):\n\t\t_implementation_version = platform.python_version()\n\telif (_implementation == 'PyPy'):\n\t\t_implementation_version = ('%s.%s.%s' % (sys.pypy_version_info.major, sys.pypy_version_info.minor, sys.pypy_version_info.micro))\n\t\tif (sys.pypy_version_info.releaselevel != 'final'):\n\t\t\t_implementation_version = ''.join([_implementation_version, sys.pypy_version_info.releaselevel])\n\telif (_implementation == 'Jython'):\n\t\t_implementation_version = platform.python_version()\n\telif (_implementation == 'IronPython'):\n\t\t_implementation_version = platform.python_version()\n\telse:\n\t\t_implementation_version = 'Unknown'\n\ttry:\n\t\tp_system = platform.system()\n\t\tp_release = platform.release()\n\texcept IOError:\n\t\tp_system = 'Unknown'\n\t\tp_release = 'Unknown'\n\treturn '\t'.join([('python-requests\/%s' % __version__), ('%s\/%s' % (_implementation, _implementation_version)), ('%s\/%s' % (p_system, p_release))])\n","return a string representing the default user agent ."] (predictor.py:56, main())
[2020-11-20 23:33:09]    INFO >> ["def _ipconfig_getnode():\n\timport os, re\n\tdirs = ['', 'c:\\\\windows\\\\system32', 'c:\\\\winnt\\\\system32']\n\ttry:\n\t\timport ctypes\n\t\tbuffer = ctypes.create_string_buffer(300)\n\t\tctypes.windll.kernel32.GetSystemDirectoryA(buffer, 300)\n\t\tdirs.insert(0, buffer.value.decode('mbcs'))\n\texcept:\n\t\tpass\n\tfor dir in dirs:\n\t\ttry:\n\t\t\tpipe = os.popen((os.path.join(dir, 'ipconfig') + '\t\/all'))\n\t\texcept IOError:\n\t\t\tcontinue\n\t\tfor line in pipe:\n\t\t\tvalue = line.split(':')[(-1)].strip().lower()\n\t\t\tif re.match('([0-9a-f][0-9a-f]-){5}[0-9a-f][0-9a-f]', value):\n\t\t\t\treturn int(value.replace('-', ''), 16)\n","get the hardware address on windows by running ipconfig ."] (predictor.py:56, main())
[2020-11-20 23:33:09]    INFO >> ["def _parse_date_greek(dateString):\n\tm = _greek_date_format_re.match(dateString)\n\tif (not m):\n\t\treturn\n\twday = _greek_wdays[m.group(1)]\n\tmonth = _greek_months[m.group(3)]\n\trfc822date = ('%(wday)s,\t%(day)s\t%(month)s\t%(year)s\t%(hour)s:%(minute)s:%(second)s\t%(zonediff)s' % {'wday': wday, 'day': m.group(2), 'month': month, 'year': m.group(4), 'hour': m.group(5), 'minute': m.group(6), 'second': m.group(7), 'zonediff': m.group(8)})\n\treturn _parse_date_rfc822(rfc822date)\n","parse a string according to a greek 8-bit date format ."] (predictor.py:56, main())
[2020-11-20 23:33:09]    INFO >> ["def logout(request, next_page=None, template_name='registration\/logged_out.html', redirect_field_name=REDIRECT_FIELD_NAME, current_app=None, extra_context=None):\n\tauth_logout(request)\n\tif (next_page is not None):\n\t\tnext_page = resolve_url(next_page)\n\tif (redirect_field_name in request.REQUEST):\n\t\tnext_page = request.REQUEST[redirect_field_name]\n\t\tif (not is_safe_url(url=next_page, host=request.get_host())):\n\t\t\tnext_page = request.path\n\tif next_page:\n\t\treturn HttpResponseRedirect(next_page)\n\tcurrent_site = get_current_site(request)\n\tcontext = {'site': current_site, 'site_name': current_site.name, 'title': _('Logged\tout')}\n\tif (extra_context is not None):\n\t\tcontext.update(extra_context)\n\treturn TemplateResponse(request, template_name, context, current_app=current_app)\n","logs out the user and displays you are logged out message ."] (predictor.py:56, main())
[2020-11-20 23:33:11]    INFO >> ["def test_read_no_header_names_NoHeader():\n\ttable = '\\n|\t\tJohn\t\t|\t555-1234\t|192.168.1.10|\\n|\t\tMary\t\t|\t555-2134\t|192.168.1.12|\\n|\t\t\tBob\t\t|\t555-4527\t|\t192.168.1.9|\\n'\n\tdat = ascii.read(table, Reader=ascii.FixedWidthNoHeader, names=('Name', 'Phone', 'TCP'))\n\tassert_equal(tuple(dat.dtype.names), ('Name', 'Phone', 'TCP'))\n\tassert_equal(dat[1][0], 'Mary')\n\tassert_equal(dat[0][1], '555-1234')\n\tassert_equal(dat[2][2], '192.168.1.9')\n","table with no header row and with col names provided ."] (predictor.py:56, main())
[2020-11-20 23:33:11]    INFO >> ["def processCondition(xmlElement):\n\txmlProcessor = xmlElement.getXMLProcessor()\n\tif (xmlElement.object == None):\n\t\txmlElement.object = ModuleXMLElement(xmlElement)\n\tif (xmlElement.object.conditionSplitWords == None):\n\t\treturn\n\tif (len(xmlProcessor.functions) < 1):\n\t\tprint 'Warning,\t\"in\"\telement\tis\tnot\tin\ta\tfunction\tin\tprocessCondition\tin\tevaluate\tfor:'\n\t\tprint xmlElement\n\t\treturn\n\tif (int(getEvaluatedExpressionValueBySplitLine(xmlElement.object.conditionSplitWords, xmlElement)) > 0):\n\t\txmlProcessor.functions[(-1)].processChildren(xmlElement)\n\telse:\n\t\txmlElement.object.processElse(xmlElement)\n","process the xml element condition ."] (predictor.py:56, main())
[2020-11-20 23:33:12]    INFO >> ["def _seticon(object_alias, icondata):\n\tfinder = _getfinder()\n\targs = {}\n\tattrs = {}\n\taeobj_00 = aetypes.ObjectSpecifier(want=aetypes.Type('cobj'), form='alis', seld=object_alias, fr=None)\n\taeobj_01 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('iimg'), fr=aeobj_00)\n\targs['----'] = aeobj_01\n\targs['data'] = icondata\n\t(_reply, args, attrs) = finder.send('core', 'setd', args, attrs)\n\tif args.has_key('errn'):\n\t\traise Error, aetools.decodeerror(args)\n\tif args.has_key('----'):\n\t\treturn args['----'].data\n","set the icondata for object ."] (predictor.py:56, main())
[2020-11-20 23:33:13]    INFO >> ["def _find_executable(executable, path=None):\n\tif (path is None):\n\t\tpath = os.environ['PATH']\n\tpaths = path.split(os.pathsep)\n\t(base, ext) = os.path.splitext(executable)\n\tif (((sys.platform == 'win32') or (os.name == 'os2')) and (ext != '.exe')):\n\t\texecutable = (executable + '.exe')\n\tif (not os.path.isfile(executable)):\n\t\tfor p in paths:\n\t\t\tf = os.path.join(p, executable)\n\t\t\tif os.path.isfile(f):\n\t\t\t\treturn f\n\t\treturn None\n\telse:\n\t\treturn executable\n","tries to find executable in the directories listed in path ."] (predictor.py:56, main())
[2020-11-20 23:33:14]    INFO >> ["def url_params_from_lookup_dict(lookups):\n\tparams = {}\n\tif (lookups and hasattr(lookups, u'items')):\n\t\titems = []\n\t\tfor (k, v) in lookups.items():\n\t\t\tif callable(v):\n\t\t\t\tv = v()\n\t\t\tif isinstance(v, (tuple, list)):\n\t\t\t\tv = u','.join([str(x) for x in v])\n\t\t\telif isinstance(v, bool):\n\t\t\t\tv = (u'0', u'1')[v]\n\t\t\telse:\n\t\t\t\tv = six.text_type(v)\n\t\t\titems.append((k, v))\n\t\tparams.update(dict(items))\n\treturn params\n","converts the type of lookups specified in a foreignkey limit_choices_to attribute to a dictionary of query parameters ."] (predictor.py:56, main())
[2020-11-20 23:33:14]    INFO >> ["def colored(text, color=None, on_color=None, attrs=None):\n\tif (os.getenv('ANSI_COLORS_DISABLED') is None):\n\t\tfmt_str = '\\x1b[%dm%s'\n\t\tif (color is not None):\n\t\t\ttext = (fmt_str % (COLORS[color], text))\n\t\tif (on_color is not None):\n\t\t\ttext = (fmt_str % (HIGHLIGHTS[on_color], text))\n\t\tif (attrs is not None):\n\t\t\tfor attr in attrs:\n\t\t\t\ttext = (fmt_str % (ATTRIBUTES[attr], text))\n\t\ttext += RESET\n\treturn text\n","colorize text ."] (predictor.py:56, main())
[2020-11-20 23:33:16]    INFO >> ["def advanced_indexing_op(input, index):\n\tbatch_size = tf.shape(input)[0]\n\tmax_length = int(input.get_shape()[1])\n\tdim_size = int(input.get_shape()[2])\n\tindex = ((tf.range(0, batch_size) * max_length) + (index - 1))\n\tflat = tf.reshape(input, [(-1), dim_size])\n\trelevant = tf.gather(flat, index)\n\treturn relevant\n","advanced indexing for sequences ."] (predictor.py:56, main())
[2020-11-20 23:33:16]    INFO >> ["def process_parallel(callbacks, input, *a, **kw):\n\tdfds = [defer.succeed(input).addCallback(x, *a, **kw) for x in callbacks]\n\td = defer.DeferredList(dfds, fireOnOneErrback=1, consumeErrors=1)\n\td.addCallbacks((lambda r: [x[1] for x in r]), (lambda f: f.value.subFailure))\n\treturn d\n","return a deferred with the output of all successful calls to the given callbacks ."] (predictor.py:56, main())
[2020-11-20 23:33:17]    INFO >> ["def send_mass_mail(datatuple, fail_silently=False, auth_user=None, auth_password=None, connection=None):\n\tconnection = (connection or get_connection(username=auth_user, password=auth_password, fail_silently=fail_silently))\n\tmessages = [EmailMessage(subject, message, sender, recipient, connection=connection) for (subject, message, sender, recipient) in datatuple]\n\treturn connection.send_messages(messages)\n","given a datatuple of ."] (predictor.py:56, main())
[2020-11-20 23:33:17]    INFO >> ["def get_templatetags_modules():\n\tglobal templatetags_modules\n\tif (not templatetags_modules):\n\t\t_templatetags_modules = []\n\t\tfor app_module in (['google.appengine._internal.django'] + list(settings.INSTALLED_APPS)):\n\t\t\ttry:\n\t\t\t\ttemplatetag_module = ('%s.templatetags' % app_module)\n\t\t\t\timport_module(templatetag_module)\n\t\t\t\t_templatetags_modules.append(templatetag_module)\n\t\t\texcept ImportError:\n\t\t\t\tcontinue\n\t\ttemplatetags_modules = _templatetags_modules\n\treturn templatetags_modules\n","return the list of all available template tag modules ."] (predictor.py:56, main())
[2020-11-20 23:33:18]    INFO >> ["def uuid4():\n\tif _uuid_generate_random:\n\t\t_buffer = ctypes.create_string_buffer(16)\n\t\t_uuid_generate_random(_buffer)\n\t\treturn UUID(bytes=_buffer.raw)\n\ttry:\n\t\timport os\n\t\treturn UUID(bytes=os.urandom(16), version=4)\n\texcept:\n\t\timport random\n\t\tbytes = [chr(random.randrange(256)) for i in range(16)]\n\t\treturn UUID(bytes=bytes, version=4)\n","generate a random uuid ."] (predictor.py:56, main())
[2020-11-20 23:33:18]    INFO >> ["def test_suggested_column_names_from_visible_table(completer, complete_event):\n\ttext = u'SELECT\t\tfrom\tusers'\n\tposition = len(u'SELECT\t')\n\tresult = set(completer.get_completions(Document(text=text, cursor_position=position), complete_event))\n\tassert (set(result) == set(((testdata.columns(u'users') + testdata.functions()) + list((testdata.builtin_functions() + testdata.keywords())))))\n","suggest column and function names when selecting from table ."] (predictor.py:56, main())
[2020-11-20 23:33:19]    INFO >> ["def get_jid(jid):\n\twith _get_serv(ret=None, commit=True) as cur:\n\t\tsql = 'SELECT\tid,\tfull_ret\tFROM\tsalt_returns\\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tWHERE\tjid\t=\t%s'\n\t\tcur.execute(sql, (jid,))\n\t\tdata = cur.fetchall()\n\t\tret = {}\n\t\tif data:\n\t\t\tfor (minion, full_ret) in data:\n\t\t\t\tret[minion] = full_ret\n\t\treturn ret\n","return the information returned when the specified job id was executed ."] (predictor.py:56, main())
[2020-11-20 23:33:19]    INFO >> ["def get_mapreduce_yaml(parse=parse_mapreduce_yaml):\n\tmr_yaml_path = find_mapreduce_yaml()\n\tif (not mr_yaml_path):\n\t\traise MissingYamlError()\n\tmr_yaml_file = open(mr_yaml_path)\n\ttry:\n\t\treturn parse(mr_yaml_file.read())\n\tfinally:\n\t\tmr_yaml_file.close()\n","locates mapreduce ."] (predictor.py:56, main())
[2020-11-20 23:33:20]    INFO >> ["def register_treebuilders_from(module):\n\tthis_module = sys.modules['bs4.builder']\n\tfor name in module.__all__:\n\t\tobj = getattr(module, name)\n\t\tif issubclass(obj, TreeBuilder):\n\t\t\tsetattr(this_module, name, obj)\n\t\t\tthis_module.__all__.append(name)\n\t\t\tthis_module.builder_registry.register(obj)\n","copy treebuilders from the given module into this module ."] (predictor.py:56, main())
[2020-11-20 23:33:20]    INFO >> ["def normalize_excludes(rootpath, excludes):\n\treturn [path.abspath(exclude) for exclude in excludes]\n","normalize the excluded directory list: * must be either an absolute path or start with rootpath ."] (predictor.py:56, main())
[2020-11-20 23:33:21]    INFO >> ["@conf.commands.register\ndef srflood(x, promisc=None, filter=None, iface=None, nofilter=None, *args, **kargs):\n\ts = conf.L3socket(promisc=promisc, filter=filter, iface=iface, nofilter=nofilter)\n\tr = sndrcvflood(s, x, *args, **kargs)\n\ts.close()\n\treturn r\n","flood and receive packets at layer 3 prn: function applied to packets received ."] (predictor.py:56, main())
[2020-11-20 23:33:23]    INFO >> ["def identityRequest():\n\ta = TpPd(pd=3)\n\tb = MessageType(mesType=21)\n\tc = IdentityType2AndforceToStandby()\n\tpacket = ((a \/ b) \/ c)\n\treturn packet\n","identity request section 9 ."] (predictor.py:56, main())
[2020-11-20 23:33:23]    INFO >> ["def course_certificate():\n\tmode = session.s3.hrm.mode\n\tdef prep(r):\n\t\tif (mode is not None):\n\t\t\tauth.permission.fail()\n\t\treturn True\n\ts3.prep = prep\n\treturn s3_rest_controller('hrm', resourcename)\n","courses to certificates controller ."] (predictor.py:56, main())
[2020-11-20 23:33:24]    INFO >> ["def idzr_svd(A, k):\n\tA = np.asfortranarray(A)\n\t(U, V, S, ier) = _id.idzr_svd(A, k)\n\tif ier:\n\t\traise _RETCODE_ERROR\n\treturn (U, V, S)\n","compute svd of a complex matrix to a specified rank ."] (predictor.py:56, main())
[2020-11-20 23:33:24]    INFO >> ["def _wait_until_complete(operation, max_attempts=5):\n\tdef _operation_complete(result):\n\t\treturn result\n\tretry = RetryResult(_operation_complete, max_tries=max_attempts)\n\treturn retry(operation.poll)()\n","wait until an operation has completed ."] (predictor.py:56, main())
[2020-11-20 23:33:25]    INFO >> ["def stream_request_body(cls):\n\tif (not issubclass(cls, RequestHandler)):\n\t\traise TypeError('expected\tsubclass\tof\tRequestHandler,\tgot\t%r', cls)\n\tcls._stream_request_body = True\n\treturn cls\n","apply to requesthandler subclasses to enable streaming body support ."] (predictor.py:56, main())
[2020-11-20 23:33:25]    INFO >> ["def getTricomplextranslate(transformWords):\n\ttranslate = euclidean.getComplexByWords(transformWords)\n\treturn [complex(1.0, 0.0), complex(0.0, 1.0), translate]\n","get matrixsvg by transformwords ."] (predictor.py:56, main())
[2020-11-20 23:33:26]    INFO >> ["def test_sample_wt_fit():\n\tratio = 'auto'\n\tee = EasyEnsemble(ratio=ratio, random_state=RND_SEED)\n\tassert_raises(RuntimeError, ee.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:33:28]    INFO >> ["def storage_directory(datadir, partition, name_hash):\n\treturn os.path.join(datadir, str(partition), name_hash[(-3):], name_hash)\n","get the storage directory ."] (predictor.py:56, main())
[2020-11-20 23:33:29]    INFO >> ["def isabs(s):\n\ts = splitdrive(s)[1]\n\treturn ((s != '') and (s[:1] in '\/\\\\'))\n","test whether a path is absolute ."] (predictor.py:56, main())
[2020-11-20 23:33:29]    INFO >> ["def educateSingleBackticks(str):\n\tstr = re.sub('`', '&#8216;', str)\n\tstr = re.sub(\"'\", '&#8217;', str)\n\treturn str\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:33:30]    INFO >> ["def _fake_run_horcmstart2(*args):\n\treturn (0 if (not run_horcmstart_returns_error2) else 3)\n","return a value based on a flag value ."] (predictor.py:56, main())
[2020-11-20 23:33:31]    INFO >> ["def compute_node_get_all(context):\n\treturn IMPL.compute_node_get_all(context)\n","get all computenodes ."] (predictor.py:56, main())
[2020-11-20 23:33:31]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:33:32]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:33:33]    INFO >> ["def norm(x):\n\treturn sqrt(squared_norm(x))\n","dot product-based euclidean norm implementation see: url ."] (predictor.py:56, main())
[2020-11-20 23:33:33]    INFO >> ["@log_call\n@utils.no_4byte_params\ndef metadef_property_create(context, namespace_name, values):\n\tglobal DATA\n\tproperty_values = copy.deepcopy(values)\n\tproperty_name = property_values['name']\n\trequired_attributes = ['name']\n\tallowed_attributes = ['name', 'description', 'json_schema', 'required']\n\tnamespace = metadef_namespace_get(context, namespace_name)\n\tfor property in DATA['metadef_properties']:\n\t\tif ((property['name'] == property_name) and (property['namespace_id'] == namespace['id'])):\n\t\t\tLOG.debug('Can\tnot\tcreate\tmetadata\tdefinition\tproperty.\tA\tproperty\twith\tname=%(name)s\talready\texists\tin\tnamespace=%(namespace_name)s.', {'name': property_name, 'namespace_name': namespace_name})\n\t\t\traise exception.MetadefDuplicateProperty(property_name=property_name, namespace_name=namespace_name)\n\tfor key in required_attributes:\n\t\tif (key not in property_values):\n\t\t\traise exception.Invalid(('%s\tis\ta\trequired\tattribute' % key))\n\tincorrect_keys = (set(property_values.keys()) - set(allowed_attributes))\n\tif incorrect_keys:\n\t\traise exception.Invalid(('The\tkeys\t%s\tare\tnot\tvalid' % str(incorrect_keys)))\n\tproperty_values['namespace_id'] = namespace['id']\n\t_check_namespace_visibility(context, namespace, namespace_name)\n\tproperty = _format_property(property_values)\n\tDATA['metadef_properties'].append(property)\n\treturn property\n","create a metadef property ."] (predictor.py:56, main())
[2020-11-20 23:33:34]    INFO >> ["def make_query_from_filter(sample_filter, require_meter=True):\n\tq = {}\n\tif sample_filter.user:\n\t\tq['user_id'] = sample_filter.user\n\tif sample_filter.project:\n\t\tq['project_id'] = sample_filter.project\n\tif sample_filter.meter:\n\t\tq['counter_name'] = sample_filter.meter\n\telif require_meter:\n\t\traise RuntimeError('Missing\trequired\tmeter\tspecifier')\n\tts_range = make_timestamp_range(sample_filter.start_timestamp, sample_filter.end_timestamp, sample_filter.start_timestamp_op, sample_filter.end_timestamp_op)\n\tif ts_range:\n\t\tq['timestamp'] = ts_range\n\tif sample_filter.resource:\n\t\tq['resource_id'] = sample_filter.resource\n\tif sample_filter.source:\n\t\tq['source'] = sample_filter.source\n\tif sample_filter.message_id:\n\t\tq['message_id'] = sample_filter.message_id\n\tq.update(dict(((('resource_%s' % k), v) for (k, v) in six.iteritems(improve_keys(sample_filter.metaquery, metaquery=True)))))\n\treturn q\n","return a query dictionary based on the settings in the filter ."] (predictor.py:56, main())
[2020-11-20 23:33:35]    INFO >> ["def get_script_header(script_text, executable=sys_executable, wininst=False):\n\tfrom distutils.command.build_scripts import first_line_re\n\tfirst = (script_text + '\\n').splitlines()[0]\n\tmatch = first_line_re.match(first)\n\toptions = ''\n\tif match:\n\t\toptions = (match.group(1) or '')\n\t\tif options:\n\t\t\toptions = ('\t' + options)\n\tif wininst:\n\t\texecutable = 'python.exe'\n\telse:\n\t\texecutable = nt_quote_arg(executable)\n\thdr = ('#!%(executable)s%(options)s\\n' % locals())\n\tif (unicode(hdr, 'ascii', 'ignore').encode('ascii') != hdr):\n\t\tif options:\n\t\t\tif options.strip().startswith('-'):\n\t\t\t\toptions = ('\t-x' + options.strip()[1:])\n\t\telse:\n\t\t\toptions = '\t-x'\n\texecutable = fix_jython_executable(executable, options)\n\thdr = ('#!%(executable)s%(options)s\\n' % locals())\n\treturn hdr\n","create a #! line ."] (predictor.py:56, main())
[2020-11-20 23:33:35]    INFO >> ["def learn_cache_key(request, response, cache_timeout=None, key_prefix=None, cache=None):\n\tif (key_prefix is None):\n\t\tkey_prefix = settings.CACHE_MIDDLEWARE_KEY_PREFIX\n\tif (cache_timeout is None):\n\t\tcache_timeout = settings.CACHE_MIDDLEWARE_SECONDS\n\tcache_key = _generate_cache_header_key(key_prefix, request)\n\tif (cache is None):\n\t\tcache = get_cache(settings.CACHE_MIDDLEWARE_ALIAS)\n\tif response.has_header('Vary'):\n\t\theaderlist = [('HTTP_' + header.upper().replace('-', '_')) for header in cc_delim_re.split(response['Vary'])]\n\t\tcache.set(cache_key, headerlist, cache_timeout)\n\t\treturn _generate_cache_key(request, request.method, headerlist, key_prefix)\n\telse:\n\t\tcache.set(cache_key, [], cache_timeout)\n\t\treturn _generate_cache_key(request, request.method, [], key_prefix)\n","learns what headers to take into account for some request path from the response object ."] (predictor.py:56, main())
[2020-11-20 23:33:36]    INFO >> ["def DocTestSuite(module=None, globs=None, extraglobs=None, test_finder=None, **options):\n\tif (test_finder is None):\n\t\ttest_finder = DocTestFinder()\n\tmodule = _normalize_module(module)\n\ttests = test_finder.find(module, globs=globs, extraglobs=extraglobs)\n\tif (globs is None):\n\t\tglobs = module.__dict__\n\tif (not tests):\n\t\traise ValueError(module, 'has\tno\ttests')\n\ttests.sort()\n\tsuite = unittest.TestSuite()\n\tfor test in tests:\n\t\tif (len(test.examples) == 0):\n\t\t\tcontinue\n\t\tif (not test.filename):\n\t\t\tfilename = module.__file__\n\t\t\tif (filename[(-4):] in ('.pyc', '.pyo')):\n\t\t\t\tfilename = filename[:(-1)]\n\t\t\ttest.filename = filename\n\t\tsuite.addTest(DocTestCase(test, **options))\n\treturn suite\n","convert doctest tests for a module to a unittest test suite ."] (predictor.py:56, main())
[2020-11-20 23:33:36]    INFO >> ["def _dnsname_match(dn, hostname, max_wildcards=1):\n\tpats = []\n\tif (not dn):\n\t\treturn False\n\tparts = dn.split('.')\n\tleftmost = parts[0]\n\twildcards = leftmost.count('*')\n\tif (wildcards > max_wildcards):\n\t\traise CertificateError(('too\tmany\twildcards\tin\tcertificate\tDNS\tname:\t' + repr(dn)))\n\tif (not wildcards):\n\t\treturn (dn.lower() == hostname.lower())\n\tif (leftmost == '*'):\n\t\tpats.append('[^.]+')\n\telif (leftmost.startswith('xn--') or hostname.startswith('xn--')):\n\t\tpats.append(re.escape(leftmost))\n\telse:\n\t\tpats.append(re.escape(leftmost).replace('\\\\*', '[^.]*'))\n\tfor frag in parts[1:]:\n\t\tpats.append(re.escape(frag))\n\tpat = re.compile((('\\\\A' + '\\\\.'.join(pats)) + '\\\\Z'), re.IGNORECASE)\n\treturn pat.match(hostname)\n","matching according to rfc 6125 ."] (predictor.py:56, main())
[2020-11-20 23:33:37]    INFO >> ["def convert_to_tgt_list_and_itor_tgt_map(zone_mapping):\n\ttarget_wwns = []\n\titor_tgt_map = {}\n\tfor san_name in zone_mapping:\n\t\tone_map = zone_mapping[san_name]\n\t\tfor target in one_map['target_port_wwn_list']:\n\t\t\tif (target not in target_wwns):\n\t\t\t\ttarget_wwns.append(target)\n\t\tfor initiator in one_map['initiator_port_wwn_list']:\n\t\t\titor_tgt_map[initiator] = one_map['target_port_wwn_list']\n\tLOG.debug('target_wwns:\t%(tgt_wwns)s\\n\tinit_targ_map:\t%(itor_tgt_map)s', {'tgt_wwns': target_wwns, 'itor_tgt_map': itor_tgt_map})\n\treturn (target_wwns, itor_tgt_map)\n","function to process data from lookup service ."] (predictor.py:56, main())
[2020-11-20 23:33:38]    INFO >> ["def figaspect(arg):\n\tisarray = (hasattr(arg, u'shape') and (not np.isscalar(arg)))\n\tfigsize_min = np.array((4.0, 2.0))\n\tfigsize_max = np.array((16.0, 16.0))\n\tif isarray:\n\t\t(nr, nc) = arg.shape[:2]\n\t\tarr_ratio = (float(nr) \/ nc)\n\telse:\n\t\tarr_ratio = float(arg)\n\tfig_height = rcParams[u'figure.figsize'][1]\n\tnewsize = np.array(((fig_height \/ arr_ratio), fig_height))\n\tnewsize \/= min(1.0, *(newsize \/ figsize_min))\n\tnewsize \/= max(1.0, *(newsize \/ figsize_max))\n\tnewsize = np.clip(newsize, figsize_min, figsize_max)\n\treturn newsize\n","create a figure with specified aspect ratio ."] (predictor.py:56, main())
[2020-11-20 23:33:39]    INFO >> ["@testing.requires_testing_data\ndef test_calculate_chpi_positions_on_chpi5_in_one_second_steps():\n\tmf_quats = read_head_pos(chpi5_pos_fname)\n\traw = read_raw_fif(chpi5_fif_fname, allow_maxshield='yes')\n\traw = _decimate_chpi(raw.crop(0.0, 15.0).load_data(), decim=8)\n\tpy_quats = _calculate_chpi_positions(raw, t_step_min=1.0, t_step_max=1.0, t_window=1.0, verbose='debug')\n\t_assert_quats(py_quats, mf_quats, dist_tol=0.0008, angle_tol=0.5)\n","comparing estimated chpi positions with mf results ."] (predictor.py:56, main())
[2020-11-20 23:33:40]    INFO >> ["def RegisterHelpFile(helpFile, helpPath, helpDesc=None, bCheckFile=1):\n\tif (helpDesc is None):\n\t\thelpDesc = helpFile\n\tfullHelpFile = os.path.join(helpPath, helpFile)\n\ttry:\n\t\tif bCheckFile:\n\t\t\tos.stat(fullHelpFile)\n\texcept os.error:\n\t\traise ValueError('Help\tfile\tdoes\tnot\texist')\n\twin32api.RegSetValue(GetRootKey(), (BuildDefaultPythonKey() + ('\\\\Help\\\\%s' % helpDesc)), win32con.REG_SZ, fullHelpFile)\n","register a help file in the registry ."] (predictor.py:56, main())
[2020-11-20 23:33:41]    INFO >> ["def from_current_timezone(value):\n\tif (settings.USE_TZ and (value is not None) and timezone.is_naive(value)):\n\t\tcurrent_timezone = timezone.get_current_timezone()\n\t\ttry:\n\t\t\treturn timezone.make_aware(value, current_timezone)\n\t\texcept Exception:\n\t\t\traise ValidationError((_(u\"%(datetime)s\tcouldn't\tbe\tinterpreted\tin\ttime\tzone\t%(current_timezone)s;\tit\tmay\tbe\tambiguous\tor\tit\tmay\tnot\texist.\") % {u'datetime': value, u'current_timezone': current_timezone}))\n\treturn value\n","when time zone support is enabled ."] (predictor.py:56, main())
[2020-11-20 23:33:42]    INFO >> ["def getLargestInsetLoopFromLoopRegardless(loop, radius):\n\tglobal globalDecreasingRadiusMultipliers\n\tfor decreasingRadiusMultiplier in globalDecreasingRadiusMultipliers:\n\t\tdecreasingRadius = (radius * decreasingRadiusMultiplier)\n\t\tlargestInsetLoop = getLargestInsetLoopFromLoop(loop, decreasingRadius)\n\t\tif (len(largestInsetLoop) > 0):\n\t\t\treturn largestInsetLoop\n\tprint 'Warning,\tthere\tshould\talways\tbe\ta\tlargestInsetLoop\tin\tgetLargestInsetLoopFromLoopRegardless\tin\tintercircle.'\n\tprint loop\n\treturn loop\n","get the largest inset loop from the loop ."] (predictor.py:56, main())
[2020-11-20 23:33:43]    INFO >> ["def scalePoints(elementNode, points, prefix):\n\tscaleVector3Default = Vector3(1.0, 1.0, 1.0)\n\tscaleVector3 = matrix.getCumulativeVector3Remove(scaleVector3Default.copy(), elementNode, prefix)\n\tif (scaleVector3 == scaleVector3Default):\n\t\treturn\n\tfor point in points:\n\t\tpoint.x *= scaleVector3.x\n\t\tpoint.y *= scaleVector3.y\n\t\tpoint.z *= scaleVector3.z\n","scale the points ."] (predictor.py:56, main())
[2020-11-20 23:33:44]    INFO >> ["def referer(pattern, accept=True, accept_missing=False, error=403, message='Forbidden\tReferer\theader.', debug=False):\n\ttry:\n\t\tref = cherrypy.serving.request.headers['Referer']\n\t\tmatch = bool(re.match(pattern, ref))\n\t\tif debug:\n\t\t\tcherrypy.log(('Referer\t%r\tmatches\t%r' % (ref, pattern)), 'TOOLS.REFERER')\n\t\tif (accept == match):\n\t\t\treturn\n\texcept KeyError:\n\t\tif debug:\n\t\t\tcherrypy.log('No\tReferer\theader', 'TOOLS.REFERER')\n\t\tif accept_missing:\n\t\t\treturn\n\traise cherrypy.HTTPError(error, message)\n","raise httperror if referer header does\/does not match the given pattern ."] (predictor.py:56, main())
[2020-11-20 23:33:45]    INFO >> ["def send_followup_email_for_monthly_fee_payment(email, event_name, date, amount, payment_url):\n\tsend_email(to=email, action=MONTHLY_PAYMENT_FOLLOWUP_EMAIL, subject=MAILS[MONTHLY_PAYMENT_FOLLOWUP_EMAIL]['subject'].format(event_name=event_name, date=date), html=MAILS[MONTHLY_PAYMENT_FOLLOWUP_EMAIL]['message'].format(event_name=event_name, date=date, payment_url=payment_url, amount=amount, app_name=get_settings()['app_name']))\n","send email every month with invoice to pay service fee ."] (predictor.py:56, main())
[2020-11-20 23:33:45]    INFO >> ["def add_message(request, level, message, extra_tags='', fail_silently=False):\n\tif hasattr(request, '_messages'):\n\t\treturn request._messages.add(level, message, extra_tags)\n\tif (hasattr(request, 'user') and request.user.is_authenticated()):\n\t\treturn request.user.message_set.create(message=message)\n\tif (not fail_silently):\n\t\traise MessageFailure('Without\tthe\tdjango.contrib.messages\tmiddleware,\tmessages\tcan\tonly\tbe\tadded\tto\tauthenticated\tusers.')\n","attempts to add a message to the request using the messages app ."] (predictor.py:56, main())
[2020-11-20 23:33:46]    INFO >> ["def register_serializer(format, serializer_module, serializers=None):\n\tif ((serializers is None) and (not _serializers)):\n\t\t_load_serializers()\n\tmodule = importlib.import_module(serializer_module)\n\tif (serializers is None):\n\t\t_serializers[format] = module\n\telse:\n\t\tserializers[format] = module\n","register a new serializer ."] (predictor.py:56, main())
[2020-11-20 23:33:46]    INFO >> ["def _exec_template(callable_, context, args=None, kwargs=None):\n\ttemplate = context._with_template\n\tif ((template is not None) and (template.format_exceptions or template.error_handler)):\n\t\terror = None\n\t\ttry:\n\t\t\tcallable_(context, *args, **kwargs)\n\t\texcept Exception as e:\n\t\t\t_render_error(template, context, e)\n\t\texcept:\n\t\t\te = sys.exc_info()[0]\n\t\t\t_render_error(template, context, e)\n\telse:\n\t\tcallable_(context, *args, **kwargs)\n","execute a rendering callable given the callable ."] (predictor.py:56, main())
[2020-11-20 23:33:47]    INFO >> ["def groups_for_user(environ, username):\n\tUserModel = auth.get_user_model()\n\tdb.reset_queries()\n\ttry:\n\t\ttry:\n\t\t\tuser = UserModel._default_manager.get_by_natural_key(username)\n\t\texcept UserModel.DoesNotExist:\n\t\t\treturn []\n\t\tif (not user.is_active):\n\t\t\treturn []\n\t\treturn [force_bytes(group.name) for group in user.groups.all()]\n\tfinally:\n\t\tdb.close_old_connections()\n","authorizes a user based on groups ."] (predictor.py:56, main())
[2020-11-20 23:33:48]    INFO >> ["def InstanceActionAPI(*args, **kwargs):\n\timportutils = nova.openstack.common.importutils\n\tcompute_api_class_name = oslo.config.cfg.CONF.compute_api_class\n\tcompute_api_class = importutils.import_class(compute_api_class_name)\n\tclass_name = (compute_api_class.__module__ + '.InstanceActionAPI')\n\treturn importutils.import_object(class_name, *args, **kwargs)\n","returns the instanceactionapi class from the same module as the configured compute api ."] (predictor.py:56, main())
[2020-11-20 23:33:48]    INFO >> ["def fetch_crl(project_id):\n\tif (not CONF.crypto.use_project_ca):\n\t\tproject_id = None\n\tcrl_file_path = crl_path(project_id)\n\tif (not os.path.exists(crl_file_path)):\n\t\traise exception.CryptoCRLFileNotFound(project=project_id)\n\twith open(crl_file_path, 'r') as crlfile:\n\t\treturn crlfile.read()\n","get crl file for project ."] (predictor.py:56, main())
[2020-11-20 23:33:49]    INFO >> ["def dispatch_hook(key, hooks, hook_data, **kwargs):\n\thooks = (hooks or dict())\n\thooks = hooks.get(key)\n\tif hooks:\n\t\tif hasattr(hooks, '__call__'):\n\t\t\thooks = [hooks]\n\t\tfor hook in hooks:\n\t\t\t_hook_data = hook(hook_data, **kwargs)\n\t\t\tif (_hook_data is not None):\n\t\t\t\thook_data = _hook_data\n\treturn hook_data\n","dispatches a hook dictionary on a given piece of data ."] (predictor.py:56, main())
[2020-11-20 23:33:49]    INFO >> ["def import_class(import_str):\n\t(mod_str, _sep, class_str) = import_str.rpartition('.')\n\ttry:\n\t\t__import__(mod_str)\n\t\treturn getattr(sys.modules[mod_str], class_str)\n\texcept (ValueError, AttributeError):\n\t\traise ImportError(('Class\t%s\tcannot\tbe\tfound\t(%s)' % (class_str, traceback.format_exception(*sys.exc_info()))))\n","returns a class from a string including module and class ."] (predictor.py:56, main())
[2020-11-20 23:33:50]    INFO >> ["def forecast_data(year, quarter):\n\tif (ct._check_input(year, quarter) is True):\n\t\tct._write_head()\n\t\tdata = _get_forecast_data(year, quarter, 1, pd.DataFrame())\n\t\tdf = pd.DataFrame(data, columns=ct.FORECAST_COLS)\n\t\tdf['code'] = df['code'].map((lambda x: str(x).zfill(6)))\n\t\treturn df\n","parameters year:int \u5e74\u5ea6 e ."] (predictor.py:56, main())
[2020-11-20 23:33:50]    INFO >> ["def replace_query_param(url, key, val):\n\t(scheme, netloc, path, query, fragment) = urlparse.urlsplit(url)\n\tquery_dict = urlparse.parse_qs(query, keep_blank_values=True)\n\tquery_dict[key] = [val]\n\tquery = urlparse.urlencode(sorted(list(query_dict.items())), doseq=True)\n\treturn urlparse.urlunsplit((scheme, netloc, path, query, fragment))\n","given a url and a key\/val pair ."] (predictor.py:56, main())
[2020-11-20 23:33:52]    INFO >> ["def _ls_emr_step_stderr_logs(fs, log_dir_stream, step_id=None):\n\tmatches = _ls_logs(fs, log_dir_stream, _match_emr_step_stderr_path, step_id=step_id)\n\treturn sorted(matches, key=_match_sort_key, reverse=True)\n","yield matching step logs ."] (predictor.py:56, main())
[2020-11-20 23:33:52]    INFO >> ["def walk_to_end(ch, input_iter):\n\tif (ch == '('):\n\t\tnesting = 1\n\telse:\n\t\tnesting = 0\n\tfor (ch, escaped) in input_iter:\n\t\tif escaped:\n\t\t\tcontinue\n\t\telif (ch == '('):\n\t\t\tnesting += 1\n\t\telif (ch == ')'):\n\t\t\tif (not nesting):\n\t\t\t\treturn\n\t\t\tnesting -= 1\n","the iterator is currently inside a capturing group ."] (predictor.py:56, main())
[2020-11-20 23:33:53]    INFO >> ["def run_migrations_offline():\n\tset_mysql_engine()\n\tkwargs = dict()\n\tif neutron_config.database.connection:\n\t\tkwargs['url'] = neutron_config.database.connection\n\telse:\n\t\tkwargs['dialect_name'] = neutron_config.database.engine\n\tkwargs['include_object'] = include_object\n\tcontext.configure(**kwargs)\n\twith context.begin_transaction():\n\t\tcontext.run_migrations()\n","run migrations in offline mode ."] (predictor.py:56, main())
[2020-11-20 23:33:53]    INFO >> ["def getAroundsFromPaths(paths, radius, thresholdRatio=0.9):\n\tpoints = []\n\tfor path in paths:\n\t\tpoints += getPointsFromPath(path, (1.01 * abs(radius)), thresholdRatio)\n\treturn getAroundsFromPoints(points, radius)\n","get the arounds from the path ."] (predictor.py:56, main())
[2020-11-20 23:33:53]    INFO >> ["def returnConnected(server, client):\n\tcio = StringIO()\n\tsio = StringIO()\n\tclient.makeConnection(FileWrapper(cio))\n\tserver.makeConnection(FileWrapper(sio))\n\tpump = IOPump(client, server, cio, sio)\n\tpump.flush()\n\tpump.flush()\n\treturn pump\n","take two protocol instances and connect them ."] (predictor.py:56, main())
[2020-11-20 23:33:54]    INFO >> ["def b64decode(s, altchars=None):\n\tif (altchars is not None):\n\t\ts = _translate(s, {altchars[0]: '+', altchars[1]: '\/'})\n\ttry:\n\t\treturn binascii.a2b_base64(s)\n\texcept binascii.Error as msg:\n\t\traise TypeError(msg)\n","decode a base64 encoded string ."] (predictor.py:56, main())
[2020-11-20 23:33:55]    INFO >> ["def en_format(name):\n\tfrom django.conf.locale.en import formats\n\twarnings.warn((\"`django.forms.fields.DEFAULT_%s`\tis\tdeprecated;\tuse\t`django.utils.formats.get_format('%s')`\tinstead.\" % (name, name)), PendingDeprecationWarning)\n\treturn getattr(formats, name)\n","helper function to stay backward compatible ."] (predictor.py:56, main())
[2020-11-20 23:33:55]    INFO >> ["def test_iht_fit_invalid_ratio():\n\tratio = (1.0 \/ 10000.0)\n\tiht = InstanceHardnessThreshold(ESTIMATOR, ratio=ratio, random_state=RND_SEED)\n\tassert_raises(RuntimeError, iht.fit, X, Y)\n","test either if an error is raised when the balancing ratio to fit is smaller than the one of the data ."] (predictor.py:56, main())
[2020-11-20 23:33:56]    INFO >> ["def get_reader_class(reader_name):\n\treader_name = reader_name.lower()\n\tif (reader_name in _reader_aliases):\n\t\treader_name = _reader_aliases[reader_name]\n\ttry:\n\t\tmodule = __import__(reader_name, globals(), locals(), level=1)\n\texcept ImportError:\n\t\tmodule = __import__(reader_name, globals(), locals(), level=0)\n\treturn module.Reader\n","return the reader class from the reader_name module ."] (predictor.py:56, main())
[2020-11-20 23:33:56]    INFO >> ["def flatten_fieldsets(fieldsets):\n\tfield_names = []\n\tfor (name, opts) in fieldsets:\n\t\tfor field in opts[u'fields']:\n\t\t\tif (type(field) == tuple):\n\t\t\t\tfield_names.extend(field)\n\t\t\telse:\n\t\t\t\tfield_names.append(field)\n\treturn field_names\n","returns a list of field names from an admin fieldsets structure ."] (predictor.py:56, main())
[2020-11-20 23:33:56]    INFO >> ["def json_splitter(buffer):\n\ttry:\n\t\t(obj, index) = json_decoder.raw_decode(buffer)\n\t\trest = buffer[json.decoder.WHITESPACE.match(buffer, index).end():]\n\t\treturn (obj, rest)\n\texcept ValueError:\n\t\treturn None\n","attempt to parse a json object from a buffer ."] (predictor.py:56, main())
[2020-11-20 23:33:56]    INFO >> ["def extract_zip(source, remove=False, fatal=True):\n\ttempdir = tempfile.mkdtemp()\n\tzip_file = SafeUnzip(source)\n\ttry:\n\t\tif zip_file.is_valid(fatal):\n\t\t\tzip_file.extract_to_dest(tempdir)\n\texcept:\n\t\trm_local_tmp_dir(tempdir)\n\t\traise\n\tif remove:\n\t\tos.remove(source)\n\treturn tempdir\n","extracts the zip file ."] (predictor.py:56, main())
[2020-11-20 23:33:57]    INFO >> ["def read_py_file(filename, skip_encoding_cookie=True):\n\twith tokopen(filename) as f:\n\t\tif skip_encoding_cookie:\n\t\t\treturn ''.join(strip_encoding_cookie(f))\n\t\telse:\n\t\t\treturn f.read()\n","read a python file ."] (predictor.py:56, main())
[2020-11-20 23:33:57]    INFO >> ["def convert_TimeProperty(model, prop, kwargs):\n\tif (prop.auto_now or prop.auto_now_add):\n\t\treturn None\n\treturn f.DateTimeField(format='%H:%M:%S', **kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:33:58]    INFO >> ["def educateEllipses(s):\n\treturn s.replace('...', '&#8230;').replace('.\t.\t.', '&#8230;')\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:33:58]    INFO >> ["def console_get_all_by_instance(context, instance_uuid, columns_to_join=None):\n\treturn IMPL.console_get_all_by_instance(context, instance_uuid, columns_to_join)\n","get consoles for a given instance ."] (predictor.py:56, main())
[2020-11-20 23:33:59]    INFO >> ["def test_sample_wt_fit():\n\tratio = 'auto'\n\tee = EasyEnsemble(ratio=ratio, random_state=RND_SEED)\n\tassert_raises(RuntimeError, ee.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:33:59]    INFO >> ["def action_peek_xml(body):\n\tdom = utils.safe_minidom_parse_string(body)\n\taction_node = dom.childNodes[0]\n\treturn action_node.tagName\n","determine action to invoke ."] (predictor.py:56, main())
[2020-11-20 23:34:01]    INFO >> ["def test_sobel_zeros():\n\tresult = filters.sobel(np.zeros((10, 10)), np.ones((10, 10), bool))\n\tassert np.all((result == 0))\n","sobel on an array of all zeros ."] (predictor.py:56, main())
[2020-11-20 23:34:02]    INFO >> ["def dup_add_mul(f, g, h, K):\n\treturn dup_add(f, dup_mul(g, h, K), K)\n","returns f + g*h where f ."] (predictor.py:56, main())
[2020-11-20 23:34:02]    INFO >> ["def componentFactory(componentid, password):\n\ta = ConnectComponentAuthenticator(componentid, password)\n\treturn xmlstream.XmlStreamFactory(a)\n","xml stream factory for external server-side components ."] (predictor.py:56, main())
[2020-11-20 23:34:03]    INFO >> ["def _api_shutdown(name, output, kwargs):\n\tsabnzbd.halt()\n\tcherrypy.engine.exit()\n\tsabnzbd.SABSTOP = True\n\treturn report(output)\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:34:03]    INFO >> ["def posixToNtSlashes(filepath):\n\treturn filepath.replace('\/', '\\\\')\n","replaces all occurances of posix slashes (\/) in provided filepath with nt ones () ."] (predictor.py:56, main())
[2020-11-20 23:34:04]    INFO >> ["def urlunquote(quoted_url):\n\treturn force_text(urllib_parse.unquote(force_str(quoted_url)))\n","a wrapper for pythons urllib ."] (predictor.py:56, main())
[2020-11-20 23:34:04]    INFO >> ["@register.tag\ndef get_comment_list(parser, token):\n\treturn CommentListNode.handle_token(parser, token)\n","gets the list of comments for the given params and populates the template context with a variable containing that value ."] (predictor.py:56, main())
[2020-11-20 23:34:05]    INFO >> ["def L(seqn):\n\treturn chain(imap((lambda x: x), R(Ig(G(seqn)))))\n","test multiple tiers of iterators ."] (predictor.py:56, main())
[2020-11-20 23:34:05]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:34:05]    INFO >> ["def apply_rollback(datastore, name):\n\treturn _proxy_cmd('apply_rollback', datastore, name)\n","apply a system rollback ."] (predictor.py:56, main())
[2020-11-20 23:34:05]    INFO >> ["def wordcount(value):\n\treturn len(value.split())\n","returns the number of words ."] (predictor.py:56, main())
[2020-11-20 23:34:06]    INFO >> ["def comment(parser, token):\n\tparser.skip_past('endcomment')\n\treturn CommentNode()\n","ignores everything between {% comment %} and {% endcomment %} ."] (predictor.py:56, main())
[2020-11-20 23:34:06]    INFO >> ["def test_ros_sk_estimator():\n\tcheck_estimator(RandomOverSampler)\n","test the sklearn estimator compatibility ."] (predictor.py:56, main())
[2020-11-20 23:34:07]    INFO >> ["def zone_type():\n\treturn s3_rest_controller()\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:34:07]    INFO >> ["def evaluation_question():\n\treturn s3_rest_controller()\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:34:08]    INFO >> ["def educateQuotesLatex(s, dquotes=('``', \"''\")):\n\ts = single_quote_start_re.sub('\\x04', s)\n\ts = double_quote_start_re.sub('\\x02', s)\n\ts = double_quote_sets_re.sub('\\x01\\x03', s)\n\ts = single_quote_sets_re.sub('\\x03\\x01', s)\n\ts = decade_abbr_re.sub('\\x04', s)\n\ts = opening_single_quotes_regex.sub('\\\\1\\x03', s)\n\ts = closing_single_quotes_regex.sub('\\\\1\\x04', s)\n\ts = closing_single_quotes_regex_2.sub('\\\\1\\x04\\\\2', s)\n\ts = s.replace(\"'\", '\\x03')\n\ts = opening_double_quotes_regex.sub('\\\\1\\x01', s)\n\ts = closing_double_quotes_regex.sub('\\x02', s)\n\ts = closing_double_quotes_regex_2.sub('\\\\1\\x02', s)\n\ts = s.replace('\"', '\\x01')\n\treturn s.replace('\\x01', dquotes[0]).replace('\\x02', dquotes[1]).replace('\\x03', '`').replace('\\x04', \"'\")\n","parameter: string ."] (predictor.py:56, main())
[2020-11-20 23:34:08]    INFO >> ["def match_hostname(cert, hostname):\n\tif (not cert):\n\t\traise ValueError('empty\tor\tno\tcertificate')\n\tdnsnames = []\n\tsan = cert.get('subjectAltName', ())\n\tfor (key, value) in san:\n\t\tif (key == 'DNS'):\n\t\t\tif _dnsname_to_pat(value).match(hostname):\n\t\t\t\treturn\n\t\t\tdnsnames.append(value)\n\tif (not dnsnames):\n\t\tfor sub in cert.get('subject', ()):\n\t\t\tfor (key, value) in sub:\n\t\t\t\tif (key == 'commonName'):\n\t\t\t\t\tif _dnsname_to_pat(value).match(hostname):\n\t\t\t\t\t\treturn\n\t\t\t\t\tdnsnames.append(value)\n\tif (len(dnsnames) > 1):\n\t\traise CertificateError((\"hostname\t%r\tdoesn't\tmatch\teither\tof\t%s\" % (hostname, ',\t'.join(map(repr, dnsnames)))))\n\telif (len(dnsnames) == 1):\n\t\traise CertificateError((\"hostname\t%r\tdoesn't\tmatch\t%r\" % (hostname, dnsnames[0])))\n\telse:\n\t\traise CertificateError('no\tappropriate\tcommonName\tor\tsubjectAltName\tfields\twere\tfound')\n","verify that *cert* (in decoded format as returned by sslsocket ."] (predictor.py:56, main())
[2020-11-20 23:34:08]    INFO >> ["def _handle_ns(packageName, path_item):\n\timporter = get_importer(path_item)\n\tif (importer is None):\n\t\treturn None\n\tloader = importer.find_module(packageName)\n\tif (loader is None):\n\t\treturn None\n\tmodule = sys.modules.get(packageName)\n\tif (module is None):\n\t\tmodule = sys.modules[packageName] = types.ModuleType(packageName)\n\t\tmodule.__path__ = []\n\t\t_set_parent_ns(packageName)\n\telif (not hasattr(module, '__path__')):\n\t\traise TypeError('Not\ta\tpackage:', packageName)\n\thandler = _find_adapter(_namespace_handlers, importer)\n\tsubpath = handler(importer, path_item, packageName, module)\n\tif (subpath is not None):\n\t\tpath = module.__path__\n\t\tpath.append(subpath)\n\t\tloader.load_module(packageName)\n\t\tsys_path = [((p and _normalize_cached(p)) or p) for p in sys.path]\n\t\tdef sort_key(p):\n\t\t\tparts = p.split(os.sep)\n\t\t\tparts = parts[:(- (packageName.count('.') + 1))]\n\t\t\treturn sys_path.index(_normalize_cached(os.sep.join(parts)))\n\t\tpath.sort(key=sort_key)\n\t\tmodule.__path__[:] = [_normalize_cached(p) for p in path]\n\treturn subpath\n","ensure that named package includes a subpath of path_item ."] (predictor.py:56, main())
[2020-11-20 23:34:09]    INFO >> ["def emails_with_users_and_watches(subject, text_template, html_template, context_vars, users_and_watches, from_email=settings.TIDINGS_FROM_ADDRESS, default_locale=settings.WIKI_DEFAULT_LANGUAGE, **extra_kwargs):\n\t@safe_translation\n\tdef _make_mail(locale, user, watch):\n\t\tcontext_vars['user'] = user\n\t\tcontext_vars['watch'] = watch[0]\n\t\tcontext_vars['watches'] = watch\n\t\tmsg = EmailMultiAlternatives((subject % context_vars), render_email(text_template, context_vars), from_email, [user.email], **extra_kwargs)\n\t\tif html_template:\n\t\t\tmsg.attach_alternative(render_email(html_template, context_vars), 'text\/html')\n\t\treturn msg\n\tfor (user, watch) in users_and_watches:\n\t\tif hasattr(user, 'locale'):\n\t\t\tlocale = user.locale\n\t\telse:\n\t\t\tlocale = default_locale\n\t\t(yield _make_mail(locale, user, watch))\n","return iterable of emailmessages with user and watch values substituted ."] (predictor.py:56, main())
[2020-11-20 23:34:09]    INFO >> ["def action_event_finish(context, values):\n\tconvert_datetimes(values, 'start_time', 'finish_time')\n\tsession = get_session()\n\twith session.begin():\n\t\taction = _action_get_by_request_id(context, values['instance_uuid'], values['request_id'], session)\n\t\tif (not action):\n\t\t\traise exception.InstanceActionNotFound(request_id=values['request_id'], instance_uuid=values['instance_uuid'])\n\t\tevent_ref = model_query(context, models.InstanceActionEvent, session=session).filter_by(action_id=action['id']).filter_by(event=values['event']).first()\n\t\tif (not event_ref):\n\t\t\traise exception.InstanceActionEventNotFound(action_id=action['id'], event=values['event'])\n\t\tevent_ref.update(values)\n\t\tif (values['result'].lower() == 'error'):\n\t\t\taction.update({'message': 'Error'})\n\treturn event_ref\n","finish an event on an instance action ."] (predictor.py:56, main())
[2020-11-20 23:34:09]    INFO >> ["def working_copy(remote_url, path=None, branch='master', update=True, use_sudo=False, user=None):\n\tcommand()\n\tif (path is None):\n\t\tpath = remote_url.split('\/')[(-1)]\n\t\tif path.endswith('.git'):\n\t\t\tpath = path[:(-4)]\n\tif is_dir(path, use_sudo=use_sudo):\n\t\tgit.fetch(path=path, use_sudo=use_sudo, user=user)\n\t\tgit.checkout(path=path, branch=branch, use_sudo=use_sudo, user=user)\n\t\tif update:\n\t\t\tgit.pull(path=path, use_sudo=use_sudo, user=user)\n\telif (not is_dir(path, use_sudo=use_sudo)):\n\t\tgit.clone(remote_url, path=path, use_sudo=use_sudo, user=user)\n\t\tgit.checkout(path=path, branch=branch, use_sudo=use_sudo, user=user)\n\telse:\n\t\traise ValueError('Invalid\tcombination\tof\tparameters.')\n","require a working copy of the repository from the remote_url ."] (predictor.py:56, main())
[2020-11-20 23:34:10]    INFO >> ["def _security_group_get_by_names(context, session, project_id, group_names):\n\tquery = _security_group_get_query(context, session=session, read_deleted='no', join_rules=False).filter_by(project_id=project_id).filter(models.SecurityGroup.name.in_(group_names))\n\tsg_models = query.all()\n\tif (len(sg_models) == len(group_names)):\n\t\treturn sg_models\n\tgroup_names_from_models = [x.name for x in sg_models]\n\tfor group_name in group_names:\n\t\tif (group_name not in group_names_from_models):\n\t\t\traise exception.SecurityGroupNotFoundForProject(project_id=project_id, security_group_id=group_name)\n","get security group models for a project by a list of names ."] (predictor.py:56, main())
[2020-11-20 23:34:10]    INFO >> ["def _margeff_cov_params_count(model, cov_margins, params, exog, count_ind, method, J):\n\tfor i in count_ind:\n\t\texog0 = exog.copy()\n\t\texog0[:, i] -= 1\n\t\tdfdb0 = model._derivative_predict(params, exog0, method)\n\t\texog0[:, i] += 2\n\t\tdfdb1 = model._derivative_predict(params, exog0, method)\n\t\tdfdb = (dfdb1 - dfdb0)\n\t\tif (dfdb.ndim >= 2):\n\t\t\tdfdb = (dfdb.mean(0) \/ 2)\n\t\tif (J > 1):\n\t\t\tK = (dfdb.shape[1] \/ (J - 1))\n\t\t\tcov_margins[i::K, :] = dfdb\n\t\telse:\n\t\t\tcov_margins[i, :] = dfdb\n\treturn cov_margins\n","returns the jacobian for discrete regressors for use in margeff_cov_params ."] (predictor.py:56, main())
[2020-11-20 23:34:11]    INFO >> ["def addToProfileMenu(profileSelection, profileType, repository):\n\tpluginFileNames = skeinforge_profile.getPluginFileNames()\n\tcraftTypeName = skeinforge_profile.getCraftTypeName()\n\tpluginModule = skeinforge_profile.getCraftTypePluginModule()\n\tprofilePluginSettings = settings.getReadRepository(pluginModule.getNewRepository())\n\tfor pluginFileName in pluginFileNames:\n\t\tskeinforge_profile.ProfileTypeMenuRadio().getFromMenuButtonDisplay(profileType, pluginFileName, repository, (craftTypeName == pluginFileName))\n\tfor profileName in profilePluginSettings.profileList.value:\n\t\tskeinforge_profile.ProfileSelectionMenuRadio().getFromMenuButtonDisplay(profileSelection, profileName, repository, (profileName == profilePluginSettings.profileListbox.value))\n","add a profile menu ."] (predictor.py:56, main())
[2020-11-20 23:34:11]    INFO >> ["def get_cls_kwargs(cls, _set=None):\n\ttoplevel = (_set is None)\n\tif toplevel:\n\t\t_set = set()\n\tctr = cls.__dict__.get('__init__', False)\n\thas_init = (ctr and isinstance(ctr, types.FunctionType) and isinstance(ctr.__code__, types.CodeType))\n\tif has_init:\n\t\t(names, has_kw) = inspect_func_args(ctr)\n\t\t_set.update(names)\n\t\tif ((not has_kw) and (not toplevel)):\n\t\t\treturn None\n\tif ((not has_init) or has_kw):\n\t\tfor c in cls.__bases__:\n\t\t\tif (get_cls_kwargs(c, _set) is None):\n\t\t\t\tbreak\n\t_set.discard('self')\n\treturn _set\n","return the full set of inherited kwargs for the given cls ."] (predictor.py:56, main())
[2020-11-20 23:34:12]    INFO >> ["def bulk_replace(values, existing_adapter, new_adapter):\n\tassert isinstance(values, list)\n\tidset = util.IdentitySet\n\texisting_idset = idset((existing_adapter or ()))\n\tconstants = existing_idset.intersection((values or ()))\n\tadditions = idset((values or ())).difference(constants)\n\tremovals = existing_idset.difference(constants)\n\tappender = new_adapter.bulk_appender()\n\tfor member in (values or ()):\n\t\tif (member in additions):\n\t\t\tappender(member)\n\t\telif (member in constants):\n\t\t\tappender(member, _sa_initiator=False)\n\tif existing_adapter:\n\t\tremover = existing_adapter.bulk_remover()\n\t\tfor member in removals:\n\t\t\tremover(member)\n","load a new collection ."] (predictor.py:56, main())
[2020-11-20 23:34:12]    INFO >> ["def ip_network(address, strict=True):\n\ttry:\n\t\treturn IPv4Network(address, strict)\n\texcept (AddressValueError, NetmaskValueError):\n\t\tpass\n\ttry:\n\t\treturn IPv6Network(address, strict)\n\texcept (AddressValueError, NetmaskValueError):\n\t\tpass\n\tif isinstance(address, bytes):\n\t\traise AddressValueError((u'%r\tdoes\tnot\tappear\tto\tbe\tan\tIPv4\tor\tIPv6\tnetwork.\tDid\tyou\tpass\tin\ta\tbytes\t(str\tin\tPython\t2)\tinstead\tof\ta\tunicode\tobject?' % address))\n\traise ValueError((u'%r\tdoes\tnot\tappear\tto\tbe\tan\tIPv4\tor\tIPv6\tnetwork' % address))\n","take an ip string\/int and return an object of the correct type ."] (predictor.py:56, main())
[2020-11-20 23:34:13]    INFO >> ["def assess():\n\tassess_tables()\n\timpact_tables()\n\ttablename = ('%s_%s' % (module, resourcename))\n\ttable = db[tablename]\n\tdef prep(r):\n\t\tif (session.s3.mobile and (r.method == 'create') and r.interactive):\n\t\t\tredirect(URL(f='assess_short_mobile'))\n\t\treturn True\n\tresponse.s3.prep = prep\n\ttabs = [(T('Edit\tDetails'), None), (T('Baselines'), 'baseline'), (T('Impacts'), 'impact'), (T('Summary'), 'summary')]\n\trheader = (lambda r: assess_rheader(r, tabs))\n\treturn s3_rest_controller(rheader=rheader)\n","restful crud controller ."] (predictor.py:56, main())
[2020-11-20 23:34:14]    INFO >> ["def storify(f, *requireds, **defaults):\n\tstor = Storage()\n\tfor k in (requireds + tuple(f.keys())):\n\t\tv = f[k]\n\t\tif isinstance(v, list):\n\t\t\tv = v[(-1)]\n\t\tif hasattr(v, 'value'):\n\t\t\tv = v.value\n\t\tsetattr(stor, k, v)\n\tfor (k, v) in defaults.iteritems():\n\t\tresult = v\n\t\tif hasattr(stor, k):\n\t\t\tresult = stor[k]\n\t\tif ((v == ()) and (not isinstance(result, tuple))):\n\t\t\tresult = (result,)\n\t\tsetattr(stor, k, result)\n\treturn stor\n","creates a storage object from dictionary d ."] (predictor.py:56, main())
[2020-11-20 23:34:15]    INFO >> ["def tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1):\n\ta = ma.asarray(a).ravel()\n\tif (limits is None):\n\t\tn = float(a.count())\n\t\treturn (a.std(axis=axis, ddof=ddof) \/ ma.sqrt(n))\n\tam = trima(a.ravel(), limits, inclusive)\n\tsd = np.sqrt(am.var(axis=axis, ddof=ddof))\n\treturn (sd \/ np.sqrt(am.count()))\n","compute the trimmed standard error of the mean ."] (predictor.py:56, main())
[2020-11-20 23:34:16]    INFO >> ["def get_credential_name(tenant_id, credential_name):\n\tsession = db.get_session()\n\ttry:\n\t\tcred = session.query(l2network_models.Credential).filter_by(tenant_id=tenant_id).filter_by(credential_name=credential_name).one()\n\t\treturn cred\n\texcept exc.NoResultFound:\n\t\traise c_exc.CredentialNameNotFound(credential_name=credential_name, tenant_id=tenant_id)\n","lists the creds for given a cred_name and tenant_id ."] (predictor.py:56, main())
[2020-11-20 23:34:16]    INFO >> ["def getSquareValues(pixelDictionary, x, y):\n\tsquareValues = []\n\tfor xStep in xrange((x - 1), (x + 2)):\n\t\tfor yStep in xrange((y - 1), (y + 2)):\n\t\t\tstepKey = getStepKey(xStep, yStep)\n\t\t\tif (stepKey in pixelDictionary):\n\t\t\t\tsquareValues += pixelDictionary[stepKey]\n\treturn squareValues\n","get a list of the values in a square around the x and y pixel coordinates ."] (predictor.py:56, main())
[2020-11-20 23:34:17]    INFO >> ["def _setHTTPTimeout():\n\tif conf.timeout:\n\t\tinfoMsg = 'setting\tthe\tHTTP\ttimeout'\n\t\tlogger.log(CUSTOM_LOGGING.SYSINFO, infoMsg)\n\t\tconf.timeout = float(conf.timeout)\n\t\tif (conf.timeout < 3.0):\n\t\t\twarnMsg = 'the\tminimum\tHTTP\ttimeout\tis\t3\tseconds,\tpocsuite\twill\tgoing\tto\treset\tit'\n\t\t\tlogger.log(CUSTOM_LOGGING.WARNING, warnMsg)\n\t\t\tconf.timeout = 3.0\n\telse:\n\t\tconf.timeout = 30.0\n\tsocket.setdefaulttimeout(conf.timeout)\n","set the http timeout ."] (predictor.py:56, main())
[2020-11-20 23:34:17]    INFO >> ["def proxy_bypass_environment(host):\n\tno_proxy = (os.environ.get('no_proxy', '') or os.environ.get('NO_PROXY', ''))\n\tif (no_proxy == '*'):\n\t\treturn 1\n\t(hostonly, port) = splitport(host)\n\tfor name in no_proxy.split(','):\n\t\tif (name and (hostonly.endswith(name) or host.endswith(name))):\n\t\t\treturn 1\n\treturn 0\n","test if proxies should not be used for a particular host ."] (predictor.py:56, main())
[2020-11-20 23:34:18]    INFO >> ["def find_instrument_devices(track_or_chain):\n\tinstrument = find_if((lambda d: (d.type == Live.Device.DeviceType.instrument)), track_or_chain.devices)\n\tif (instrument and (not instrument.can_have_drum_pads) and instrument.can_have_chains):\n\t\treturn chain([instrument], *imap(find_instrument_devices, instrument.chains))\n\treturn []\n","returns a list with all instrument rack descendants from a track or chain ."] (predictor.py:56, main())
[2020-11-20 23:34:19]    INFO >> ["def getTransformedOutlineByPath(elementNode, path, yAxisPointingUpward):\n\taroundsFromPath = intercircle.getAroundsFromPath(path, getStrokeRadius(elementNode))\n\treturn getChainMatrixSVGIfNecessary(elementNode, yAxisPointingUpward).getTransformedPaths(aroundsFromPath)\n","get the outline from the path ."] (predictor.py:56, main())
[2020-11-20 23:34:20]    INFO >> ["def test_roberts_diagonal1():\n\timage = np.tri(10, 10, 0)\n\texpected = (~ (np.tri(10, 10, (-1)).astype(bool) | np.tri(10, 10, (-2)).astype(bool).transpose()))\n\texpected = _mask_filter_result(expected, None)\n\tresult = filters.roberts(image).astype(bool)\n\tassert_close(result, expected)\n","roberts filter on a diagonal edge should be a diagonal line ."] (predictor.py:56, main())
[2020-11-20 23:34:20]    INFO >> ["def new_figure_manager(num, *args, **kwargs):\n\t_focus = windowing.FocusManager()\n\tFigureClass = kwargs.pop('FigureClass', Figure)\n\tfigure = FigureClass(*args, **kwargs)\n\twindow = Tk.Tk()\n\tcanvas = FigureCanvasTkAgg(figure, master=window)\n\tfigManager = FigureManagerTkAgg(canvas, num, window)\n\tif matplotlib.is_interactive():\n\t\tfigManager.show()\n\treturn figManager\n","create a new figure manager instance ."] (predictor.py:56, main())
[2020-11-20 23:34:20]    INFO >> ["def fetch_stream_from_url(url, config, data=None, handlers=None):\n\t(return_code, return_message, response) = open_url(url, config, data=data, handlers=handlers)\n\tif (return_code and (return_code == httplib.OK)):\n\t\treturn response\n\telse:\n\t\traise URLFetchError(return_message)\n","returns data retrieved from a url ."] (predictor.py:56, main())
[2020-11-20 23:34:21]    INFO >> ["def net_if_stats():\n\tnames = net_io_counters().keys()\n\tret = {}\n\tfor name in names:\n\t\t(isup, duplex, speed, mtu) = cext_posix.net_if_stats(name)\n\t\tif hasattr(_common, 'NicDuplex'):\n\t\t\tduplex = _common.NicDuplex(duplex)\n\t\tret[name] = _common.snicstats(isup, duplex, speed, mtu)\n\treturn ret\n","get nic stats ."] (predictor.py:56, main())
[2020-11-20 23:34:21]    INFO >> ["def test_nm2__wrong_nn_obj():\n\tratio = 'auto'\n\tnn = 'rnd'\n\tnm2 = NearMiss(ratio=ratio, random_state=RND_SEED, version=VERSION_NEARMISS, return_indices=True, n_neighbors=nn)\n\tassert_raises(ValueError, nm2.fit_sample, X, Y)\n","test either if an error is raised with wrong nn object ."] (predictor.py:56, main())
[2020-11-20 23:34:22]    INFO >> ["def compress_kml(kml):\n\tkmz = cStringIO.StringIO()\n\tzf = zipfile.ZipFile(kmz, 'a', zipfile.ZIP_DEFLATED)\n\tzf.writestr('doc.kml', kml.encode(settings.DEFAULT_CHARSET))\n\tzf.close()\n\tkmz.seek(0)\n\treturn kmz.read()\n","returns compressed kmz from the given kml string ."] (predictor.py:56, main())
[2020-11-20 23:34:23]    INFO >> ["def service_get_all(context, backend_match_level=None, **filters):\n\treturn IMPL.service_get_all(context, backend_match_level, **filters)\n","get all services that match the criteria ."] (predictor.py:56, main())
[2020-11-20 23:34:23]    INFO >> ["def guess_locale_from_lang_windows(lang):\n\tlocale_n = str(LEGAL_VALUES[u'_WINDOWS_LOCALE_GUESSES'].get(lang, None))\n\tif (not is_valid_locale(locale_n)):\n\t\tlocale_n = None\n\treturn locale_n\n","guess a locale ."] (predictor.py:56, main())
[2020-11-20 23:34:23]    INFO >> ["def sitemap_urls_from_robots(robots_text):\n\tfor line in robots_text.splitlines():\n\t\tif line.lstrip().startswith('Sitemap:'):\n\t\t\t(yield line.split(':', 1)[1].strip())\n","return an iterator over all sitemap urls contained in the given robots ."] (predictor.py:56, main())
[2020-11-20 23:34:24]    INFO >> ["def setup_input(pin, pull_mode):\n\timport Adafruit_BBIO.GPIO as GPIO\n\tGPIO.setup(pin, GPIO.IN, (GPIO.PUD_DOWN if (pull_mode == 'DOWN') else GPIO.PUD_UP))\n","setup a gpio as input ."] (predictor.py:56, main())
[2020-11-20 23:34:25]    INFO >> ["def connect_to_region(region_name, **kw_params):\n\tfor region in regions():\n\t\tif (region.name == region_name):\n\t\t\treturn region.connect(**kw_params)\n\treturn None\n","given a valid region name ."] (predictor.py:56, main())
[2020-11-20 23:34:25]    INFO >> ["def convert_DateProperty(model, prop, kwargs):\n\tif (prop.auto_now or prop.auto_now_add):\n\t\treturn None\n\tkwargs.setdefault('format', '%Y-%m-%d')\n\treturn f.DateField(**kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:34:25]    INFO >> ["def _env_is_exposed(env):\n\treturn salt.utils.check_whitelist_blacklist(env, whitelist=__opts__['hgfs_env_whitelist'], blacklist=__opts__['hgfs_env_blacklist'])\n","check if an environment is exposed by comparing it against a whitelist and blacklist ."] (predictor.py:56, main())
[2020-11-20 23:34:26]    INFO >> ["def startLoggingWithObserver(observer, setStdout=1):\n\ttheLogPublisher._startLogging(observer, setStdout)\n\tmsg('Log\topened.')\n","initialize logging to a specified observer ."] (predictor.py:56, main())
[2020-11-20 23:34:26]    INFO >> ["def parsePWDResponse(response):\n\tmatch = re.search('\"(.*)\"', response)\n\tif match:\n\t\treturn match.groups()[0]\n\telse:\n\t\treturn None\n","returns the path from a response to a pwd command ."] (predictor.py:56, main())
[2020-11-20 23:34:26]    INFO >> ["def all_config_files():\n\tuser = user_config_files()\n\tif os.path.exists('setup.cfg'):\n\t\treturn (user + ['setup.cfg'])\n\treturn user\n","return path to any existing user config files ."] (predictor.py:56, main())
[2020-11-20 23:34:28]    INFO >> ["def definite_article(word, gender=MALE):\n\tif (MASCULINE in gender):\n\t\treturn (((PLURAL in gender) and 'los') or 'el')\n\treturn (((PLURAL in gender) and 'las') or 'la')\n","returns the definite article for a given word ."] (predictor.py:56, main())
[2020-11-20 23:34:29]    INFO >> ["def _equalsIgnoreCase(a, b):\n\treturn ((a == b) or (string.lower(a) == string.lower(b)))\n","return true iff a and b have the same lowercase representation ."] (predictor.py:56, main())
[2020-11-20 23:34:29]    INFO >> ["def getNewDerivation(elementNode):\n\treturn evaluate.EmptyObject(elementNode)\n","get new derivation ."] (predictor.py:56, main())
[2020-11-20 23:34:31]    INFO >> ["def test_find_module_2():\n\tnt.assert_is_none(mp.find_module('xmod', []))\n","testing sys ."] (predictor.py:56, main())
[2020-11-20 23:34:31]    INFO >> ["def get_readable_field_data_type(field):\n\treturn (field.description % field.__dict__)\n","returns the description for a given field type ."] (predictor.py:56, main())
[2020-11-20 23:34:31]    INFO >> ["def convert_ByteStringProperty(model, prop, kwargs):\n\treturn get_TextField(kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:34:32]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:34:32]    INFO >> ["def demo_repr_rule_format():\n\tpostag(ruleformat='repr')\n","exemplify repr (see also str and rule ."] (predictor.py:56, main())
[2020-11-20 23:34:32]    INFO >> ["def itervalues(d):\n\treturn getattr(d, _itervalues)()\n","return an iterator over the values of a dictionary ."] (predictor.py:56, main())
[2020-11-20 23:34:33]    INFO >> ["def sendStayAwake():\n\treturn False\n","sends a signal to your system to indicate that the computer is in use and should not sleep ."] (predictor.py:56, main())
[2020-11-20 23:34:34]    INFO >> ["def addSparseEndpointsFromSegment(doubleInfillWidth, endpoints, horizontalSegmentsDictionary, horizontalSegmentsDictionaryKey, infillSolidity, removedEndpoints, segment, solidSurfaceThickness, surroundingXIntersections):\n\tif (infillSolidity > 0.0):\n\t\tif (int(round((round((float(horizontalSegmentsDictionaryKey) * infillSolidity)) \/ infillSolidity))) == horizontalSegmentsDictionaryKey):\n\t\t\tendpoints += segment\n\t\t\treturn\n\t\tif (abs((segment[0].point - segment[1].point)) < doubleInfillWidth):\n\t\t\tendpoints += segment\n\t\t\treturn\n\t\tif (not isSegmentAround(horizontalSegmentsDictionary, (horizontalSegmentsDictionaryKey - 1), segment)):\n\t\t\tendpoints += segment\n\t\t\treturn\n\t\tif (not isSegmentAround(horizontalSegmentsDictionary, (horizontalSegmentsDictionaryKey + 1), segment)):\n\t\t\tendpoints += segment\n\t\t\treturn\n\tif (solidSurfaceThickness == 0):\n\t\tremovedEndpoints += segment\n\t\treturn\n\tif isSegmentCompletelyInAnIntersection(segment, surroundingXIntersections):\n\t\tremovedEndpoints += segment\n\t\treturn\n\tendpoints += segment\n","add sparse endpoints from a segment ."] (predictor.py:56, main())
[2020-11-20 23:34:34]    INFO >> ["def getLargestCenterOutsetLoopFromLoop(loop, radius, thresholdRatio=0.9):\n\tif (radius == 0.0):\n\t\treturn loop\n\tradius = abs(radius)\n\tpoints = getPointsFromLoop(loop, radius, thresholdRatio)\n\tcenters = getCentersFromPoints(points, (globalIntercircleMultiplier * radius))\n\tlargestCenterOutset = None\n\tlargestOutsetArea = (-987654321.0)\n\tfor center in centers:\n\t\toutset = getSimplifiedInsetFromClockwiseLoop(center, radius)\n\t\tif isLargeSameDirection(outset, center, radius):\n\t\t\tif (euclidean.isPathInsideLoop(loop, outset) != euclidean.isWiddershins(loop)):\n\t\t\t\tcenterOutset = CenterOutset(center, outset)\n\t\t\t\toutsetArea = abs(euclidean.getAreaLoop(outset))\n\t\t\t\tif (outsetArea > largestOutsetArea):\n\t\t\t\t\tlargestOutsetArea = outsetArea\n\t\t\t\t\tlargestCenterOutset = centerOutset\n\tif (largestCenterOutset == None):\n\t\treturn None\n\tlargestCenterOutset.center = euclidean.getSimplifiedLoop(largestCenterOutset.center, radius)\n\treturn largestCenterOutset\n","get the largest circle outset loop from the loop ."] (predictor.py:56, main())
[2020-11-20 23:34:34]    INFO >> ["def rename_ep_file(cur_path, new_path, old_path_length=0):\n\tif ((old_path_length == 0) or (old_path_length > len(cur_path))):\n\t\t(cur_file_name, cur_file_ext) = os.path.splitext(cur_path)\n\telse:\n\t\tcur_file_ext = cur_path[old_path_length:]\n\t\tcur_file_name = cur_path[:old_path_length]\n\tif (cur_file_ext[1:] in subtitleExtensions):\n\t\tsublang = os.path.splitext(cur_file_name)[1][1:]\n\t\tfrom sickrage.core.searchers import subtitle_searcher\n\t\tif subtitle_searcher.isValidLanguage(sublang):\n\t\t\tcur_file_ext = ((u'.' + sublang) + cur_file_ext)\n\tnew_path += cur_file_ext\n\tmake_dirs(os.path.dirname(new_path))\n\ttry:\n\t\tsickrage.srCore.srLogger.info((u'Renaming\tfile\tfrom\t%s\tto\t%s' % (cur_path, new_path)))\n\t\tmoveFile(cur_path, new_path)\n\texcept (OSError, IOError) as e:\n\t\tsickrage.srCore.srLogger.error((u'Failed\trenaming\t%s\tto\t%s\t:\t%r' % (cur_path, new_path, e)))\n\t\treturn False\n\tdelete_empty_folders(os.path.dirname(cur_path))\n\treturn True\n","creates all folders needed to move a file to its new location ."] (predictor.py:56, main())
[2020-11-20 23:34:35]    INFO >> ["def insertTwistPortions(derivation, elementNode):\n\tinterpolationDictionary = derivation.interpolationDictionary\n\tinterpolationTwist = Interpolation().getByPrefixX(elementNode, derivation.twistPathDefault, 'twist')\n\tinterpolationDictionary['twist'] = interpolationTwist\n\tfor point in interpolationTwist.path:\n\t\tpoint.y = math.radians(point.y)\n\tremainderPortionDirections = interpolationTwist.portionDirections[1:]\n\tinterpolationTwist.portionDirections = [interpolationTwist.portionDirections[0]]\n\tif (elementNode != None):\n\t\ttwistPrecision = setting.getTwistPrecisionRadians(elementNode)\n\tfor remainderPortionDirection in remainderPortionDirections:\n\t\taddTwistPortions(interpolationTwist, remainderPortionDirection, twistPrecision)\n\t\tinterpolationTwist.portionDirections.append(remainderPortionDirection)\n","insert twist portions and radian the twist ."] (predictor.py:56, main())
[2020-11-20 23:34:36]    INFO >> ["def phone2numeric(phone):\n\tletters = re.compile('[A-PR-Y]', re.I)\n\tchar2number = (lambda m: {'a': '2', 'c': '2', 'b': '2', 'e': '3', 'd': '3', 'g': '4', 'f': '3', 'i': '4', 'h': '4', 'k': '5', 'j': '5', 'm': '6', 'l': '5', 'o': '6', 'n': '6', 'p': '7', 's': '7', 'r': '7', 'u': '8', 't': '8', 'w': '9', 'v': '8', 'y': '9', 'x': '9'}.get(m.group(0).lower()))\n\treturn letters.sub(char2number, phone)\n","converts a phone number with letters into its numeric equivalent ."] (predictor.py:56, main())
[2020-11-20 23:34:36]    INFO >> ["def formatwarning(message, category, filename, lineno, line=None):\n\ts = ('%s:%s:\t%s:\t%s\\n' % (filename, lineno, category.__name__, message))\n\tline = (linecache.getline(filename, lineno) if (line is None) else line)\n\tif line:\n\t\tline = line.strip()\n\t\ts += ('\t\t%s\\n' % line)\n\treturn s\n","function to format a warning the standard way ."] (predictor.py:56, main())
[2020-11-20 23:34:37]    INFO >> ["def originalTextFor(expr, asString=True):\n\tlocMarker = Empty().setParseAction((lambda s, loc, t: loc))\n\tendlocMarker = locMarker.copy()\n\tendlocMarker.callPreparse = False\n\tmatchExpr = ((locMarker('_original_start') + expr) + endlocMarker('_original_end'))\n\tif asString:\n\t\textractText = (lambda s, l, t: s[t._original_start:t._original_end])\n\telse:\n\t\tdef extractText(s, l, t):\n\t\t\tdel t[:]\n\t\t\tt.insert(0, s[t._original_start:t._original_end])\n\t\t\tdel t['_original_start']\n\t\t\tdel t['_original_end']\n\tmatchExpr.setParseAction(extractText)\n\treturn matchExpr\n","helper to return the original ."] (predictor.py:56, main())
[2020-11-20 23:34:38]    INFO >> ["def logout(request, next_page=None, template_name='registration\/logged_out.html', redirect_field_name=REDIRECT_FIELD_NAME, current_app=None, extra_context=None):\n\tauth_logout(request)\n\tif (next_page is not None):\n\t\tnext_page = resolve_url(next_page)\n\tif (redirect_field_name in request.REQUEST):\n\t\tnext_page = request.REQUEST[redirect_field_name]\n\t\tif (not is_safe_url(url=next_page, host=request.get_host())):\n\t\t\tnext_page = request.path\n\tif next_page:\n\t\treturn HttpResponseRedirect(next_page)\n\tcurrent_site = get_current_site(request)\n\tcontext = {'site': current_site, 'site_name': current_site.name, 'title': _('Logged\tout')}\n\tif (extra_context is not None):\n\t\tcontext.update(extra_context)\n\treturn TemplateResponse(request, template_name, context, current_app=current_app)\n","logs out the user and displays you are logged out message ."] (predictor.py:56, main())
[2020-11-20 23:34:38]    INFO >> ["def _formatparam(param, value=None, quote=True):\n\tif ((value is not None) and (len(value) > 0)):\n\t\tif isinstance(value, tuple):\n\t\t\tparam += '*'\n\t\t\tvalue = utils.encode_rfc2231(value[2], value[0], value[1])\n\t\tif (quote or tspecials.search(value)):\n\t\t\treturn ('%s=\"%s\"' % (param, utils.quote(value)))\n\t\telse:\n\t\t\treturn ('%s=%s' % (param, value))\n\telse:\n\t\treturn param\n","convenience function to format and return a key=value pair ."] (predictor.py:56, main())
[2020-11-20 23:34:39]    INFO >> ["def add_qos(tenant_id, qos_name, qos_desc):\n\tLOG.debug(_('add_qos()\tcalled'))\n\tsession = db.get_session()\n\ttry:\n\t\tqos = session.query(network_models_v2.QoS).filter_by(tenant_id=tenant_id).filter_by(qos_name=qos_name).one()\n\t\traise c_exc.QosNameAlreadyExists(qos_name=qos_name, tenant_id=tenant_id)\n\texcept exc.NoResultFound:\n\t\tqos = network_models_v2.QoS(tenant_id, qos_name, qos_desc)\n\t\tsession.add(qos)\n\t\tsession.flush()\n\t\treturn qos\n","adds a qos to tenant association ."] (predictor.py:56, main())
[2020-11-20 23:34:40]    INFO >> ["def _fastq_illumina_convert_fastq_solexa(in_handle, out_handle, alphabet=None):\n\tfrom Bio.SeqIO.QualityIO import solexa_quality_from_phred\n\tmapping = ''.join((([chr(0) for ascii in range(0, 64)] + [chr((64 + int(round(solexa_quality_from_phred(q))))) for q in range(0, (62 + 1))]) + [chr(0) for ascii in range(127, 256)]))\n\tassert (len(mapping) == 256)\n\treturn _fastq_generic(in_handle, out_handle, mapping)\n","fast illumina 1 ."] (predictor.py:56, main())
[2020-11-20 23:34:40]    INFO >> ["def get_yaml_path(builtin_name, runtime=''):\n\tif (_handler_dir is None):\n\t\tset_builtins_dir(DEFAULT_DIR)\n\tavailable_builtins = set(_available_builtins)\n\tif (builtin_name not in available_builtins):\n\t\traise InvalidBuiltinName(('%s\tis\tnot\tthe\tname\tof\ta\tvalid\tbuiltin.\\nAvailable\thandlers\tare:\t%s' % (builtin_name, ',\t'.join(sorted(available_builtins)))))\n\treturn _get_yaml_path(builtin_name, runtime)\n","returns the full path to a yaml file by giving the builtin modules name ."] (predictor.py:56, main())
[2020-11-20 23:34:41]    INFO >> ["def framework_find(fn, executable_path=None, env=None):\n\ttry:\n\t\treturn dyld_find(fn, executable_path=executable_path, env=env)\n\texcept ValueError:\n\t\tpass\n\tfmwk_index = fn.rfind('.framework')\n\tif (fmwk_index == (-1)):\n\t\tfmwk_index = len(fn)\n\t\tfn += '.framework'\n\tfn = os.path.join(fn, os.path.basename(fn[:fmwk_index]))\n\treturn dyld_find(fn, executable_path=executable_path, env=env)\n","find a framework using dyld semantics in a very loose manner ."] (predictor.py:56, main())
[2020-11-20 23:34:41]    INFO >> ["def get_server_certificate(addr, ssl_version=PROTOCOL_SSLv23, ca_certs=None):\n\t(host, port) = addr\n\tif (ca_certs is not None):\n\t\tcert_reqs = CERT_REQUIRED\n\telse:\n\t\tcert_reqs = CERT_NONE\n\tcontext = _create_stdlib_context(ssl_version, cert_reqs=cert_reqs, cafile=ca_certs)\n\twith closing(create_connection(addr)) as sock:\n\t\twith closing(context.wrap_socket(sock)) as sslsock:\n\t\t\tdercert = sslsock.getpeercert(True)\n\treturn DER_cert_to_PEM_cert(dercert)\n","retrieve the certificate from the server at the specified address ."] (predictor.py:56, main())
[2020-11-20 23:34:42]    INFO >> ["def getChainTextFromProcedures(fileName, procedures, text):\n\tlastProcedureTime = time.time()\n\tfor procedure in procedures:\n\t\tcraftModule = getCraftModule(procedure)\n\t\tif (craftModule != None):\n\t\t\ttext = craftModule.getCraftedText(fileName, text)\n\t\t\tif gcodec.isProcedureDone(text, procedure):\n\t\t\t\tprint ('%s\tprocedure\ttook\t%s.' % (procedure.capitalize(), euclidean.getDurationString((time.time() - lastProcedureTime))))\n\t\t\t\tlastProcedureTime = time.time()\n\treturn text\n","get a crafted shape file from a list of procedures ."] (predictor.py:56, main())
[2020-11-20 23:34:42]    INFO >> ["def encode_labels(labels, nclass=5):\n\tY = np.zeros((len(labels), nclass)).astype('float32')\n\tfor (j, y) in enumerate(labels):\n\t\tfor i in range(nclass):\n\t\t\tif ((i + 1) == (np.floor(y) + 1)):\n\t\t\t\tY[(j, i)] = (y - np.floor(y))\n\t\t\tif ((i + 1) == np.floor(y)):\n\t\t\t\tY[(j, i)] = ((np.floor(y) - y) + 1)\n\treturn Y\n","label encoding from tree lstm paper ."] (predictor.py:56, main())
[2020-11-20 23:34:42]    INFO >> ["def _api_switch(name, output, kwargs):\n\tvalue = kwargs.get('value')\n\tvalue2 = kwargs.get('value2')\n\tif (value and value2):\n\t\t(pos, prio) = NzbQueue.do.switch(value, value2)\n\t\tif (output not in ('xml', 'json')):\n\t\t\treturn report(output, data=(pos, prio))\n\t\telse:\n\t\t\treturn report(output, keyword='result', data={'position': pos, 'priority': prio})\n\telse:\n\t\treturn report(output, _MSG_NO_VALUE2)\n","api: accepts output ."] (predictor.py:56, main())
[2020-11-20 23:34:43]    INFO >> ["def identify_names(code):\n\tfinder = NameFinder()\n\ttry:\n\t\tfinder.visit(ast.parse(code))\n\texcept SyntaxError:\n\t\treturn {}\n\texample_code_obj = {}\n\tfor (name, full_name) in finder.get_mapping():\n\t\tsplitted = full_name.rsplit('.', 1)\n\t\tif (len(splitted) == 1):\n\t\t\tcontinue\n\t\t(module, attribute) = splitted\n\t\tmodule_short = get_short_module_name(module, attribute)\n\t\tcobj = {'name': attribute, 'module': module, 'module_short': module_short}\n\t\texample_code_obj[name] = cobj\n\treturn example_code_obj\n","builds a codeobj summary by identifying and resolving used names ."] (predictor.py:56, main())
[2020-11-20 23:34:43]    INFO >> ["def set_vif_host_backend_802qbg_config(conf, devname, managerid, typeid, typeidversion, instanceid, tapname=None):\n\tconf.net_type = 'direct'\n\tconf.source_dev = devname\n\tconf.source_mode = 'vepa'\n\tconf.vporttype = '802.1Qbg'\n\tconf.add_vport_param('managerid', managerid)\n\tconf.add_vport_param('typeid', typeid)\n\tconf.add_vport_param('typeidversion', typeidversion)\n\tconf.add_vport_param('instanceid', instanceid)\n\tif tapname:\n\t\tconf.target_dev = tapname\n","populate a libvirtconfigguestinterface instance with host backend details for an 802 ."] (predictor.py:56, main())
[2020-11-20 23:34:44]    INFO >> ["def _should_use_proxy(url, no_proxy=None):\n\tif (no_proxy is None):\n\t\tno_proxy_effective = os.environ.get('no_proxy', '')\n\telse:\n\t\tno_proxy_effective = no_proxy\n\turlObj = urlparse_.urlparse(_url_as_string(url))\n\tfor np in [h.strip() for h in no_proxy_effective.split(',')]:\n\t\tif (urlObj.hostname == np):\n\t\t\treturn False\n\treturn True\n","determines whether a proxy should be used to open a connection to the specified url ."] (predictor.py:56, main())
[2020-11-20 23:34:44]    INFO >> ["def coordinate_from_string(coord_string):\n\tmatch = COORD_RE.match(coord_string.upper())\n\tif (not match):\n\t\tmsg = ('Invalid\tcell\tcoordinates\t(%s)' % coord_string)\n\t\traise CellCoordinatesException(msg)\n\t(column, row) = match.groups()\n\treturn (column, int(row))\n","convert a coordinate string like b12 to a tuple ."] (predictor.py:56, main())
[2020-11-20 23:34:45]    INFO >> ["def send_html_mail_jinja(subject, html_template, text_template, context, *args, **kwargs):\n\twith no_jinja_autoescape():\n\t\thtml_template = get_env().get_template(html_template)\n\t\ttext_template = get_env().get_template(text_template)\n\tmsg = send_mail(subject, text_template.render(context), html_message=html_template.render(context), *args, **kwargs)\n\treturn msg\n","sends html mail using a jinja template with autoescaping turned off ."] (predictor.py:56, main())
[2020-11-20 23:34:45]    INFO >> ["def groups_for_user(environ, username):\n\tUserModel = auth.get_user_model()\n\tdb.reset_queries()\n\ttry:\n\t\ttry:\n\t\t\tuser = UserModel._default_manager.get_by_natural_key(username)\n\t\texcept UserModel.DoesNotExist:\n\t\t\treturn []\n\t\tif (not user.is_active):\n\t\t\treturn []\n\t\treturn [force_bytes(group.name) for group in user.groups.all()]\n\tfinally:\n\t\tdb.close_old_connections()\n","authorizes a user based on groups ."] (predictor.py:56, main())
[2020-11-20 23:34:46]    INFO >> ["def IndexYamlForQuery(kind, ancestor, props):\n\tserialized_yaml = []\n\tserialized_yaml.append(('-\tkind:\t%s' % kind))\n\tif ancestor:\n\t\tserialized_yaml.append('\t\tancestor:\tyes')\n\tif props:\n\t\tserialized_yaml.append('\t\tproperties:')\n\t\tfor (name, direction) in props:\n\t\t\tserialized_yaml.append(('\t\t-\tname:\t%s' % name))\n\t\t\tif (direction == DESCENDING):\n\t\t\t\tserialized_yaml.append('\t\t\t\tdirection:\tdesc')\n\treturn '\\n'.join(serialized_yaml)\n","return the composite index definition yaml needed for a query ."] (predictor.py:56, main())
[2020-11-20 23:34:46]    INFO >> ["def time(value, arg=None):\n\tfrom google.appengine._internal.django.utils import dateformat\n\tif (value in (None, u'')):\n\t\treturn u''\n\tif (arg is None):\n\t\targ = settings.TIME_FORMAT\n\ttry:\n\t\treturn formats.time_format(value, arg)\n\texcept AttributeError:\n\t\ttry:\n\t\t\treturn dateformat.time_format(value, arg)\n\t\texcept AttributeError:\n\t\t\treturn ''\n","formats a time according to the given format ."] (predictor.py:56, main())
[2020-11-20 23:34:47]    INFO >> ["def vol_usage_update(context, id, rd_req, rd_bytes, wr_req, wr_bytes, instance_id, last_refreshed=None, update_totals=False):\n\treturn IMPL.vol_usage_update(context, id, rd_req, rd_bytes, wr_req, wr_bytes, instance_id, last_refreshed=last_refreshed, update_totals=update_totals)\n","update cached volume usage for a volume creates new record if needed ."] (predictor.py:56, main())
[2020-11-20 23:34:47]    INFO >> ["def remove_qos(tenant_id, qos_id):\n\tsession = db.get_session()\n\ttry:\n\t\tqos = session.query(l2network_models.QoS).filter_by(tenant_id=tenant_id).filter_by(qos_id=qos_id).one()\n\t\tsession.delete(qos)\n\t\tsession.flush()\n\t\treturn qos\n\texcept exc.NoResultFound:\n\t\tpass\n","removes a qos to tenant association ."] (predictor.py:56, main())
[2020-11-20 23:34:48]    INFO >> ["def _extract_labels(filename, num_labels):\n\tprint('Extracting\tlabels\tfrom:\t', filename)\n\twith gzip.open(filename) as bytestream:\n\t\tbytestream.read(8)\n\t\tbuf = bytestream.read((1 * num_labels))\n\t\tlabels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n\treturn labels\n","extract the labels into a vector of int64 label ids ."] (predictor.py:56, main())
[2020-11-20 23:34:48]    INFO >> ["def generate_credits(component, start_date, end_date):\n\tresult = []\n\tfor translation in component.translation_set.all():\n\t\tauthors = Change.objects.authors_list(translation, (start_date, end_date))\n\t\tif (not authors):\n\t\t\tcontinue\n\t\tresult.append({translation.language.name: sorted(set(authors))})\n\treturn result\n","generates credits data for given component ."] (predictor.py:56, main())
[2020-11-20 23:34:48]    INFO >> ["def dup_trial_division(f, factors, K):\n\tresult = []\n\tfor factor in factors:\n\t\tk = 0\n\t\twhile True:\n\t\t\t(q, r) = dup_div(f, factor, K)\n\t\t\tif (not r):\n\t\t\t\t(f, k) = (q, (k + 1))\n\t\t\telse:\n\t\t\t\tbreak\n\t\tresult.append((factor, k))\n\treturn _sort_factors(result)\n","determine multiplicities of factors using trial division ."] (predictor.py:56, main())
[2020-11-20 23:34:49]    INFO >> ["def chexor(old, name, timestamp):\n\tif (name is None):\n\t\traise Exception('name\tis\tNone!')\n\tnew = hashlib.md5(('%s-%s' % (name, timestamp)).encode('utf8')).hexdigest()\n\treturn ('%032x' % (int(old, 16) ^ int(new, 16)))\n","each entry in the account and container databases is xored by the 128-bit hash on insert or delete ."] (predictor.py:56, main())
[2020-11-20 23:34:49]    INFO >> ["def libvlc_audio_get_track_description(p_mi):\n\tf = (_Cfunctions.get('libvlc_audio_get_track_description', None) or _Cfunction('libvlc_audio_get_track_description', ((1,),), None, ctypes.POINTER(TrackDescription), MediaPlayer))\n\treturn f(p_mi)\n","get the description of available audio tracks ."] (predictor.py:56, main())
[2020-11-20 23:34:51]    INFO >> ["def vary_on_headers(*headers):\n\tdef decorator(func):\n\t\tdef inner_func(*args, **kwargs):\n\t\t\tresponse = func(*args, **kwargs)\n\t\t\tpatch_vary_headers(response, headers)\n\t\t\treturn response\n\t\treturn wraps(func, assigned=available_attrs(func))(inner_func)\n\treturn decorator\n","a view decorator that adds the specified headers to the vary header of the response ."] (predictor.py:56, main())
[2020-11-20 23:34:51]    INFO >> ["def add_organization_course(organization_data, course_id):\n\tif (not organizations_enabled()):\n\t\treturn None\n\tfrom organizations import api as organizations_api\n\treturn organizations_api.add_organization_course(organization_data=organization_data, course_key=course_id)\n","client api operation adapter\/wrapper ."] (predictor.py:56, main())
[2020-11-20 23:34:51]    INFO >> ["def GetInvisibleSpecialPropertyNames():\n\tinvisible_names = []\n\tfor (name, value) in _SPECIAL_PROPERTY_MAP.items():\n\t\t(is_visible, _, _) = value\n\t\tif (not is_visible):\n\t\t\tinvisible_names.append(name)\n\treturn invisible_names\n","gets the names of all non user-visible special properties ."] (predictor.py:56, main())
[2020-11-20 23:34:52]    INFO >> ["def get_default_timezone():\n\tglobal _localtime\n\tif (_localtime is None):\n\t\tif (isinstance(settings.TIME_ZONE, six.string_types) and (pytz is not None)):\n\t\t\t_localtime = pytz.timezone(settings.TIME_ZONE)\n\t\telse:\n\t\t\t_localtime = LocalTimezone()\n\treturn _localtime\n","returns the default time zone as a tzinfo instance ."] (predictor.py:56, main())
[2020-11-20 23:34:52]    INFO >> ["def test_nm3_sample_wt_fit():\n\tratio = 'auto'\n\tnm3 = NearMiss(ratio=ratio, random_state=RND_SEED, version=VERSION_NEARMISS)\n\tassert_raises(RuntimeError, nm3.sample, X, Y)\n","test either if an error is raised when sample is called before fitting ."] (predictor.py:56, main())
[2020-11-20 23:34:52]    INFO >> ["def custom_check(cmd, ignore_retcode=False):\n\tp = custom_popen(cmd)\n\t(out, _) = p.communicate()\n\tif (p.returncode and (not ignore_retcode)):\n\t\traise RarExecError('Check-run\tfailed')\n\treturn out\n","run command ."] (predictor.py:56, main())
[2020-11-20 23:34:53]    INFO >> ["def check_message(keywords, message):\n\t(exc_type, exc_value, exc_traceback) = sys.exc_info()\n\tif set(str(exc_value).split('\t')).issuperset(set(keywords)):\n\t\texc_value._safe_message = message\n\t\traise\n","checks an exception for given keywords and raises a new actionerror with the desired message if the keywords are found ."] (predictor.py:56, main())
[2020-11-20 23:34:53]    INFO >> ["def test_iht_init():\n\tratio = 'auto'\n\tiht = InstanceHardnessThreshold(ESTIMATOR, ratio=ratio, random_state=RND_SEED)\n\tassert_equal(iht.ratio, ratio)\n\tassert_equal(iht.random_state, RND_SEED)\n","test the initialisation of the object ."] (predictor.py:56, main())
[2020-11-20 23:34:53]    INFO >> ["def make_dist(name, version, **kwargs):\n\tsummary = kwargs.pop(u'summary', u'Placeholder\tfor\tsummary')\n\tmd = Metadata(**kwargs)\n\tmd.name = name\n\tmd.version = version\n\tmd.summary = (summary or u'Placeholder\tfor\tsummary')\n\treturn Distribution(md)\n","a convenience method for making a dist given just a name and version ."] (predictor.py:56, main())
[2020-11-20 23:34:54]    INFO >> ["def test_nearmiss_wrong_version():\n\tversion = 1000\n\tnm1 = NearMiss(version=version, random_state=RND_SEED)\n\tassert_raises(ValueError, nm1.fit_sample, X, Y)\n","test either if an error is raised when the version is unknown ."] (predictor.py:56, main())
[2020-11-20 23:34:54]    INFO >> ["def get_auth_from_url(url):\n\tparsed = urlparse(url)\n\ttry:\n\t\tauth = (unquote(parsed.username), unquote(parsed.password))\n\texcept (AttributeError, TypeError):\n\t\tauth = ('', '')\n\treturn auth\n","given a url with authentication components ."] (predictor.py:56, main())
[2020-11-20 23:34:55]    INFO >> ["def get_paths(scheme=_get_default_scheme(), vars=None, expand=True):\n\t_ensure_cfg_read()\n\tif expand:\n\t\treturn _expand_vars(scheme, vars)\n\telse:\n\t\treturn dict(_SCHEMES.items(scheme))\n","return a mapping containing an install scheme ."] (predictor.py:56, main())
[2020-11-20 23:34:55]    INFO >> ["def xpath_tokenizer(p):\n\tout = []\n\tfor (op, tag) in ElementPath.xpath_tokenizer(p):\n\t\tout.append((op or tag))\n\treturn out\n","test the xpath tokenizer ."] (predictor.py:56, main())
[2020-11-20 23:34:56]    INFO >> ["def getPluginsDirectoryPath():\n\treturn archive.getAbsoluteFolderPath(os.path.dirname(__file__), os.path.join('skeinforge_plugins', 'meta_plugins'))\n","get the plugins directory path ."] (predictor.py:56, main())
[2020-11-20 23:34:56]    INFO >> ["def file_upload_echo(request):\n\tr = {k: f.name for (k, f) in request.FILES.items()}\n\treturn HttpResponse(json.dumps(r))\n","simple view to echo back info about uploaded files for tests ."] (predictor.py:56, main())
[2020-11-20 23:34:56]    INFO >> ["def image_tag_delete(context, image_id, value, session=None):\n\t_check_image_id(image_id)\n\tsession = (session or get_session())\n\tquery = session.query(models.ImageTag).filter_by(image_id=image_id).filter_by(value=value).filter_by(deleted=False)\n\ttry:\n\t\ttag_ref = query.one()\n\texcept sa_orm.exc.NoResultFound:\n\t\traise exception.NotFound()\n\ttag_ref.delete(session=session)\n","delete an image tag ."] (predictor.py:56, main())
[2020-11-20 23:34:57]    INFO >> ["def get_language_bidi():\n\tfrom django.conf import settings\n\tbase_lang = get_language().split(u'-')[0]\n\treturn (base_lang in settings.LANGUAGES_BIDI)\n","returns selected languages bidi layout ."] (predictor.py:56, main())
[2020-11-20 23:34:57]    INFO >> ["def test_roc_auc_one_vs_one():\n\tskip_if_no_sklearn()\n\ttrainer = yaml_parse.load(test_yaml_ovo)\n\ttrainer.main_loop()\n","test one vs ."] (predictor.py:56, main())
[2020-11-20 23:34:57]    INFO >> ["def render_to_kmz(*args, **kwargs):\n\treturn HttpResponse(compress_kml(loader.render_to_string(*args, **kwargs)), mimetype='application\/vnd.google-earth.kmz')\n","compresses the kml content and returns as kmz ."] (predictor.py:56, main())
[2020-11-20 23:34:58]    INFO >> ["def assert_server_running(server):\n\tif (server.poll() is not None):\n\t\traise RuntimeError('Server\tdied\tunexpectedly!')\n","get the exit code of the server ."] (predictor.py:56, main())
[2020-11-20 23:34:58]    INFO >> ["def validate_argmin_with_skipna(skipna, args, kwargs):\n\t(skipna, args) = process_skipna(skipna, args)\n\tvalidate_argmin(args, kwargs)\n\treturn skipna\n","if series ."] (predictor.py:56, main())
[2020-11-20 23:34:58]    INFO >> ["def skipUnlessDBFeature(feature):\n\treturn _deferredSkip((lambda : (not getattr(connection.features, feature))), (u\"Database\tdoesn't\tsupport\tfeature\t%s\" % feature))\n","skip a test unless a database has the named feature ."] (predictor.py:56, main())
[2020-11-20 23:34:58]    INFO >> ["def certificate_get_all_by_project(context, project_id):\n\treturn IMPL.certificate_get_all_by_project(context, project_id)\n","get all certificates for a project ."] (predictor.py:56, main())
[2020-11-20 23:34:59]    INFO >> ["def urlquote_plus(url, safe=''):\n\treturn force_unicode(urllib.quote_plus(smart_str(url), safe))\n","a version of pythons urllib ."] (predictor.py:56, main())
[2020-11-20 23:34:59]    INFO >> ["def _make_entity_from_pb(annotations):\n\treturn [EntityAnnotation.from_pb(annotation) for annotation in annotations]\n","create an entity from a protobuf response ."] (predictor.py:56, main())
[2020-11-20 23:35:00]    INFO >> ["def test_resize_icon_enlarge():\n\tresize_size = [1000]\n\tfinal_size = [(339, 128)]\n\t_uploader(resize_size, final_size)\n","image stays the same ."] (predictor.py:56, main())
[2020-11-20 23:35:01]    INFO >> ["def idd_sfrm(l, n, w, x):\n\treturn _id.idd_sfrm(l, n, w, x)\n","transform real vector via a composition of rokhlins random transform ."] (predictor.py:56, main())
[2020-11-20 23:35:01]    INFO >> ["def isCocoaTk():\n\tassert (_tk_type is not None)\n\treturn (_tk_type == 'cocoa')\n","returns true if idle is using a cocoa aqua tk ."] (predictor.py:56, main())
[2020-11-20 23:35:02]    INFO >> ["def extra_padding_x(original_size, padding):\n\treturn _resize(original_size, 0, padding=padding)\n","reduce the width of original_size by padding ."] (predictor.py:56, main())
[2020-11-20 23:35:02]    INFO >> ["def convert_PhoneNumberProperty(model, prop, kwargs):\n\treturn get_TextField(kwargs)\n","returns a form field for a db ."] (predictor.py:56, main())
[2020-11-20 23:35:02]    INFO >> ["def instance_get(context, instance_id, columns_to_join=None):\n\treturn IMPL.instance_get(context, instance_id, columns_to_join=columns_to_join)\n","get an instance or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:35:04]    INFO >> ["def processXMLElement(xmlElement):\n\tgroup.processShape(Difference, xmlElement)\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:35:04]    INFO >> ["def inspect_response(response, spider):\n\tShell(spider.crawler).start(response=response)\n","open a shell to inspect the given response ."] (predictor.py:56, main())
[2020-11-20 23:35:04]    INFO >> ["@register.filter('escapejs')\n@stringfilter\ndef escapejs_filter(value):\n\treturn escapejs(value)\n","hex encodes characters for use in javascript strings ."] (predictor.py:56, main())
[2020-11-20 23:35:06]    INFO >> ["def transferClosestFillLoop(extrusionHalfWidth, oldOrderedLocation, remainingFillLoops, skein):\n\tclosestDistance = 9.876543219876543e+17\n\tclosestFillLoop = None\n\tfor remainingFillLoop in remainingFillLoops:\n\t\tdistance = getClosestDistanceIndexToLine(oldOrderedLocation.dropAxis(), remainingFillLoop).distance\n\t\tif (distance < closestDistance):\n\t\t\tclosestDistance = distance\n\t\t\tclosestFillLoop = remainingFillLoop\n\tnewClosestFillLoop = getLoopInsideContainingLoop(closestFillLoop, remainingFillLoops)\n\twhile (newClosestFillLoop != None):\n\t\tclosestFillLoop = newClosestFillLoop\n\t\tnewClosestFillLoop = getLoopInsideContainingLoop(closestFillLoop, remainingFillLoops)\n\tremainingFillLoops.remove(closestFillLoop)\n\taddToThreadsFromLoop(extrusionHalfWidth, 'loop', closestFillLoop[:], oldOrderedLocation, skein)\n","transfer the closest remaining fill loop ."] (predictor.py:56, main())
[2020-11-20 23:35:06]    INFO >> ["def test_run_json_dump(mocker, mock_ensure_success, mock_user_config, template_name, context, replay_test_dir, replay_file):\n\tspy_get_replay_file = mocker.spy(replay, 'get_file_name')\n\tmock_json_dump = mocker.patch('json.dump', side_effect=json.dump)\n\treplay.dump(replay_test_dir, template_name, context)\n\tassert (not mock_user_config.called)\n\tmock_ensure_success.assert_called_once_with(replay_test_dir)\n\tspy_get_replay_file.assert_called_once_with(replay_test_dir, template_name)\n\tassert (mock_json_dump.call_count == 1)\n\t((dumped_context, outfile_handler), kwargs) = mock_json_dump.call_args\n\tassert (outfile_handler.name == replay_file)\n\tassert (dumped_context == context)\n","test that replay ."] (predictor.py:56, main())
[2020-11-20 23:35:07]    INFO >> ["def user_data_dir(appname, roaming=False):\n\tif WINDOWS:\n\t\tconst = ((roaming and 'CSIDL_APPDATA') or 'CSIDL_LOCAL_APPDATA')\n\t\tpath = os.path.join(os.path.normpath(_get_win_folder(const)), appname)\n\telif (sys.platform == 'darwin'):\n\t\tpath = os.path.join(expanduser('~\/Library\/Application\tSupport\/'), appname)\n\telse:\n\t\tpath = os.path.join(os.getenv('XDG_DATA_HOME', expanduser('~\/.local\/share')), appname)\n\treturn path\n","return full path to the user-specific data dir for this application ."] (predictor.py:56, main())
[2020-11-20 23:35:08]    INFO >> ["def add_lazy_relation(cls, field, relation, operation):\n\tif (relation == RECURSIVE_RELATIONSHIP_CONSTANT):\n\t\tapp_label = cls._meta.app_label\n\t\tmodel_name = cls.__name__\n\telse:\n\t\ttry:\n\t\t\t(app_label, model_name) = relation.split('.')\n\t\texcept ValueError:\n\t\t\tapp_label = cls._meta.app_label\n\t\t\tmodel_name = relation\n\t\texcept AttributeError:\n\t\t\tapp_label = relation._meta.app_label\n\t\t\tmodel_name = relation._meta.object_name\n\tmodel = get_model(app_label, model_name, seed_cache=False, only_installed=False)\n\tif model:\n\t\toperation(field, model, cls)\n\telse:\n\t\tkey = (app_label, model_name)\n\t\tvalue = (cls, field, operation)\n\t\tpending_lookups.setdefault(key, []).append(value)\n","adds a lookup on cls when a related field is defined using a string ."] (predictor.py:56, main())
[2020-11-20 23:35:08]    INFO >> ["def parseParam(line):\n\tif (line == ''):\n\t\treturn (None, '')\n\telif (line[0] != '\"'):\n\t\tmode = 1\n\telse:\n\t\tmode = 2\n\tres = ''\n\tio = StringIO(line)\n\tif (mode == 2):\n\t\tio.read(1)\n\twhile 1:\n\t\ta = io.read(1)\n\t\tif (a == '\"'):\n\t\t\tif (mode == 2):\n\t\t\t\tio.read(1)\n\t\t\t\treturn (res, io.read())\n\t\telif (a == '\\\\'):\n\t\t\ta = io.read(1)\n\t\t\tif (a == ''):\n\t\t\t\treturn (None, line)\n\t\telif (a == ''):\n\t\t\tif (mode == 1):\n\t\t\t\treturn (res, io.read())\n\t\t\telse:\n\t\t\t\treturn (None, line)\n\t\telif (a == '\t'):\n\t\t\tif (mode == 1):\n\t\t\t\treturn (res, io.read())\n\t\tres += a\n","chew one dqstring or atom from beginning of line and return ."] (predictor.py:56, main())
[2020-11-20 23:35:09]    INFO >> ["def run_migrations_online():\n\tconnectable = settings.engine\n\twith connectable.connect() as connection:\n\t\tcontext.configure(connection=connection, target_metadata=target_metadata, compare_type=COMPARE_TYPE)\n\t\twith context.begin_transaction():\n\t\t\tcontext.run_migrations()\n","run migrations in online mode ."] (predictor.py:56, main())
[2020-11-20 23:35:09]    INFO >> ["def forbid_multi_line_headers(name, val, encoding):\n\tencoding = (encoding or settings.DEFAULT_CHARSET)\n\tval = force_text(val)\n\tif (('\\n' in val) or ('\\r' in val)):\n\t\traise BadHeaderError((\"Header\tvalues\tcan't\tcontain\tnewlines\t(got\t%r\tfor\theader\t%r)\" % (val, name)))\n\ttry:\n\t\tval.encode('ascii')\n\texcept UnicodeEncodeError:\n\t\tif (name.lower() in ADDRESS_HEADERS):\n\t\t\tval = ',\t'.join((sanitize_address(addr, encoding) for addr in getaddresses((val,))))\n\t\telse:\n\t\t\tval = Header(val, encoding).encode()\n\telse:\n\t\tif (name.lower() == 'subject'):\n\t\t\tval = Header(val).encode()\n\treturn (name, val)\n","forbids multi-line headers ."] (predictor.py:56, main())
[2020-11-20 23:35:10]    INFO >> ["def apply_nms(all_boxes, thresh):\n\tnum_classes = len(all_boxes)\n\tnum_images = len(all_boxes[0])\n\tnms_boxes = [[[] for _ in xrange(num_images)] for _ in xrange(num_classes)]\n\tfor cls_ind in xrange(num_classes):\n\t\tfor im_ind in xrange(num_images):\n\t\t\tdets = all_boxes[cls_ind][im_ind]\n\t\t\tif (dets == []):\n\t\t\t\tcontinue\n\t\t\tkeep = nms(dets, thresh)\n\t\t\tif (len(keep) == 0):\n\t\t\t\tcontinue\n\t\t\tnms_boxes[cls_ind][im_ind] = dets[keep, :].copy()\n\treturn nms_boxes\n","apply non-maximum suppression to all predicted boxes output by the test_net method ."] (predictor.py:56, main())
[2020-11-20 23:35:10]    INFO >> ["def _suffix_rules(token, tag='NN'):\n\tif isinstance(token, (list, tuple)):\n\t\t(token, tag) = token\n\tif token.endswith('ing'):\n\t\ttag = 'VBG'\n\tif token.endswith('ly'):\n\t\ttag = 'RB'\n\tif (token.endswith('s') and (not token.endswith(('is', 'ous', 'ss')))):\n\t\ttag = 'NNS'\n\tif (token.endswith(('able', 'al', 'ful', 'ible', 'ient', 'ish', 'ive', 'less', 'tic', 'ous')) or ('-' in token)):\n\t\ttag = 'JJ'\n\tif token.endswith('ed'):\n\t\ttag = 'VBN'\n\tif token.endswith(('ate', 'ify', 'ise', 'ize')):\n\t\ttag = 'VBP'\n\treturn [token, tag]\n","default morphological tagging rules for english ."] (predictor.py:56, main())
[2020-11-20 23:35:11]    INFO >> ["def test_rgb_to_hsl_part_0():\n\tassert (rgb_to_hsl(255, 0, 0) == (0, 100, 50))\n\tassert (rgb_to_hsl(255, 255, 0) == (60, 100, 50))\n\tassert (rgb_to_hsl(0, 255, 0) == (120, 100, 50))\n\tassert (rgb_to_hsl(0, 255, 255) == (180, 100, 50))\n\tassert (rgb_to_hsl(0, 0, 255) == (240, 100, 50))\n\tassert (rgb_to_hsl(255, 0, 255) == (300, 100, 50))\n","test rgb to hsl color function ."] (predictor.py:56, main())
[2020-11-20 23:35:11]    INFO >> ["def list_nodes(call=None):\n\tif (call == 'action'):\n\t\traise SaltCloudSystemExit('The\tlist_nodes\tfunction\tmust\tbe\tcalled\twith\t-f\tor\t--function.')\n\tnodes = list_nodes_full()\n\tret = {}\n\tfor (instance_id, full_node) in nodes.items():\n\t\tret[instance_id] = {'id': full_node['id'], 'image': full_node['image'], 'size': full_node['size'], 'state': full_node['state'], 'public_ips': full_node['public_ips'], 'private_ips': full_node['private_ips']}\n\treturn ret\n","return a list of the vms that are on the provider ."] (predictor.py:56, main())
[2020-11-20 23:35:13]    INFO >> ["def fetch_from_url_to_file(url, config, output_file, data=None, handlers=None):\n\t(return_code, return_message, response) = open_url(url, config, data=data, handlers=handlers)\n\tif (return_code == http_client_.OK):\n\t\treturn_data = response.read()\n\t\tresponse.close()\n\t\toutfile = open(output_file, 'w')\n\t\toutfile.write(return_data)\n\t\toutfile.close()\n\treturn (return_code, return_message, (return_code == http_client_.OK))\n","writes data retrieved from a url to a file ."] (predictor.py:56, main())
[2020-11-20 23:35:13]    INFO >> ["def _spectrogram(x, fs=1.0, window=('tukey', 0.25), nperseg=256, noverlap=None, nfft=None, detrend='constant', return_onesided=True, scaling='density', axis=(-1), mode='psd'):\n\tif (noverlap is None):\n\t\tnoverlap = (nperseg \/\/ 8)\n\t(freqs, time, Pxy) = _spectral_helper(x, x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode=mode)\n\treturn (freqs, time, Pxy)\n","compute a spectrogram with consecutive fourier transforms ."] (predictor.py:56, main())
[2020-11-20 23:35:13]    INFO >> ["def address_in_network(ip, net):\n\tipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n\t(netaddr, bits) = net.split('\/')\n\tnetmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n\tnetwork = (struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask)\n\treturn ((ipaddr & netmask) == (network & netmask))\n","this function allows you to check if on ip belongs to a network subnet example: returns true if ip = 192 ."] (predictor.py:56, main())
[2020-11-20 23:35:14]    INFO >> ["def _shared_login(request):\n\tcsession = request.session\n\tplayer = request.user\n\tsesslogin = csession.get('logged_in', None)\n\tif (csession.session_key is None):\n\t\tcsession.save()\n\telif player.is_authenticated():\n\t\tif (not sesslogin):\n\t\t\tcsession['logged_in'] = player.id\n\telif sesslogin:\n\t\tplayer = PlayerDB.objects.get(id=sesslogin)\n\t\ttry:\n\t\t\tplayer = authenticate(autologin=player)\n\t\t\tlogin(request, player)\n\t\texcept AttributeError:\n\t\t\tlogger.log_trace()\n","handle the shared login between website and webclient ."] (predictor.py:56, main())
[2020-11-20 23:35:15]    INFO >> ["def recursive_keypairs(d, separator=':'):\n\tfor (name, value) in sorted(six.iteritems(d)):\n\t\tif isinstance(value, dict):\n\t\t\tfor (subname, subvalue) in recursive_keypairs(value, separator):\n\t\t\t\t(yield (('%s%s%s' % (name, separator, subname)), subvalue))\n\t\telif isinstance(value, (tuple, list)):\n\t\t\t(yield (name, decode_unicode(value)))\n\t\telse:\n\t\t\t(yield (name, value))\n","generator that produces sequence of keypairs for nested dictionaries ."] (predictor.py:56, main())
[2020-11-20 23:35:15]    INFO >> ["def import_library(taglib_module):\n\ttry:\n\t\tmod = import_module(taglib_module)\n\texcept ImportError as e:\n\t\tif is_library_missing(taglib_module):\n\t\t\treturn None\n\t\telse:\n\t\t\traise InvalidTemplateLibrary(('ImportError\traised\tloading\t%s:\t%s' % (taglib_module, e)))\n\ttry:\n\t\treturn mod.register\n\texcept AttributeError:\n\t\traise InvalidTemplateLibrary((\"Template\tlibrary\t%s\tdoes\tnot\thave\ta\tvariable\tnamed\t'register'\" % taglib_module))\n","load a template tag library module ."] (predictor.py:56, main())
[2020-11-20 23:35:15]    INFO >> ["def make_analysator(f):\n\tdef text_analyse(text):\n\t\trv = f(text)\n\t\tif (not rv):\n\t\t\treturn 0.0\n\t\treturn min(1.0, max(0.0, float(rv)))\n\ttext_analyse.__doc__ = f.__doc__\n\treturn staticmethod(text_analyse)\n","return a static text analysation function that returns float values ."] (predictor.py:56, main())
[2020-11-20 23:35:16]    INFO >> ["def read_cached_file(filename, cache_info, reload_func=None):\n\tmtime = os.path.getmtime(filename)\n\tif ((not cache_info) or (mtime != cache_info.get('mtime'))):\n\t\tLOG.debug((_('Reloading\tcached\tfile\t%s') % filename))\n\t\twith open(filename) as fap:\n\t\t\tcache_info['data'] = fap.read()\n\t\tcache_info['mtime'] = mtime\n\t\tif reload_func:\n\t\t\treload_func(cache_info['data'])\n\treturn cache_info['data']\n","read from a file if it has been modified ."] (predictor.py:56, main())
[2020-11-20 23:35:16]    INFO >> ["def set_mindays(name, mindays):\n\tpre_info = info(name)\n\tif (mindays == pre_info['min']):\n\t\treturn True\n\tcmd = 'passwd\t-n\t{0}\t{1}'.format(mindays, name)\n\t__salt__['cmd.run'](cmd, python_shell=False)\n\tpost_info = info(name)\n\tif (post_info['min'] != pre_info['min']):\n\t\treturn (post_info['min'] == mindays)\n\treturn False\n","set the minimum number of days between password changes ."] (predictor.py:56, main())
[2020-11-20 23:35:16]    INFO >> ["def net_if_stats():\n\tnames = net_io_counters().keys()\n\tret = {}\n\tfor name in names:\n\t\t(isup, duplex, speed, mtu) = cext_posix.net_if_stats(name)\n\t\tif hasattr(_common, 'NicDuplex'):\n\t\t\tduplex = _common.NicDuplex(duplex)\n\t\tret[name] = _common.snicstats(isup, duplex, speed, mtu)\n\treturn ret\n","get nic stats ."] (predictor.py:56, main())
[2020-11-20 23:35:17]    INFO >> ["def get_mapped_batch(dataset, design_batch):\n\tif (design_batch.ndim != 2):\n\t\tdesign_batch = dataset.get_design_matrix(design_batch.copy())\n\tmapped_design = dataset.mapback(design_batch.copy())\n\tmapped_batch = dataset.get_topological_view(mapped_design.copy())\n\treturn mapped_batch\n","get mapped batch if mapback_for_viewer is available with the dataset ."] (predictor.py:56, main())
[2020-11-20 23:35:18]    INFO >> ["def commit_manually(using=None):\n\twarnings.warn('commit_manually\tis\tdeprecated\tin\tfavor\tof\tset_autocommit.', PendingDeprecationWarning, stacklevel=2)\n\tdef entering(using):\n\t\tenter_transaction_management(using=using)\n\tdef exiting(exc_type, using):\n\t\tleave_transaction_management(using=using)\n\treturn _transaction_func(entering, exiting, using)\n","decorator that activates manual transaction control ."] (predictor.py:56, main())
[2020-11-20 23:35:18]    INFO >> ["def mark_safe(s):\n\tif hasattr(s, '__html__'):\n\t\treturn s\n\tif (isinstance(s, bytes) or (isinstance(s, Promise) and s._delegate_bytes)):\n\t\treturn SafeBytes(s)\n\tif isinstance(s, (str, Promise)):\n\t\treturn SafeText(s)\n\tif callable(s):\n\t\treturn _safety_decorator(mark_safe, s)\n\treturn SafeString(str(s))\n","explicitly mark a string as safe for output purposes ."] (predictor.py:56, main())
[2020-11-20 23:35:19]    INFO >> ["def never_cache(view_func):\n\t@wraps(view_func)\n\tdef _wrapped_view_func(request, *args, **kwargs):\n\t\tresponse = view_func(request, *args, **kwargs)\n\t\tadd_never_cache_headers(response)\n\t\treturn response\n\treturn _wrapped_view_func\n","decorator that adds headers to a response so that it will never be cached ."] (predictor.py:56, main())
[2020-11-20 23:35:20]    INFO >> ["def _get_model(model_identifier):\n\ttry:\n\t\tModel = models.get_model(*model_identifier.split('.'))\n\texcept TypeError:\n\t\tModel = None\n\tif (Model is None):\n\t\traise base.DeserializationError((\"Invalid\tmodel\tidentifier:\t'%s'\" % model_identifier))\n\treturn Model\n","helper to look up a model from an \"app_label ."] (predictor.py:56, main())
[2020-11-20 23:35:20]    INFO >> ["def _strip_once(value):\n\ts = MLStripper()\n\ttry:\n\t\ts.feed(value)\n\texcept HTMLParseError:\n\t\treturn value\n\ttry:\n\t\ts.close()\n\texcept HTMLParseError:\n\t\treturn (s.get_data() + s.rawdata)\n\telse:\n\t\treturn s.get_data()\n","internal tag stripping utility used by strip_tags ."] (predictor.py:56, main())
[2020-11-20 23:35:20]    INFO >> ["def getResolver():\n\tglobal theResolver\n\tif (theResolver is None):\n\t\ttry:\n\t\t\ttheResolver = createResolver()\n\t\texcept ValueError:\n\t\t\ttheResolver = createResolver(servers=[('127.0.0.1', 53)])\n\treturn theResolver\n","get a resolver instance ."] (predictor.py:56, main())
[2020-11-20 23:35:21]    INFO >> ["def _convert_other(other, raiseit=False, allow_float=False):\n\tif isinstance(other, Decimal):\n\t\treturn other\n\tif isinstance(other, (int, long)):\n\t\treturn Decimal(other)\n\tif (allow_float and isinstance(other, float)):\n\t\treturn Decimal.from_float(other)\n\timport sys\n\tif (sys.platform == 'cli'):\n\t\timport System\n\t\tif isinstance(other, System.Decimal):\n\t\t\treturn Decimal(other)\n\tif raiseit:\n\t\traise TypeError(('Unable\tto\tconvert\t%s\tto\tDecimal' % other))\n\treturn NotImplemented\n","convert other to decimal ."] (predictor.py:56, main())
[2020-11-20 23:35:21]    INFO >> ["def is_library_missing(name):\n\t(path, module) = name.rsplit(u'.', 1)\n\ttry:\n\t\tpackage = import_module(path)\n\t\treturn (not module_has_submodule(package, module))\n\texcept ImportError:\n\t\treturn is_library_missing(path)\n","check if library that failed to load cannot be found under any templatetags directory or does exist but fails to import ."] (predictor.py:56, main())
[2020-11-20 23:35:21]    INFO >> ["def send_from_directory(directory, filename, **options):\n\tfilename = safe_join(directory, filename)\n\tif (not os.path.isfile(filename)):\n\t\traise NotFound()\n\toptions.setdefault('conditional', True)\n\treturn send_file(filename, **options)\n","send a file from a given directory with :func:send_file ."] (predictor.py:56, main())
[2020-11-20 23:35:22]    INFO >> ["def DeleteCampaignFeed(client, campaign_feed):\n\tcampaign_feed_service = client.GetService('CampaignFeedService', 'v201607')\n\toperation = {'operand': campaign_feed, 'operator': 'REMOVE'}\n\tcampaign_feed_service.mutate([operation])\n","deletes a campaign feed ."] (predictor.py:56, main())
[2020-11-20 23:35:22]    INFO >> ["def splittag(url):\n\t(path, delim, tag) = url.rpartition('#')\n\tif delim:\n\t\treturn (path, tag)\n\treturn (url, None)\n","splittag --> \/path ."] (predictor.py:56, main())
[2020-11-20 23:35:23]    INFO >> ["def mail_managers(subject, message, fail_silently=False, connection=None):\n\tif (not settings.MANAGERS):\n\t\treturn\n\tEmailMessage((u'%s%s' % (settings.EMAIL_SUBJECT_PREFIX, subject)), message, settings.SERVER_EMAIL, [a[1] for a in settings.MANAGERS], connection=connection).send(fail_silently=fail_silently)\n","sends a message to the managers ."] (predictor.py:56, main())
[2020-11-20 23:35:23]    INFO >> ["def FixedOffset(offset, _tzinfos={}):\n\tif (offset == 0):\n\t\treturn UTC\n\tinfo = _tzinfos.get(offset)\n\tif (info is None):\n\t\tinfo = _tzinfos.setdefault(offset, _FixedOffset(offset))\n\treturn info\n","return a fixed-offset timezone based off a number of minutes ."] (predictor.py:56, main())
[2020-11-20 23:35:23]    INFO >> ["def subn(pattern, repl, string, count=0, flags=0, pos=None, endpos=None, concurrent=None, **kwargs):\n\treturn _compile(pattern, flags, kwargs).subn(repl, string, count, pos, endpos, concurrent)\n","return a 2-tuple containing ."] (predictor.py:56, main())
[2020-11-20 23:35:24]    INFO >> ["def vary_on_cookie(func):\n\tdef inner_func(*args, **kwargs):\n\t\tresponse = func(*args, **kwargs)\n\t\tpatch_vary_headers(response, ('Cookie',))\n\t\treturn response\n\treturn inner_func\n","a view decorator that adds \"cookie\" to the vary header of a response ."] (predictor.py:56, main())
[2020-11-20 23:35:24]    INFO >> ["def print_last(limit=None, file=None):\n\tif (not hasattr(sys, 'last_type')):\n\t\traise ValueError('no\tlast\texception')\n\tif (file is None):\n\t\tfile = sys.stderr\n\tprint_exception(sys.last_type, sys.last_value, sys.last_traceback, limit, file)\n","this is a shorthand for print_exception ."] (predictor.py:56, main())
[2020-11-20 23:35:24]    INFO >> ["def getGeometryOutputByArguments(arguments, elementNode):\n\tevaluate.setAttributesByArguments(['sides', 'radius'], arguments, elementNode)\n\treturn getGeometryOutput(None, elementNode)\n","get vector3 vertexes from attribute dictionary by arguments ."] (predictor.py:56, main())
[2020-11-20 23:35:25]    INFO >> ["def get_authorization_header(request):\n\tauth = request.META.get(u'HTTP_AUTHORIZATION', '')\n\tif isinstance(auth, text_type):\n\t\tauth = auth.encode(HTTP_HEADER_ENCODING)\n\treturn auth\n","return requests authorization: header ."] (predictor.py:56, main())
[2020-11-20 23:35:25]    INFO >> ["def quota_usage_update(context, project_id, resource, **kwargs):\n\treturn IMPL.quota_usage_update(context, project_id, resource, **kwargs)\n","update a quota usage or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:35:25]    INFO >> ["def volume_type_extra_specs_delete(context, volume_type_id, key):\n\tIMPL.volume_type_extra_specs_delete(context, volume_type_id, key)\n","delete the given extra specs item ."] (predictor.py:56, main())
[2020-11-20 23:35:26]    INFO >> ["def backends(user):\n\treturn user_backends_data(user, get_helper('AUTHENTICATION_BACKENDS'), get_helper('STORAGE', do_import=True))\n","load social auth current user data to context under the key backends ."] (predictor.py:56, main())
[2020-11-20 23:35:27]    INFO >> ["def article(word, function=INDEFINITE):\n\treturn (((function == DEFINITE) and definite_article(word)) or indefinite_article(word))\n","returns the indefinite or definite article for the given word ."] (predictor.py:56, main())
[2020-11-20 23:35:27]    INFO >> ["def is_aware(value):\n\treturn ((value.tzinfo is not None) and (value.tzinfo.utcoffset(value) is not None))\n","determines if a given datetime ."] (predictor.py:56, main())
[2020-11-20 23:35:27]    INFO >> ["def check_isinstance(obj, cls):\n\tif isinstance(obj, cls):\n\t\treturn obj\n\traise Exception((_('Expected\tobject\tof\ttype:\t%s') % str(cls)))\n\treturn cls()\n","checks that obj is of type cls ."] (predictor.py:56, main())
[2020-11-20 23:35:28]    INFO >> ["def _project_cert_subject(project_id):\n\treturn (CONF.project_cert_subject % (project_id, timeutils.isotime()))\n","helper to generate user cert subject ."] (predictor.py:56, main())
[2020-11-20 23:35:28]    INFO >> ["@library.global_function\ndef unlocalized_url(viewname, *args, **kwargs):\n\treturn django_reverse(viewname, args=args, kwargs=kwargs)\n","helper for djangos reverse in templates ."] (predictor.py:56, main())
[2020-11-20 23:35:29]    INFO >> ["def getTextLines(text):\n\tif ('\\r' in text):\n\t\ttext = text.replace('\\r', '\\n').replace('\\n\\n', '\\n')\n\ttextLines = text.split('\\n')\n\tif (len(textLines) == 1):\n\t\tif (textLines[0] == ''):\n\t\t\treturn []\n\treturn textLines\n","get the all the lines of text of a text ."] (predictor.py:56, main())
[2020-11-20 23:35:29]    INFO >> ["def connections_support_transactions():\n\treturn all((conn.settings_dict['SUPPORTS_TRANSACTIONS'] for conn in connections.all()))\n","returns true if all connections support transactions ."] (predictor.py:56, main())
[2020-11-20 23:35:29]    INFO >> ["def test_sarcasm():\n\tdirty = u'Yeah\tright\t<sarcasm\/>'\n\tclean = u'Yeah\tright\t&lt;sarcasm\/&gt;'\n\teq_(clean, linkify(dirty))\n","jokes should crash ."] (predictor.py:56, main())
[2020-11-20 23:35:30]    INFO >> ["def update_last_login(sender, user, **kwargs):\n\tuser.last_login = timezone.now()\n\tuser.save()\n","a signal receiver which updates the last_login date for the user logging in ."] (predictor.py:56, main())
[2020-11-20 23:35:30]    INFO >> ["def getPluginsDirectoryPath():\n\treturn archive.getAbsoluteFolderPath(os.path.dirname(__file__), os.path.join('skeinforge_plugins', 'meta_plugins'))\n","get the plugins directory path ."] (predictor.py:56, main())
[2020-11-20 23:35:31]    INFO >> ["def consistencygroup_get(context, consistencygroup_id):\n\treturn IMPL.consistencygroup_get(context, consistencygroup_id)\n","get a consistencygroup or raise if it does not exist ."] (predictor.py:56, main())
[2020-11-20 23:35:31]    INFO >> ["def is_executable(exe):\n\treturn os.access(exe, os.X_OK)\n","checks a file is executable ."] (predictor.py:56, main())
[2020-11-20 23:35:31]    INFO >> ["def processElementNode(elementNode):\n\tpath.convertElementNode(elementNode, getGeometryOutput(None, elementNode))\n","process the xml element ."] (predictor.py:56, main())
[2020-11-20 23:35:32]    INFO >> ["def getNewRepository():\n\treturn ExportRepository()\n","get new repository ."] (predictor.py:56, main())
[2020-11-20 23:35:32]    INFO >> ["def _approximate_mode(class_counts, n_draws, rng):\n\tcontinuous = ((n_draws * class_counts) \/ class_counts.sum())\n\tfloored = np.floor(continuous)\n\tneed_to_add = int((n_draws - floored.sum()))\n\tif (need_to_add > 0):\n\t\tremainder = (continuous - floored)\n\t\tvalues = np.sort(np.unique(remainder))[::(-1)]\n\t\tfor value in values:\n\t\t\t(inds,) = np.where((remainder == value))\n\t\t\tadd_now = min(len(inds), need_to_add)\n\t\t\tinds = choice(inds, size=add_now, replace=False, random_state=rng)\n\t\t\tfloored[inds] += 1\n\t\t\tneed_to_add -= add_now\n\t\t\tif (need_to_add == 0):\n\t\t\t\tbreak\n\treturn floored.astype(np.int)\n","computes approximate mode of multivariate hypergeometric ."] (predictor.py:56, main())
[2020-11-20 23:35:32]    INFO >> ["def reverse_field_path(model, path):\n\treversed_path = []\n\tparent = model\n\tpieces = path.split(LOOKUP_SEP)\n\tfor piece in pieces:\n\t\tfield = parent._meta.get_field(piece)\n\t\tdirect = ((not field.auto_created) or field.concrete)\n\t\tif (len(reversed_path) == (len(pieces) - 1)):\n\t\t\ttry:\n\t\t\t\tget_model_from_relation(field)\n\t\t\texcept NotRelationField:\n\t\t\t\tbreak\n\t\tif direct:\n\t\t\trelated_name = field.related_query_name()\n\t\t\tparent = field.rel.to\n\t\telse:\n\t\t\trelated_name = field.field.name\n\t\t\tparent = field.model\n\t\treversed_path.insert(0, related_name)\n\treturn (parent, LOOKUP_SEP.join(reversed_path))\n","create a reversed field path ."] (predictor.py:56, main())
[2020-11-20 23:35:33]    INFO >> ["def get_properties_of_kind(kind, start=None, end=None):\n\tq = Property.all(keys_only=True)\n\tq.ancestor(Property.key_for_kind(kind))\n\tif ((start is not None) and (start != '')):\n\t\tq.filter('__key__\t>=', Property.key_for_property(kind, start))\n\tif (end is not None):\n\t\tif (end == ''):\n\t\t\treturn []\n\t\tq.filter('__key__\t<', Property.key_for_property(kind, end))\n\treturn [Property.key_to_property(x) for x in q.run()]\n","return all properties of kind in the specified range ."] (predictor.py:56, main())
[2020-11-20 23:35:33]    INFO >> ["def add_credential(tenant_id, credential_name, user_name, password):\n\tsession = db.get_session()\n\ttry:\n\t\tcred = session.query(network_models_v2.Credential).filter_by(tenant_id=tenant_id).filter_by(credential_name=credential_name).one()\n\t\traise c_exc.CredentialAlreadyExists(credential_name=credential_name, tenant_id=tenant_id)\n\texcept exc.NoResultFound:\n\t\tcred = network_models_v2.Credential(tenant_id, credential_name, user_name, password)\n\t\tsession.add(cred)\n\t\tsession.flush()\n\t\treturn cred\n","adds a qos to tenant association ."] (predictor.py:56, main())
[2020-11-20 23:35:33]    INFO >> ["def removeElementFromListTable(element, key, listTable):\n\tif (key not in listTable):\n\t\treturn\n\telementList = listTable[key]\n\tif (len(elementList) < 2):\n\t\tdel listTable[key]\n\t\treturn\n\tif (element in elementList):\n\t\telementList.remove(element)\n","remove an element from the list table ."] (predictor.py:56, main())
[2020-11-20 23:35:34]    INFO >> ["def _reraise_translated_image_exception(image_id):\n\t(_exc_type, exc_value, exc_trace) = sys.exc_info()\n\tnew_exc = _translate_image_exception(image_id, exc_value)\n\tsix.reraise(type(new_exc), new_exc, exc_trace)\n","transform the exception for the image but keep its traceback intact ."] (predictor.py:56, main())
[2020-11-20 23:35:34]    INFO >> ["def parse_qsl(qs, keep_blank_values=0, strict_parsing=0):\n\tpairs = [s2 for s1 in qs.split('&') for s2 in s1.split(';')]\n\tr = []\n\tfor name_value in pairs:\n\t\tif ((not name_value) and (not strict_parsing)):\n\t\t\tcontinue\n\t\tnv = name_value.split('=', 1)\n\t\tif (len(nv) != 2):\n\t\t\tif strict_parsing:\n\t\t\t\traise ValueError, ('bad\tquery\tfield:\t%r' % (name_value,))\n\t\t\tif keep_blank_values:\n\t\t\t\tnv.append('')\n\t\t\telse:\n\t\t\t\tcontinue\n\t\tif (len(nv[1]) or keep_blank_values):\n\t\t\tname = unquote(nv[0].replace('+', '\t'))\n\t\t\tvalue = unquote(nv[1].replace('+', '\t'))\n\t\t\tr.append((name, value))\n\treturn r\n","parse a query given as a string argument ."] (predictor.py:56, main())
[2020-11-20 23:35:34]    INFO >> ["def get_plural(locale=LC_CTYPE):\n\tlocale = Locale.parse(locale)\n\ttry:\n\t\ttup = PLURALS[str(locale)]\n\texcept KeyError:\n\t\ttry:\n\t\t\ttup = PLURALS[locale.language]\n\t\texcept KeyError:\n\t\t\ttup = DEFAULT_PLURAL\n\treturn _PluralTuple(tup)\n","a tuple with the information catalogs need to perform proper pluralization ."] (predictor.py:56, main())
